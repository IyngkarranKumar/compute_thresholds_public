{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pwlf #for colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "modules = [\n",
    "    ('numpy', 'np'),\n",
    "    ('scipy.stats', 'stats'),\n",
    "    ('scipy.optimize', 'optimize'), \n",
    "    ('matplotlib.pyplot', 'plt'), \n",
    "    ('pandas', 'pd'),\n",
    "    ('seaborn', 'sns'),\n",
    "    ('itertools', 'itertools'),\n",
    "    ('copy', 'copy'),\n",
    "    ('re', 're'),\n",
    "    ('pdb', 'pdb'),\n",
    "    ('logging', 'logging')\n",
    "]\n",
    "\n",
    "for module, alias in modules:\n",
    "    start = time.time()\n",
    "    exec(f\"import {module} as {alias}\")\n",
    "    end = time.time()\n",
    "    print(f\"{module}: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats, optimize\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd #taking long to load here\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import copy,re, pdb, logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logger=logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"https://epochai.org/data/epochdb/notable_systems.csv\")\n",
    "url = 'https://drive.google.com/file/d/1RLLKPU3bEYK65wlQlU0p20u9M8cHkLMl/view?usp=sharing'\n",
    "url = 'https://drive.google.com/uc?id=' + url.split('/')[-2]\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "df = df[~df[\"Notability criteria\"].isna()]\n",
    "\n",
    "df[\"compute\"] = df[\"Training compute (FLOP)\"]\n",
    "df[\"date\"] = df[\"Publication date\"]\n",
    "df[\"model\"] = df[\"System\"]\n",
    "df[\"poss1e23\"] = df[\"Possibly over 1e23 FLOP\"]\n",
    "df[\"poss1e25\"] = df[\"Estimated over 1e25 FLOP\"]\n",
    "df[\"cost\"] = df[\"Training compute cost (2023 USD)\"]\n",
    "df[\"cost\"] = df[\"cost\"].str.replace(\",\", \"\").str.replace(\"$\", \"\").astype(float)\n",
    "\n",
    "df = df[[\"model\", \"compute\", \"date\", \"cost\", \"poss1e23\", \"poss1e25\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = ['AlphaGo Zero','AlphaZero'] #outliers\n",
    "df = df[~df[\"model\"].isin(to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_append = [\n",
    "  [\"Claude 3.5 Sonnet\", 4.3e25, \"2024-06-21\", np.nan, np.nan, np.nan],\n",
    "  [\"GPT-4o Mini\", 1.2e25, \"2024-07-18\", np.nan, np.nan, np.nan],\n",
    "]\n",
    "\n",
    "for row in to_append:\n",
    "  if row[0] not in df[\"model\"].values:\n",
    "    df.loc[len(df)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_add_compute = {\n",
    "    \"Claude 3 Opus\": 2.5e25,\n",
    "    \"Claude 3 Sonnet\": 1.1e25,\n",
    "    \"GPT-4o\": 2.9e25,\n",
    "    \"Gemini 1.0 Pro\": 2.8e24,\n",
    "    \"Gemini 1.5 Pro\": 1.9e25,\n",
    "    \"Reka Core\": 8.4e24,\n",
    "    \"GPT-4 Turbo\": 2.1e25,  # rough guess\n",
    "    \"GPT-4V\": 2.1e25,  # rough guess\n",
    "    \"Claude 2.1\": df[df[\"model\"]==\"Claude 2\"][\"compute\"].values,  # rough guess\n",
    "}\n",
    "\n",
    "logger.info('Can add more recent models here')\n",
    "\n",
    "\n",
    "for k, v in to_add_compute.items():\n",
    "  if df.loc[df[\"model\"] == k, \"compute\"].isna().values:\n",
    "    df.loc[df[\"model\"] == k, \"compute\"] = v\n",
    "  else:\n",
    "    print(f\"{k} already has a compute value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the ones we've set\n",
    "df.loc[~df[\"compute\"].isna(), \"poss1e23\"] = np.nan\n",
    "df.loc[~df[\"compute\"].isna(), \"poss1e25\"] = np.nan\n",
    "\n",
    "# Set some temporary placeholder values\n",
    "# TODO: revisit\n",
    "# df.loc[(df[\"poss1e25\"] == \"checked\"), \"compute\"] = 1.01e25  # placeholder\n",
    "# df.loc[((df[\"poss1e23\"] ==\"checked\") & (df[\"poss1e25\"] != \"checked\")), \"compute\"] = 1.01e23  # placeholder\n",
    "\n",
    "# We want to handle these leading models manually via the above compute estimates.\n",
    "assert df[(df[\"poss1e25\"] == \"checked\") & (df[\"compute\"].isna())].size == 0\n",
    "\n",
    "# We sample 1e23-1e25 models with unknown compute from the existing empirical distribution.\n",
    "# TODO: revisit\n",
    "poss1e23 = ((df[\"poss1e23\"] == \"checked\") & (df[\"poss1e25\"] != \"checked\"))\n",
    "df.loc[poss1e23, \"compute\"] = df[(df[\"compute\"] >= 1e23) & (df[\"compute\"] < 1e25)][\"compute\"].sample(poss1e23.sum(), random_state=0).values\n",
    "\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df[\"log_compute\"] = np.log10(df[\"compute\"])\n",
    "\n",
    "df[\"date_float\"] = df[\"date\"].dt.year + df[\"date\"].dt.month/12\n",
    "\n",
    "df['year'] = df['date'].dt.year\n",
    "\n",
    "df = df.sort_values(\"date\")\n",
    "df.dropna(subset=\"compute\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate basic scatterplot\n",
    "if 1:\n",
    "    fig = sns.scatterplot(data=df[df['date']>'2010-01-01'], x='date',y='compute')\n",
    "    fig.set(yscale='log')\n",
    "    plt.grid(alpha=0.5)\n",
    "\n",
    "    # Add line of best fit for historical data\n",
    "    historical_data = df[df['date']>'2010-01-01']\n",
    "    x = historical_data['date'].astype(np.int64) // 10**9  # Convert to unix timestamp\n",
    "    y = historical_data['compute']\n",
    "    z = np.polyfit(x, np.log(y), 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(historical_data['date'], np.exp(p(x)), 'b--', alpha=0.8)\n",
    "\n",
    "    future_dates = pd.date_range(start='2025-01-01', end='2029-12-31', periods=200)\n",
    "    base = 1e25  # Starting point based on 2024 level\n",
    "    noise = np.random.normal(0, 10, len(future_dates))\n",
    "    years_from_2025 = (future_dates.year - 2025)\n",
    "\n",
    "    growth_rate = 3.0  # Exponential growth rate\n",
    "    future_compute = base * np.exp(growth_rate * years_from_2025) * (1 + noise)\n",
    "    plt.scatter(future_dates, future_compute, alpha=0.3, color='red', label='Projected - business as usual')\n",
    "\n",
    "    growth_rate = 0.4\n",
    "    future_compute = base * np.exp(growth_rate * years_from_2025) * (1 + noise)\n",
    "    plt.scatter(future_dates, future_compute, alpha=0.3, color='green', label='Projected - inference scaling')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlim([pd.Timestamp('2020-01-01'),pd.Timestamp('2030-01-01')])\n",
    "\n",
    "    for exp in range(25,31):\n",
    "        plt.axhline(y=10**exp,color='gray',linestyle='--',alpha=0.6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLOP_dollar=2e25/100e6 #FLOP per dollar conversion ~2023 (GPT-4 was ~2e25 FLOP for estimated $1e8)\n",
    "\n",
    "\n",
    "fig = sns.scatterplot(data=df[df['date']>'2010-01-01'], x='date',y=(1/FLOP_dollar)*df['compute'])\n",
    "fig.set(yscale='log')\n",
    "plt.grid(alpha=0.5)\n",
    "plt.axhline(y=1e14,label='World GDP',color='red',linestyle='--',alpha=0.8)\n",
    "plt.axhline(y=30e12,label='US GDP',color='orange',linestyle='--',alpha=0.8)\n",
    "plt.axhline(y=40e9,label='Meta R&D budget 2023',color='green',linestyle='--',alpha=0.8)\n",
    "plt.axhline(y=100e6,label='GPT-4 training cost (est)',color='purple',linestyle='--',alpha=0.8)\n",
    "\n",
    "# Add future projections\n",
    "future_dates = pd.date_range(start='2024-01-01', end='2029-12-31', periods=500)\n",
    "base = (1/FLOP_dollar) * 2e25  # Starting point based on 2024 level\n",
    "noise = np.random.normal(0, 10, len(future_dates))\n",
    "years_from_2024 = (future_dates.year - 2024)\n",
    "\n",
    "growth_rate = 3.0  # Exponential growth rate\n",
    "future_costs = base * np.exp(growth_rate * years_from_2024) * (1 + noise)\n",
    "plt.scatter(future_dates, future_costs, alpha=0.3, color='red', label='Projected - business as usual')\n",
    "\n",
    "#growth_rate = 0.4\n",
    "#future_costs = base * np.exp(growth_rate * years_from_2024) * (1 + noise)\n",
    "#plt.scatter(future_dates, future_costs, alpha=0.3, color='green', label='Projected - inference scaling')\n",
    "\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.xlim([pd.Timestamp('2020-01-01'),pd.Timestamp('2030-01-01')])\n",
    "plt.ylabel(\"Training compute cost ($)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "year_filter=[2020,2021,2022,2023]\n",
    "group_param=5\n",
    "table=pd.DataFrame(index=[f'Group {i}' for i in range(group_param)],columns=year_filter)\n",
    "\n",
    "\n",
    "for year in df['date'].dt.year.unique():\n",
    "    if year not in year_filter: continue\n",
    "    year_data = df[df['date'].dt.year == year]\n",
    "    print(f\"\\nYear: {year}\")\n",
    "    sorted_year_data=year_data.sort_values(by='compute',ascending=False)['compute']\n",
    "    grouped_data=pd.qcut(sorted_year_data,q=group_param,labels=False)\n",
    "    for group in range(group_param):\n",
    "        group_data = sorted_year_data[grouped_data == group]\n",
    "        group_share = group_data.sum() / year_data['compute'].sum() * 100\n",
    "        table.loc[f'Group {group}',year] = group_share\n",
    "        print(f\"Group {group}: {group_share:.1f}% of total compute\")\n",
    "\n",
    "\n",
    "\n",
    "# Plot pie chart of latest year's data\n",
    "latest_year = max(year_filter)\n",
    "latest_data = table[latest_year]\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.pie(latest_data, labels=[f'Group {i}' for i in range(group_param)], autopct='%1.1f%%')\n",
    "plt.title(f'Share of Total Compute by Group ({latest_year})')\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "FLOP_dollar_2024 = 2e25/100e6\n",
    "dollar_FLOP_2024 = 1/FLOP_dollar_2024\n",
    "year_grouped_df=df.groupby(df['date'][df['date']>'2010-01-01'].dt.year)\n",
    "aggregate_compute=year_grouped_df['compute'].sum()\n",
    "aggregate_compute_cost=aggregate_compute*dollar_FLOP_2024\n",
    "log_aggregate_compute=np.log10(aggregate_compute)\n",
    "log_aggregate_compute_cost=np.log10(aggregate_compute_cost)\n",
    "#plot\n",
    "# Plot historical data\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(year_grouped_df.groups.keys(), log_aggregate_compute_cost, label='Historical data')\n",
    "\n",
    "# Fit exponential for extrapolation\n",
    "# Linear regression\n",
    "x = np.array(list(year_grouped_df.groups.keys())).reshape(-1, 1)\n",
    "y = log_aggregate_compute_cost.values\n",
    "reg = LinearRegression().fit(x, y)\n",
    "\n",
    "# Generate future years for extrapolation\n",
    "future_years = np.arange(max(x), 2030).reshape(-1, 1)\n",
    "\n",
    "# Get predictions\n",
    "future_predictions = reg.predict(future_years)\n",
    "\n",
    "\n",
    "# Plot extrapolation\n",
    "plt.plot(future_years, future_predictions, '--', label='Extrapolation')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Log10(Total Compute)')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_compute_2028 = 1e30\n",
    "cost_2024 = total_compute_2028 * dollar_FLOP_2024\n",
    "print(f\"With 2024 FLOP/dollar costs, the cost of {total_compute_2028} FLOP is approx {cost_2024/1e12:,.2f} trillion USD\")\n",
    "\n",
    "#case 1 - ~ 9 models with 1e29, 100 models with 1e27 \n",
    "#case 1 - ~ 9 models with \n",
    "\n",
    "#case 2 - ~10000 models with 1e26, 0 models above that\n",
    "\n",
    "#case 3 - 1 model 1e29, 10 models 1e28, 100 models 1e27, 1000 models 1e26 etc. \n",
    "\n",
    "years_to_iter=[2020,2021,2022,2023]\n",
    "fig,axs=plt.subplots(nrows=2,ncols=2,figsize=(8,6)); axs_ravel=axs.ravel()\n",
    "kde_fig,kde_axs=plt.subplots(nrows=2,ncols=2,figsize=(8,6)); kde_axs_ravel=kde_axs.ravel()\n",
    "\n",
    "def percentage_formatter(x,pos):\n",
    "        return f'{x:.6f}%'\n",
    "\n",
    "\n",
    "\n",
    "for idx,year in enumerate(years_to_iter):\n",
    "        ax,kde_ax=axs_ravel[idx], kde_axs_ravel[idx]\n",
    "        total_compute=aggregate_compute[aggregate_compute.index==year].values\n",
    "        cost_2023=total_compute*dollar_FLOP_2024\n",
    "        datapoints_year=df[df['date'].dt.year==year]['compute']\n",
    "        mean_log_compute=np.log10(datapoints_year).mean()\n",
    "\n",
    "        #prep data\n",
    "        sorted_computes=np.sort(datapoints_year)\n",
    "        norm_factor=total_compute[0]\n",
    "        norm_sorted_computes=sorted_computes/norm_factor\n",
    "        cumsum=np.cumsum(sorted_computes)\n",
    "        norm_cumsum=cumsum/norm_factor\n",
    "\n",
    "\n",
    "\n",
    "        #T-m plot\n",
    "        ax.plot(norm_sorted_computes,norm_cumsum)\n",
    "        ax.scatter(norm_sorted_computes, norm_cumsum, alpha=0.5, color='blue', s=30,marker='x')\n",
    "\n",
    "        ax.grid(True,alpha=0.3)\n",
    "        ax.set_xscale('log'); ax.set_yscale('log')\n",
    "        #ax.set_xlim([1e18,1e27])\n",
    "        ax.set_xlabel('individual model size'); ax.set_ylabel('Total training compute')\n",
    "        ax.set_title(f'Year: {year}')\n",
    "        ax.text(0.05, 0.95, f'Total compute: {total_compute[0]:.2e} FLOP', \n",
    "                transform=ax.transAxes, verticalalignment='top')\n",
    "        ax.axhline(y=norm_cumsum[-1],color='r',linestyle='--')\n",
    "        ax.axvline(x=1,color='g',linestyle='--',alpha=0.5)\n",
    "        ax.text(1,ax.get_ylim()[0],f'{norm_factor:.2e}',\n",
    "                rotation=90,fontsize=8,verticalalignment='top')\n",
    "        ax.yaxis.set_major_formatter(percentage_formatter)\n",
    "\n",
    "        #KDE plot \n",
    "        kde=stats.gaussian_kde(np.log10(norm_sorted_computes))\n",
    "        x_range=np.logspace(np.log10(norm_sorted_computes).min(),np.log10(1))\n",
    "        kde_ax.plot(x_range,kde(np.log10(x_range)))\n",
    "        kde_ax.set_xscale('log')\n",
    "        kde_ax.set_title(f'Year: {year}')\n",
    "        kde_ax.grid(alpha=0.5)\n",
    "\n",
    "        kde_ax.axvline(x=1,color='g',linestyle='--',alpha=0.5)\n",
    "        kde_ax.text(1,ax.get_ylim()[0],f'{norm_factor:.2e}',\n",
    "                rotation=90,fontsize=8,verticalalignment='top')\n",
    "        if idx>=2: kde_ax.set_xlabel('Model compute (normalised by total)')\n",
    "\n",
    "fig.tight_layout(pad=2.0)\n",
    "kde_fig.tight_layout(pad=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T=245\n",
    "N=10\n",
    "a,b=23,26\n",
    "\n",
    "# Generate all possible integer combinations between log_a and log_b\n",
    "possible_values = np.arange(a, b+1).astype(float)\n",
    "all_combinations = list(itertools.combinations_with_replacement(possible_values, N))\n",
    "\n",
    "# Filter combinations that sum to target\n",
    "valid_combinations = []\n",
    "for combo in all_combinations:\n",
    "    if np.sum(combo)==T:\n",
    "        valid_combinations.append(combo)\n",
    "\n",
    "valid_distributions = np.array(valid_combinations)\n",
    "\n",
    "print(valid_distributions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sci_comp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
