{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset setup and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from scipy import stats, optimize\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd #taking long to load here\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import copy,re, pdb, logging\n",
    "from sklearn import linear_model\n",
    "from collections import defaultdict\n",
    "\n",
    "modules_to_import = [\n",
    "    ('numpy', 'np'),\n",
    "    ('scipy.stats', 'stats'),\n",
    "    ('scipy.optimize', 'optimize'),\n",
    "    ('matplotlib.pyplot', 'plt'),\n",
    "    ('pandas', 'pd'),\n",
    "    ('seaborn', 'sns'),\n",
    "    ('itertools', 'itertools'),\n",
    "    ('copy', 'copy'),\n",
    "    ('re', 're'),\n",
    "    ('pdb', 'pdb'),\n",
    "    ('logging', 'logging'),\n",
    "    ('sklearn.linear_model', 'linear_model'),\n",
    "]\n",
    "\n",
    "for module, alias in modules_to_import:\n",
    "    start_time = time.time()\n",
    "    exec(f\"import {module} as {alias}\")\n",
    "    end_time = time.time()\n",
    "    print(f\"{module} imported in {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "\n",
    "logging.getLogger().handlers.clear()\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    handlers=[\n",
    "        #logging.FileHandler(log_filename),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feb 2025 dataset\n",
    "\n",
    "#path \n",
    "path=\"/Users/iyngkarrankumar/Documents/GovAI WF/EUAIA_thresholds_project/data/notable_ai_models_24_02_2025.csv\"\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "df = df[~df[\"Notability criteria\"].isna()]\n",
    "\n",
    "df[\"compute\"] = df[\"Training compute (FLOP)\"]\n",
    "df[\"date\"] = pd.to_datetime(df[\"Publication date\"])\n",
    "df[\"year\"] = pd.to_datetime(df[\"date\"]).dt.year\n",
    "df[\"model\"] = df[\"Model\"]\n",
    "df[\"cost\"] = df[\"Training compute cost (2023 USD)\"]\n",
    "df[\"cost\"] = df[\"cost\"].fillna(\"$0\")  # Handle NaN values\n",
    "df[\"cost\"] = df[\"cost\"].astype(str)  # Convert to string\n",
    "df[\"cost\"] = df[\"cost\"].str.replace(\",\", \"\").str.replace(\"$\", \"\").astype(float)\n",
    "df = df[[\"model\", \"compute\", \"date\", \"cost\",\"year\"]]\n",
    "\n",
    "# Models to remove\n",
    "to_remove = [\"AlphaGo Zero\", \"AlphaZero\"]\n",
    "df = df[~df[\"model\"].isin(to_remove)]\n",
    "\n",
    "\n",
    "\n",
    "# Print stats for full dataset\n",
    "logging.info(\"=== Full Dataset ===\")\n",
    "logging.info(\"Most recent date: %s\", df[\"date\"].max())\n",
    "logging.debug(\"Datapoints per year:\")\n",
    "for year in range(2017, 2025):\n",
    "    count = len(df[df[\"year\"] == year])\n",
    "    logging.debug(\"%d: %d\", year, count)\n",
    "\n",
    "total_compute_2024 = df[df['year'] == 2024]['compute'].sum()\n",
    "largest_model_2024 = df[df['year'] == 2024]['compute'].max()\n",
    "\n",
    "if 0:\n",
    "    logging.info(\"Total compute used to train models in 2024: %.2e\", total_compute_2024)\n",
    "    logging.info(\"Largest model in 2024: %.2e\", largest_model_2024)\n",
    "    ratio_largest_to_total_compute_2024 = largest_model_2024 / total_compute_2024\n",
    "    logging.info(\"Ratio of largest model to total compute in 2024: %.4f\", ratio_largest_to_total_compute_2024)\n",
    "\n",
    "if 0:\n",
    "    # Count models with compute > 1e25 by year\n",
    "    threshold = 1e25\n",
    "    models_above_threshold = df[df['compute'] > threshold].groupby('year').size()\n",
    "    logging.info(\"\\nNumber of models with compute > 1e25 by year:\")\n",
    "    for year in models_above_threshold.index:\n",
    "        logging.info(\"%d: %d\", year, models_above_threshold[year])\n",
    "\n",
    "if 1:\n",
    "    total_compute_2020 = df[df['year'] == 2020]['compute'].sum()\n",
    "    largest_model_2020 = df[df['year'] == 2020]['compute'].max()\n",
    "\n",
    "    logging.info(\"Total compute used to train models in 2020: %.2e\", total_compute_2020)\n",
    "    logging.info(\"Largest model in 2020: %.2e\", largest_model_2020)\n",
    "    ratio_largest_to_total_compute_2020 = largest_model_2020 / total_compute_2020\n",
    "    logging.info(\"Ratio of largest model to total compute in 2020: %.4f\", ratio_largest_to_total_compute_2020)\n",
    "\n",
    "max_compute_idx = df['compute'].idxmax()\n",
    "logging.info(\"Largest compute value: %.2e (%s)\", df.loc[max_compute_idx, 'compute'], df.loc[max_compute_idx, 'model'])\n",
    "# Create dataset without specified years\n",
    "years_to_exclude = [2025, 2024]  # List of years to exclude\n",
    "df_filtered = df[~df[\"year\"].isin(years_to_exclude)].copy()\n",
    "\n",
    "logging.info(\"\\n\\n=== Dataset excluding years %s ===\", years_to_exclude)\n",
    "logging.info(\"Most recent date: %s\", df_filtered[\"date\"].max())\n",
    "\n",
    "max_compute_idx = df_filtered['compute'].idxmax()\n",
    "logging.info(\"Largest compute value: %.2e (%s)\", df_filtered.loc[max_compute_idx, 'compute'], df_filtered.loc[max_compute_idx, 'model'])\n",
    "\n",
    "df = df_filtered\n",
    "\n",
    "# Report number of entries before removing NaN\n",
    "logging.info(\"\\n\\n Number of entries before removing rows with compute=NaN: %d\", len(df))\n",
    "\n",
    "# Remove rows with NaN in compute column\n",
    "df = df.dropna(subset=['compute'])\n",
    "\n",
    "# Report number of entries after removing rows with compute=NaN\n",
    "logging.info(\"Number of entries after removing rows with compute=NaN: %d\", len(df))\n",
    "\n",
    "logging.info(\"\\nDatapoints per year after removing rows with compute=NaN:\")\n",
    "for year in range(2017, df.year.max()+1):\n",
    "    count = len(df[df[\"year\"] == year])\n",
    "    logging.info(\"%d: %d\", year, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate basic scatterplot\n",
    "if 1:\n",
    "    fig = sns.scatterplot(data=df[df['date']>'2010-01-01'], x='date',y='compute')\n",
    "    fig.set(yscale='log')\n",
    "    plt.grid(alpha=0.5)\n",
    "\n",
    "    # Add line of best fit for historical data\n",
    "    historical_data = df[df['date']>'2010-01-01']\n",
    "    x = historical_data['date'].astype(np.int64) // 10**9  # Convert to unix timestamp\n",
    "    y = historical_data['compute']\n",
    "    z = np.polyfit(x, np.log(y), 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(historical_data['date'], np.exp(p(x)), 'b--', alpha=0.8)\n",
    "\n",
    "    future_dates = pd.date_range(start=f'{df.year.max()+1}-01-01', end='2029-12-31', periods=200)\n",
    "    base = 1e23  # Starting point based on 2024 level\n",
    "    noise = np.random.normal(0, 10, len(future_dates))\n",
    "    years_from_2025 = (future_dates.year - (df.year.max()+1))\n",
    "\n",
    "    growth_rate = 3.0  # Exponential growth rate\n",
    "    future_compute = base * np.exp(growth_rate * years_from_2025) * (1 + noise)\n",
    "    plt.scatter(future_dates, future_compute, alpha=0.3, color='red', label='Scenario A')\n",
    "\n",
    "    growth_rate = 0.4\n",
    "    future_compute = base * np.exp(growth_rate * years_from_2025) * (1 + noise)\n",
    "    plt.scatter(future_dates, future_compute, alpha=0.3, color='green', label='Scenario B')\n",
    "\n",
    "    growth_rate = 5.0  # Higher growth rate than Scenario A\n",
    "    future_compute = base * np.exp(growth_rate * years_from_2025) * (1 + noise)\n",
    "    plt.scatter(future_dates, future_compute, alpha=0.3, color='blue', label='Scenario C')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlim([pd.Timestamp('2020-01-01'),pd.Timestamp('2030-01-01')])\n",
    "\n",
    "    for exp in range(25,31):\n",
    "        plt.axhline(y=10**exp,color='gray',linestyle='--',alpha=0.6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick info\n",
    "largest_model_2021 = df[df['year'] == 2021].sort_values(by='compute', ascending=False).iloc[0]\n",
    "largest_model_name = largest_model_2021['model']\n",
    "largest_model_date = largest_model_2021['date']\n",
    "largest_model_compute = largest_model_2021['compute']\n",
    "\n",
    "print(f\"Largest model in 2021: {largest_model_name}, Date: {largest_model_date}, Compute: {largest_model_compute}\")\n",
    "\n",
    "largest_model_2020 = df[df['year'] == 2020].sort_values(by='compute', ascending=False).iloc[0]\n",
    "largest_model_name_2020 = largest_model_2020['model']\n",
    "largest_model_date_2020 = largest_model_2020['date']\n",
    "largest_model_compute_2020 = largest_model_2020['compute']\n",
    "\n",
    "print(f\"Largest model in 2020: {largest_model_name_2020}, Date: {largest_model_date_2020}, Compute: {largest_model_compute_2020}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils + global params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#util funcs cell\n",
    "def norm_exp_func(x,a,b,k):\n",
    "    norm_factor=(1/k)*(np.exp(k*b)-np.exp(k*a))\n",
    "    return (1/norm_factor)*np.exp(k*x)\n",
    "\n",
    "def sample_from_exp_dist(a,b,k,spacing='linear'):\n",
    "    x=np.linspace(a,b,10000) #might need to change this to logspace\n",
    "    dx=x[1]-x[0] #differnt if logspace\n",
    "    pdf=norm_exp_func(x,a,b,k=k)\n",
    "    assert(round(sum(pdf*dx),2)==1), print(sum(pdf*dx)) #sanity check on probability dist\n",
    "    prob_dist=pdf*dx\n",
    "    prob_dist=prob_dist/np.sum(prob_dist) #ensure that sums exactly to 1 for use with np.random.choice\n",
    "\n",
    "    return np.random.choice(x,p=prob_dist)\n",
    "\n",
    "\n",
    "def decimal_year_to_date(decimal_year):\n",
    "    if isinstance(decimal_year, pd.Series):\n",
    "        return decimal_year.apply(lambda x: decimal_year_to_date(x))\n",
    "    if isinstance(decimal_year, (list, np.ndarray)):\n",
    "        return [decimal_year_to_date(x) for x in decimal_year]\n",
    "    year = int(decimal_year)\n",
    "    remainder = decimal_year-year\n",
    "    days_in_year = 366 if pd.Timestamp(year,1,1).is_leap_year else 365\n",
    "    days = int(remainder*days_in_year)\n",
    "    return pd.Timestamp(year,1,1)+pd.Timedelta(days=days)\n",
    "\n",
    "\n",
    "def alloc_ratio_to_alloc(alloc_ratio):\n",
    "    #note - assumes alloc_rati = train/inf\n",
    "    alloc_ratio=np.array(alloc_ratio)\n",
    "    train_alloc=alloc_ratio/(1+alloc_ratio)\n",
    "    inference_alloc=1-train_alloc\n",
    "    return train_alloc, inference_alloc\n",
    "\n",
    "def round_dates(dates, freq):\n",
    "    #from Claude; unsure how this works\n",
    "    if freq == '6M':\n",
    "        return dates.map(lambda d: d.replace(day=1) + pd.offsets.MonthEnd(6 - (d.month - 1) % 6))\n",
    "    elif freq == '3M':\n",
    "        return dates.map(lambda d: d.replace(day=1) + pd.offsets.MonthEnd(3 - (d.month - 1) % 3))\n",
    "    elif freq == '1M':\n",
    "        return dates.map(lambda d: d.replace(day=1) + pd.offsets.MonthEnd(1))\n",
    "    elif freq == '1Y':\n",
    "        return dates.map(lambda d: d.replace(month=1, day=1) + pd.offsets.YearEnd())\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported frequency\")\n",
    "\n",
    "def truncated_normal(mean,std_dev,min_lms=None,max_lms=None,size=1):\n",
    "    if min_lms is None: min_lms=mean-3*std_dev\n",
    "    if max_lms is None: max_lms=mean+3*std_dev\n",
    "    samples = np.random.normal(mean, std_dev, size)\n",
    "    return np.clip(samples, min_lms, max_lms) \n",
    "\n",
    "\n",
    "n_simulations = 100 #for bootstrappng, sampling parameters etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training compute spending extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total AI relevant compute extrapolations\n",
    "\n",
    "### PARAMETERS \n",
    "#extrap\n",
    "AI2027_EXTRAP=True\n",
    "method_choice=\"method 2027\" #['linear extrapolation', 'method 2027']\n",
    "\n",
    "hist_alloc=1/1\n",
    "hist_alloc_multiplier=1+(1/hist_alloc)\n",
    "FIXED_ALLOCATION=True\n",
    "fixed_alloc=40/60\n",
    "DYNAMIC_ALLOCATION=False #inference scaling continues improving\n",
    "assert(FIXED_ALLOCATION+DYNAMIC_ALLOCATION)==1\n",
    "pred_alloc_dict = {\n",
    "        2024: 40/60,\n",
    "        2025: 30/70,\n",
    "        2026: 30/70,\n",
    "        2027: 20/80,\n",
    "        2028: 20/80,\n",
    "    }\n",
    "\n",
    "g_global_AI_compute_mean=2.25\n",
    "g_AI_workload_share_mean=1.5 #assuming AI_compute_usage/AI_compute_capacity = const - 3.0 gets the two superposed!\n",
    "g_total = g_global_AI_compute_mean + g_AI_workload_share_mean\n",
    "g_stdev=0.0 #get more reasonable values by fixing rather than computing from historical data\n",
    "\n",
    "###DATA STRUCTURE INIT\n",
    "LOG_AGGREGATE_COMPUTE_DATA={}\n",
    "\n",
    "###PLOT\n",
    "PLOT=True\n",
    "\n",
    "\n",
    "for sim in range(n_simulations):\n",
    "    LOG_AGGREGATE_COMPUTE_DATA[sim] = {}\n",
    "\n",
    "    year_grouped_df=df.groupby(df['date'][df['date']>'2010-01-01'].dt.year)\n",
    "    aggregate_compute=year_grouped_df['compute'].sum()\n",
    "    log_aggregate_compute=np.log10(aggregate_compute)\n",
    "\n",
    "    recent_years = log_aggregate_compute[log_aggregate_compute.index.isin(range(2020,df.year.max()+1))]\n",
    "    recent_log_compute_dict = {int(k): v for k, v in recent_years.items()}\n",
    "\n",
    "\n",
    "    if 1: #do historical data\n",
    "        LOG_AGGREGATE_COMPUTE_DATA[sim]['historical aggregate training compute'] = {int(k): v for k, v in log_aggregate_compute.items()}\n",
    "        LOG_AGGREGATE_COMPUTE_DATA[sim]['historical aggregate total compute'] = {int(k): v+np.log10(hist_alloc_multiplier) for k, v in log_aggregate_compute.items()}\n",
    "\n",
    "    if AI2027_EXTRAP:\n",
    "        training_usage_2023 = 10**log_aggregate_compute.get(2023)\n",
    "        total_usage_2023 = 2 * training_usage_2023\n",
    "\n",
    "        AI_compute_usage={}\n",
    "        for idx,year in enumerate(range(2024, 2029)):\n",
    "            AI_compute_usage[year] = total_usage_2023 * (g_total+np.random.normal(0,g_stdev)) ** (idx + 1)\n",
    "\n",
    "        log_aggregate_compute_predictions_dict = {year: np.log10(compute) for year, compute in AI_compute_usage.items()}\n",
    "        LOG_AGGREGATE_COMPUTE_DATA[sim]['Total-method 2027'] = log_aggregate_compute_predictions_dict\n",
    "\n",
    "\n",
    "    #do allocations\n",
    "    if 1: \n",
    "        if FIXED_ALLOCATION:\n",
    "            train_alloc,inference_alloc=alloc_ratio_to_alloc(alloc_ratio=fixed_alloc)\n",
    "            LOG_AGGREGATE_COMPUTE_DATA[sim]['aggregate training compute'] = {year: val + np.log10(train_alloc) for year, val in LOG_AGGREGATE_COMPUTE_DATA[sim][f\"Total-{method_choice}\"].items()}\n",
    "            LOG_AGGREGATE_COMPUTE_DATA[sim]['aggregate inference compute'] = {year: val + np.log10(inference_alloc) for year, val in LOG_AGGREGATE_COMPUTE_DATA[sim][f\"Total-{method_choice}\"].items()}\n",
    "\n",
    "        if DYNAMIC_ALLOCATION:\n",
    "            train_alloc_dict = {}\n",
    "            inference_alloc_dict = {}\n",
    "\n",
    "            for year, val in LOG_AGGREGATE_COMPUTE_DATA[sim][f'Total-{method_choice}'].items():\n",
    "                alloc_ratio=pred_alloc_dict.get(year,1.0)\n",
    "                train_alloc, inference_alloc = alloc_ratio_to_alloc(alloc_ratio=alloc_ratio)\n",
    "                train_alloc_dict[year] = val + np.log10(train_alloc)\n",
    "                inference_alloc_dict[year] = val + np.log10(inference_alloc)\n",
    "\n",
    "            LOG_AGGREGATE_COMPUTE_DATA[sim]['aggregate training compute'] = train_alloc_dict\n",
    "            LOG_AGGREGATE_COMPUTE_DATA[sim]['aggregate inference compute'] = inference_alloc_dict\n",
    "\n",
    "\n",
    "if PLOT:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot extrapolations for each method\n",
    "    colors = {\n",
    "        'historical aggregate training compute': 'blue',\n",
    "        'historical aggregate total compute': 'cyan',\n",
    "        'Total-method 2027': 'purple',\n",
    "        'aggregate training compute': 'green',\n",
    "        'aggregate inference compute': 'red',\n",
    "    }\n",
    "    markers = {\n",
    "        'historical aggregate training compute': 'o',\n",
    "        'historical aggregate total compute': 'v',\n",
    "        'Total-method 2027': 's',\n",
    "        'aggregate training compute': '.',\n",
    "        'aggregate inference compute': 'x',\n",
    "    }\n",
    "\n",
    "    for method in colors.keys():\n",
    "        all_sim_values = defaultdict(list)\n",
    "        \n",
    "        for sim in range(n_simulations):\n",
    "            predictions = LOG_AGGREGATE_COMPUTE_DATA[sim].get(method, {})\n",
    "            for year, value in predictions.items():\n",
    "                all_sim_values[year].append(value)\n",
    "        \n",
    "        years = sorted(all_sim_values.keys())\n",
    "        medians = [np.median(all_sim_values[year]) for year in years]\n",
    "        lower_bounds = [np.percentile(all_sim_values[year], 5) for year in years]\n",
    "        upper_bounds = [np.percentile(all_sim_values[year], 95) for year in years]\n",
    "\n",
    "        plt.plot(years, medians, label=f'{method} (Median)', color=colors[method], marker=markers[method])\n",
    "        if \"historical\" not in method:\n",
    "            plt.fill_between(years, lower_bounds, upper_bounds, color=colors[method], alpha=0.2, label=f'{method} (90% CI)')\n",
    "\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Log10(Compute) [FLOP]')\n",
    "    plt.title(f'Compute Usage Over Time')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xticks(np.arange(min(log_aggregate_compute.index), 2030, 2))\n",
    "\n",
    "    # Plot compute allocations for different tau values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    years = sorted(pred_alloc_dict.keys())\n",
    "    alloc_ratios = [pred_alloc_dict[y] for y in years]\n",
    "\n",
    "    train_allocs = []\n",
    "    inference_allocs = []\n",
    "    if FIXED_ALLOCATION:\n",
    "        train_allocs, inference_allocs = alloc_ratio_to_alloc(np.ones(years.__len__()) * fixed_alloc)\n",
    "    if DYNAMIC_ALLOCATION:\n",
    "        train_allocs, inference_allocs = alloc_ratio_to_alloc(np.array(list(pred_alloc_dict.values())))\n",
    "\n",
    "    plt.plot(years, train_allocs, 'g-', label='Training Allocation')\n",
    "    plt.plot(years, inference_allocs, 'r-', label='Inference Allocation')\n",
    "    plt.scatter(years, train_allocs, color='green', marker='o')\n",
    "    plt.scatter(years, inference_allocs, color='red', marker='o')\n",
    "    plt.ylim(0, 1)\n",
    "\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Allocation Fraction')\n",
    "    plt.title('Compute Allocations Over Time')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xticks(years)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit allocations for fit years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get compute_alloc fits\n",
    "fit_years=np.arange(2020,df.year.max()+1)\n",
    "pred_years = np.arange(2024,2029)\n",
    "FIT_DATA={year:None for year in fit_years}\n",
    "constraint_point=(1,1)\n",
    "filter_thresholds=1e-20 #ignore models smaller than this\n",
    "\n",
    "\n",
    "logging.info('Fitting f_M coefficients')\n",
    "\n",
    "for idx,year in enumerate(fit_years):\n",
    "    total_compute=aggregate_compute[aggregate_compute.index==year].values\n",
    "    datapoints_year=df[df['date'].dt.year==year]['compute']\n",
    "    mean_log_compute=np.log10(datapoints_year).mean()\n",
    "    largest_model=datapoints_year.max()\n",
    "    smallest_model=datapoints_year.min()\n",
    "    norm_factor_total=total_compute[0]\n",
    "\n",
    "    #ms\n",
    "    sorted_computes=np.sort(datapoints_year)\n",
    "    norm_sorted_computes=sorted_computes/largest_model\n",
    "    \n",
    "    #cum_alloc\n",
    "    cumsum=np.cumsum(sorted_computes)\n",
    "    norm_cum_alloc=cumsum/norm_factor_total\n",
    "\n",
    "    #catg_alloc (derived from cum_alloc)\n",
    "    norm_catg_alloc = np.diff(norm_cum_alloc)\n",
    "    residual_catg_alloc = 1-np.sum(norm_catg_alloc)\n",
    "    norm_catg_alloc = np.concatenate((np.array([residual_catg_alloc]),norm_catg_alloc))\n",
    "\n",
    "    #store data \n",
    "    FIT_DATA[year]={\n",
    "    'compute':sorted_computes,\n",
    "    'cumulative_sum':cumsum,\n",
    "    'norm_factor_total':norm_factor_total,\n",
    "    'largest_model':largest_model,\n",
    "    'norm_smallest_model':smallest_model/largest_model,\n",
    "    'norm_cum_alloc fits':None,\n",
    "    'norm_catg_alloc fits':None,\n",
    "            }\n",
    "    \n",
    "    #fit data\n",
    "    X = np.log10(norm_sorted_computes).reshape(-1, 1)\n",
    "    y = np.log10(norm_cum_alloc)\n",
    "    X_trans,y_trans=X-constraint_point[0],y-constraint_point[1]\n",
    "    reg_cum_alloc = linear_model.LinearRegression(fit_intercept=False).fit(X_trans, y_trans) #forcing X-a,y-b to go through (0,0) means X,y goes through (a,b)\n",
    "    FIT_DATA[year]['cum_alloc_fits'] = [reg_cum_alloc.coef_[0], reg_cum_alloc.intercept_]\n",
    "\n",
    "\n",
    "    X,y = np.log10(norm_sorted_computes).reshape(-1,1),np.log10(norm_catg_alloc).reshape(-1,1)\n",
    "    reg_catg_alloc = linear_model.LinearRegression(fit_intercept=True).fit(X,y) #we claim that there is a linear relationship between log(norm_computes) and log(catg_alloc)\n",
    "    FIT_DATA[year]['catg_alloc_fits'] = [reg_catg_alloc.coef_[0][0], reg_catg_alloc.intercept_[0]]\n",
    "    FIT_DATA[year]['norm_catg_alloc']=norm_catg_alloc\n",
    "\n",
    "if 0:\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10, 8))\n",
    "    axes = [ax1, ax2, ax3, ax4]\n",
    "    \n",
    "    for i, year in enumerate(fit_years):\n",
    "        if year in FIT_DATA:\n",
    "            data = FIT_DATA[year]\n",
    "            norm_sorted_computes = data['compute'] / data['largest_model']\n",
    "            norm_catg_alloc = data['norm_catg_alloc']\n",
    "            m, b = data['catg_alloc_fits']\n",
    "            \n",
    "            axes[i].scatter(norm_sorted_computes, norm_catg_alloc, marker='x', s=50, label=f'Data points')\n",
    "            log_catg_alloc = m * np.log10(norm_sorted_computes) + b #the relationship in log space\n",
    "            y_fit = 10**(log_catg_alloc)\n",
    "            axes[i].plot(norm_sorted_computes, y_fit, label=f'Fit (m={m:.2f}, b={b:.2f})')\n",
    "\n",
    "            # Create extrapolation points from smallest x value back to near 0\n",
    "            min_x = np.min(data['compute'] / data['largest_model'])\n",
    "            x_extrap = np.logspace(-10, np.log10(min_x), 100)\n",
    "            log_catg_alloc = m * np.log10(x_extrap) + b\n",
    "            y_extrap = 10**(log_catg_alloc)\n",
    "            \n",
    "            axes[i].plot(x_extrap, y_extrap, '--', alpha=0.5)\n",
    "            \n",
    "            axes[i].set_xlabel('Normalized Sorted Computes')\n",
    "            axes[i].set_ylabel('Normalized Category Allocations')\n",
    "            axes[i].set_title(f'Year {year}')\n",
    "            axes[i].set_xscale('log')\n",
    "            axes[i].set_yscale('log')\n",
    "            axes[i].legend()\n",
    "            axes[i].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    # Log debug - Print cum_alloc_fits for all years\n",
    "    logging.info(\"cum_alloc_fits for each year:\")\n",
    "    cum_alloc_coeffs = FIT_DATA[year]['cum_alloc_fits']\n",
    "    catg_alloc_coeffs = FIT_DATA[year]['catg_alloc_fits']\n",
    "    logging.info(f\"Year {year}: cum_alloc_fits - slope={cum_alloc_coeffs[0]:.4f}, intercept={cum_alloc_coeffs[1]:.4f}\")\n",
    "    logging.info(f\"Year {year}: catg_alloc_fits - slope={catg_alloc_coeffs[0]:.4f}, intercept={catg_alloc_coeffs[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate compute samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##generate compute samples\n",
    "\n",
    "np.random.seed(None) #no seeding\n",
    "import logging\n",
    "\n",
    "\n",
    "##allocation fits\n",
    "ALLOC_FIT_TYPE='cumulative' #[cumulative, categorical]\n",
    "POINT_CUM_ALLOC_PARAMS=False #takes mean of historical datas\n",
    "DISTRIBUTION_CUM_ALLOC_PARAMS=True\n",
    "grad_cum_alloc_min, grad_cum_alloc_max = 1.00, 1.00 #for setting up uncertainty modelling\n",
    "assert(POINT_CUM_ALLOC_PARAMS+DISTRIBUTION_CUM_ALLOC_PARAMS)==1, \"Only one of DEFAULT_CUM_ALLOC_PARAMS or CUSTOM_CUM_ALLOC_PARAMS can be True\"\n",
    "\n",
    "DEFAULT_CATG_ALLOC_PARAMS=True\n",
    "CUSTOM_CATG_ALLOC_PARAMS=False\n",
    "custom_catg_alloc_params = (1,-0.5)\n",
    "\n",
    "assert(DEFAULT_CATG_ALLOC_PARAMS+CUSTOM_CATG_ALLOC_PARAMS)==1, \"Only one of DEFAULT_CATG_ALLOC_PARAMS or CUSTOM_CATG_ALLOC_PARAMS can be True\"\n",
    "\n",
    "#IMPORTANT PARAMETER - largest model share\n",
    "LMS_SAMPLING=\"uniform\"\n",
    "assert LMS_SAMPLING in ['gaussian', 'uniform']\n",
    "largest_model_share_mean,lms_stddev,min_lms,max_lms=0.3, 0.1,0.05,0.50\n",
    "\n",
    "#min m sampling\n",
    "min_norm_m_min,min_norm_m_max = 1e-8, 1e-6 #wacky variable names\n",
    "\n",
    "#n_catg setting (higher the better, up to a point where delta M gets too small)\n",
    "n_catgs = 20\n",
    "\n",
    "PLOT_KDES=False\n",
    "PLOT_SCATTER=True\n",
    "\n",
    "\n",
    "all_years=np.concatenate([fit_years, pred_years.astype(int).ravel()])\n",
    "COMPUTE_SAMPLE_DATA = {sim: {int(year): {} for year in all_years} for sim in range(n_simulations)} #init data structure \n",
    "\n",
    "for sim in range(n_simulations):\n",
    "\n",
    "    for year in all_years:\n",
    "        #get total compute\n",
    "        if year in fit_years:\n",
    "            log_agg_training_compute = LOG_AGGREGATE_COMPUTE_DATA[sim][\"historical aggregate training compute\"][year]\n",
    "        if year in pred_years:\n",
    "            log_agg_training_compute = LOG_AGGREGATE_COMPUTE_DATA[sim][\"aggregate training compute\"][year]\n",
    "        agg_training_compute = 10**log_agg_training_compute \n",
    "\n",
    "        #set largest model that year \n",
    "        if LMS_SAMPLING=='gaussian':\n",
    "            norm_largest_model = truncated_normal(mean=largest_model_share_mean,std_dev=lms_stddev,min_lms=min_lms,max_lms=max_lms, size=1)[0]\n",
    "        elif LMS_SAMPLING=='uniform':\n",
    "            norm_largest_model = np.random.uniform(min_lms, max_lms)\n",
    "\n",
    "        largest_model = norm_largest_model * agg_training_compute\n",
    "        assert largest_model <= 0.5*agg_training_compute, print(f\"Year: {year}, Largest Model: {largest_model}, Total Training Compute: {agg_training_compute}\")\n",
    "\n",
    "        #sample smallest model that year\n",
    "        min_norm_m = 10**(np.random.uniform(np.log10(min_norm_m_min),np.log10(min_norm_m_max)))\n",
    "\n",
    "        # model sizes (as fraction of largest_model)\n",
    "        norm_ms = np.logspace(np.log10(min_norm_m), np.log10(1.0), num=n_catgs)\n",
    "        log_norm_ms = np.log10(norm_ms)\n",
    "\n",
    "\n",
    "        assert ALLOC_FIT_TYPE in ['cumulative','categorical']\n",
    "\n",
    "        #generate compute bin allocations (catg_alloc)\n",
    "        if ALLOC_FIT_TYPE=='cumulative':\n",
    "            if POINT_CUM_ALLOC_PARAMS:\n",
    "                grad_cum_alloc = np.mean([FIT_DATA[year]['cum_alloc_fits'][0] for year in FIT_DATA.keys()])\n",
    "                int_cum_alloc = np.mean([FIT_DATA[year]['cum_alloc_fits'][1] for year in FIT_DATA.keys()])\n",
    "            elif DISTRIBUTION_CUM_ALLOC_PARAMS:\n",
    "                grad_cum_alloc, int_cum_alloc = np.random.uniform(grad_cum_alloc_min,grad_cum_alloc_max), 0\n",
    "            else:\n",
    "                raise ValueError(\"Invalid choice of cumulative alloc params\")\n",
    "\n",
    "\n",
    "            log_cum_alloc = grad_cum_alloc*log_norm_ms + int_cum_alloc\n",
    "            cum_alloc = 10**log_cum_alloc\n",
    "            catg_alloc = np.diff(cum_alloc)\n",
    "            assert abs(np.sum(catg_alloc) - 1) < 1e-5, f\"Sum of category allocations {np.sum(catg_alloc)} not equal to 1\"\n",
    "\n",
    "            residual_catg_alloc = 1-np.sum(catg_alloc)\n",
    "            catg_alloc = np.concatenate(([residual_catg_alloc],catg_alloc))\n",
    "\n",
    "        if ALLOC_FIT_TYPE=='categorical':\n",
    "            if DEFAULT_CATG_ALLOC_PARAMS:\n",
    "                grad_catg_alloc, int_catg_alloc = 1, np.log10(norm_largest_model) #grad_catg_alloc shouldn't be a choice. \n",
    "            elif CUSTOM_CATG_ALLOC_PARAMS:\n",
    "                grad_catg_alloc, int_catg_alloc = custom_catg_alloc_params\n",
    "            else:\n",
    "                raise ValueError(\"Invalid choice of catg_alloc_params\")\n",
    "            if year in FIT_DATA.keys():\n",
    "                grad_catg_alloc, int_catg_alloc = FIT_DATA[year]['catg_alloc_fits']\n",
    "\n",
    "            #compute category allocations\n",
    "            log_catg_alloc = grad_catg_alloc*log_norm_ms + int_catg_alloc # 1 = grad_catg_alloc\n",
    "            catg_alloc = 10**log_catg_alloc\n",
    "            \n",
    "            assert abs(np.sum(catg_alloc) - 1) < 1e-5, f\"Sum of category allocations {np.sum(catg_alloc)} not equal to 1\"\n",
    "\n",
    "        absl_ms = norm_ms*largest_model\n",
    "        absl_model_catgs = [(absl_ms[i], absl_ms[i+1]) for i in range(len(absl_ms) - 1)]\n",
    "        absl_model_catgs = [(min_norm_m*largest_model,min_norm_m*largest_model)] + absl_model_catgs\n",
    "        absl_allocs = catg_alloc * agg_training_compute\n",
    "        alloc_ub_check_var = [ctg[-1] for ctg in absl_model_catgs] < absl_allocs\n",
    "        assert(np.all(alloc_ub_check_var)), print(f'{(~alloc_ub_check_var).sum()/len(alloc_ub_check_var)*100} of alloc-ctg pairs exceed ctg_ub')\n",
    "\n",
    "\n",
    "        model_ctgs = [(norm_ms[i], norm_ms[i+1]) for i in range(len(norm_ms) - 1)]\n",
    "        model_ctgs = [(min_norm_m,min_norm_m)] + model_ctgs #for first ctg bin - we sample just the smallest model\n",
    "        ctgs_lbs, ctgs_ubs =[ctg[0] for ctg in model_ctgs], [ctg[-1] for ctg in model_ctgs] #useful vars\n",
    "\n",
    "        bin_compute_allocs = catg_alloc * agg_training_compute  # array of how much compute allocated to each bin\n",
    "\n",
    "        compute_samples_rand = []\n",
    "\n",
    "        #draw samples\n",
    "        for idx, (ctg, alloc) in enumerate(list(zip(model_ctgs, bin_compute_allocs))):\n",
    "            if idx==0: continue\n",
    "        \n",
    "\n",
    "            # set initial bounds\n",
    "            bounds = ctg\n",
    "            norm_model_bin_lb, norm_model_bin_ub = float(bounds[0]), float(bounds[1])\n",
    "            model_bin_lb, model_bin_ub = largest_model * norm_model_bin_lb, largest_model * norm_model_bin_ub  # normalising factor is total training compute\n",
    "            assert alloc > model_bin_ub\n",
    "            if alloc==0:  # skip bins which have no compute allocated to them - occurs when allocation gradient large \n",
    "                continue \n",
    "\n",
    "\n",
    "            #perform sampling \n",
    "            allocnorm_model_bin_lb, allocnorm_model_bin_ub = model_bin_lb / alloc, model_bin_ub / alloc  # this is purely just for sampling; no physical meaning\n",
    "            running_tot = 0\n",
    "            allocnormed_samples = []\n",
    "            while running_tot < 1:\n",
    "                # SAMPLE\n",
    "                sample = np.random.uniform(allocnorm_model_bin_lb, allocnorm_model_bin_ub)\n",
    "                sample = float(sample) if isinstance(sample, np.ndarray) else sample\n",
    "                assert sample <= 1 #sample should be smaller than alloc OR equal to it\n",
    "\n",
    "\n",
    "                # SUM CHECK\n",
    "                if running_tot + sample > 1:\n",
    "                    allocnormed_samples.append(1 - running_tot)\n",
    "                    running_tot = 1\n",
    "                else:\n",
    "                    allocnormed_samples.append(sample)\n",
    "                    running_tot += sample\n",
    "\n",
    "            bin_samples = alloc*np.array(allocnormed_samples) # un-normalise\n",
    "            compute_samples_rand = compute_samples_rand + (list(bin_samples)) #add to sample list\n",
    "\n",
    "            #print(f\"Number of samples drawn for model category: {len(allocnormed_samples)}\")\n",
    "\n",
    "\n",
    "        compute_samples_rand = [x for x in compute_samples_rand if x != 0]\n",
    "        print(f\"Samples drawn for sim {sim}, year {year}: {len(compute_samples_rand)}\")\n",
    "\n",
    "        COMPUTE_SAMPLE_DATA[sim][year]['samples'] = compute_samples_rand\n",
    "        COMPUTE_SAMPLE_DATA[sim][year]['date'] = [decimal_year_to_date(year + np.random.random()) for _ in compute_samples_rand]  # convert to standard pd datetime format\n",
    "        COMPUTE_SAMPLE_DATA[sim][year]['largest model'] = largest_model\n",
    "\n",
    "\n",
    "logging.debug(\"\\nNumber of samples per year:\")\n",
    "for year in pred_years.ravel():\n",
    "    logging.debug(f\"{year}: {len(COMPUTE_SAMPLE_DATA[0][year]['samples'])} samples\") #take first sim\n",
    "\n",
    "        \n",
    "\n",
    "if PLOT_KDES:\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(12, 8))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for idx, year in enumerate(pred_years):\n",
    "        all_samples = [np.log10(COMPUTE_SAMPLE_DATA[sim][year]['samples']) for sim in range(n_simulations)]\n",
    "        \n",
    "        # Define a common set of x-points for KDE evaluation\n",
    "        x_points = np.linspace(15, 30, 1000)\n",
    "        \n",
    "        # Evaluate KDE for each simulation\n",
    "        from scipy.stats import gaussian_kde\n",
    "        kde_values = [gaussian_kde(samples)(x_points) for samples in all_samples]\n",
    "        \n",
    "        # Calculate median and 90th percentile KDE values at each x-point\n",
    "        median_kde = np.median(kde_values, axis=0)\n",
    "        lower_bound_kde = np.percentile(kde_values, 5, axis=0)\n",
    "        upper_bound_kde = np.percentile(kde_values, 95, axis=0)\n",
    "        \n",
    "        # Plot the median KDE\n",
    "        axes[idx].plot(x_points, median_kde, label='Median KDE')\n",
    "        \n",
    "        # Fill between the 5th and 95th percentile KDE values\n",
    "        axes[idx].fill_between(x_points, lower_bound_kde, upper_bound_kde, alpha=0.3, label='90% CI')\n",
    "        \n",
    "        axes[idx].set_title(f'Year {year}')\n",
    "        axes[idx].set_xlabel('log compute (FLOPs)')\n",
    "        axes[idx].set_ylabel('Density')\n",
    "        axes[idx].grid(alpha=0.5)\n",
    "        axes[idx].set_xlim([15, 30])\n",
    "        axes[idx].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if PLOT_SCATTER:\n",
    "    ylims = (14, 30)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    for year in all_years:\n",
    "        if year in fit_years:\n",
    "            sample_data = COMPUTE_SAMPLE_DATA[0][year]\n",
    "            plt.scatter(sample_data['date'], np.log10(sample_data['samples']), alpha=0.2, color='blue', label='Retrodicted Samples' if year == fit_years[0] else \"\",marker='x')\n",
    "        if year in pred_years:\n",
    "            sample_data = COMPUTE_SAMPLE_DATA[0][year]\n",
    "            plt.scatter(sample_data['date'], np.log10(sample_data['samples']), alpha=0.5, label='Projected Samples' if year == pred_years[0] else \"\", color='red')\n",
    "\n",
    "    plt.scatter(df[df['year'].isin(fit_years)]['date'], np.log10(df[df['year'].isin(fit_years)]['compute']), alpha=1.0, label='Historical',marker='x')\n",
    "\n",
    "\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Log Compute (FLOPs)')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.ylim(ylims)\n",
    "    plt.yticks(np.arange(ylims[0], ylims[1], 0.5))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sim_idx=0\n",
    "# Scatter plot for observed data\n",
    "for year in range(2020, 2024):\n",
    "    observed_data = df[df['year'] == year]\n",
    "    plt.scatter(observed_data['date'], np.log10(observed_data['compute']), alpha=0.5, label=f'Observed' if year==2020 else \"\", color='blue')\n",
    "\n",
    "# Scatter plot for retrodicted data\n",
    "for year in range(2020, 2024):\n",
    "    retrodicted_data = COMPUTE_SAMPLE_DATA[sim_idx][year]\n",
    "    plt.scatter(retrodicted_data['date'], np.log10(retrodicted_data['samples']), alpha=0.5, label=f'Retrodicted' if year==2020 else \"\", color='red', marker='x')\n",
    "\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Log Compute (FLOPs)')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrodict_thresholds=[23,24,25]\n",
    "threshold_widths = [0.5,1.0,1.5]  # List of threshold widths to analyze\n",
    "period_freq = '3M'  # Can be changed to any frequency like '1Y', '3M', '4M', '6M'\n",
    "thresholds = [25, 26, 27, 28, 29]\n",
    "CI_percentiles=[10,50,90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#backtesting the absolute thresholds\n",
    "\n",
    "retrodict_years=fit_years\n",
    "\n",
    "#observed\n",
    "# Create DataFrame from observed counts\n",
    "df_observed = pd.DataFrame.from_dict({threshold: {year: sum(df[df['year'] == year]['compute'] > 10**threshold)\n",
    "                                                for year in retrodict_years}\n",
    "                                    for threshold in retrodict_thresholds}, \n",
    "                                    orient='index')\n",
    "df_observed.index = [f'{10**threshold:.2e}' for threshold in retrodict_thresholds]\n",
    "df_observed.index.name = 'Threshold'\n",
    "\n",
    "# Create retrodict counts dictionary\n",
    "retrodict_counts = {year: {threshold: [] for threshold in retrodict_thresholds} for year in retrodict_years}\n",
    "\n",
    "for sim, sim_data in COMPUTE_SAMPLE_DATA.items():\n",
    "    for year, year_data in sim_data.items():\n",
    "        if year in retrodict_years:\n",
    "            for threshold in retrodict_thresholds:\n",
    "                count = (sum(x >= 10**threshold for x in year_data['samples'])).astype(int)\n",
    "                retrodict_counts[year][threshold].append(count)\n",
    "\n",
    "# Calculate percentiles for each year and threshold\n",
    "\n",
    "retrodict_percentile_counts = {year: {percentile: [] for percentile in CI_percentiles} for year in retrodict_years}\n",
    "for year in retrodict_years:\n",
    "    for threshold in retrodict_thresholds:\n",
    "        for percentile in CI_percentiles:\n",
    "            percentile_count = (np.percentile(retrodict_counts[year][threshold], percentile)).astype(int)\n",
    "            retrodict_percentile_counts[year][percentile].append(percentile_count)\n",
    "\n",
    "dfs_retrodict = {}\n",
    "for percentile in CI_percentiles:\n",
    "    dfs_retrodict[percentile] = pd.DataFrame(\n",
    "        {year: retrodict_percentile_counts[year][percentile] for year in retrodict_years},\n",
    "        index=[f'{10**t:.2e}' for t in retrodict_thresholds]\n",
    "    )\n",
    "    dfs_retrodict[percentile].index.name = 'Threshold'\n",
    "\n",
    "# Take cumulative sum across years for both dataframes\n",
    "df_observed_cumulative = df_observed.cumsum(axis=1)\n",
    "dfs_retrodict_cumulative = {percentile: df.cumsum(axis=1) for percentile, df in dfs_retrodict.items()}\n",
    "\n",
    "\n",
    "# Create dataframe with observed and retrodicted values for each percentile\n",
    "combined_df = pd.DataFrame(index=df_observed_cumulative.index)\n",
    "\n",
    "for year in df_observed_cumulative.columns:\n",
    "    combined_df[year] = [f\"{obs} ({','.join(str(x) for x in ret)})\" for obs, ret in zip(\n",
    "        df_observed_cumulative[year],\n",
    "        zip(*[dfs_retrodict_cumulative[percentile][year] for percentile in CI_percentiles])\n",
    "    )]\n",
    "\n",
    "display(combined_df)\n",
    "# Calculate the difference between observed and retrodicted values for each percentile\n",
    "difference_df = pd.DataFrame(index=df_observed_cumulative.index)\n",
    "\n",
    "for year in df_observed_cumulative.columns:\n",
    "    differences = []\n",
    "    for obs, *rets in zip(df_observed_cumulative[year], \n",
    "                         *[dfs_retrodict_cumulative[percentile][year] for percentile in CI_percentiles]):\n",
    "        differences.append(f\"{obs-rets[0]}, {obs-rets[1]}, {obs-rets[2]}\")\n",
    "    difference_df[year] = differences\n",
    "\n",
    "display(difference_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## frontier counts\n",
    "\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Group data into specified periods\n",
    "df['period'] = round_dates(df['date'], period_freq)\n",
    "df['log_compute'] = np.log10(df['compute'])\n",
    "\n",
    "frontier_counts = {}\n",
    "\n",
    "for year in fit_years:\n",
    "    year_filtered_df = df[df['date'].dt.year == year]\n",
    "    frontier_counts[year] = {}\n",
    "    for width in threshold_widths:\n",
    "        width_year_counts = 0\n",
    "        for idx, period in enumerate(sorted(year_filtered_df['period'].unique())):\n",
    "            largest_model = df[df['period'] < period]['compute'].max()  # get largest model before this period\n",
    "            period_data = df[df.period == period]\n",
    "            within_threshold_condition = ((np.log10(largest_model) - np.log10(period_data['compute'])) <= width) & ((np.log10(largest_model) - np.log10(period_data['compute'])) > 0)\n",
    "            above_frontier_condition = period_data['compute'] > largest_model\n",
    "            count = within_threshold_condition.sum() + above_frontier_condition.sum()\n",
    "            width_year_counts += count\n",
    "        frontier_counts[year][width] = width_year_counts\n",
    "\n",
    "# Calculate frontier counts for each percentile\n",
    "sample_frontier_counts = {year: {width: [] for width in threshold_widths} for year in fit_years}\n",
    "\n",
    "for sim, sim_data in COMPUTE_SAMPLE_DATA.items():\n",
    "    for year in fit_years:\n",
    "        year_data = sim_data[year]\n",
    "        year_data['period'] = round_dates(pd.to_datetime(year_data['date']), period_freq)\n",
    "        year_data['log_compute'] = np.log10(year_data['samples'])\n",
    "        \n",
    "        for width in threshold_widths:\n",
    "            width_year_counts = 0\n",
    "            for period in sorted(year_data['period'].unique()):\n",
    "                largest_model = max(np.concatenate([np.array(data['samples'])[np.array(data['date']) < period] for data in sim_data.values()]))\n",
    "                period_sample_data = np.array(year_data['samples'])[year_data['period'] == period]\n",
    "                within_threshold_condition = (np.log10(largest_model) - np.log10(period_sample_data) <= width) & (np.log10(largest_model) - np.log10(period_sample_data) > 0)\n",
    "                above_frontier_condition = period_sample_data > largest_model\n",
    "                width_year_counts += within_threshold_condition.sum() + above_frontier_condition.sum()\n",
    "            sample_frontier_counts[year][width].append(width_year_counts)\n",
    "\n",
    "# Calculate percentile counts for each year and width\n",
    "percentile_frontier_counts = {year: {width: {percentile: [] for percentile in CI_percentiles} for width in threshold_widths} for year in fit_years}\n",
    "for year in fit_years:\n",
    "    for width in threshold_widths:\n",
    "        for percentile in CI_percentiles:\n",
    "            percentile_count = (np.percentile(sample_frontier_counts[year][width], percentile)).astype(int)\n",
    "            percentile_frontier_counts[year][width][percentile] = percentile_count\n",
    "\n",
    "# Create combined dataframe with observed and retrodicted values\n",
    "combined_df = pd.DataFrame(index=threshold_widths)\n",
    "combined_df.index.name = 'width'\n",
    "\n",
    "for year in fit_years:\n",
    "    combined_df[year] = [f\"{frontier_counts[year][width]} ({','.join(str(percentile_frontier_counts[year][width][p]) for p in CI_percentiles)})\" for width in threshold_widths]\n",
    "\n",
    "display(combined_df)\n",
    "\n",
    "# Calculate differences between observed and retrodicted values\n",
    "difference_df = pd.DataFrame(index=threshold_widths)\n",
    "difference_df.index.name = 'width'\n",
    "\n",
    "for year in fit_years:\n",
    "    differences = []\n",
    "    for width in threshold_widths:\n",
    "        obs = frontier_counts[year][width]\n",
    "        rets = [percentile_frontier_counts[year][width][p] for p in CI_percentiles]\n",
    "        differences.append(f\"{obs-rets[0]}, {obs-rets[1]}, {obs-rets[2]}\")\n",
    "    difference_df[year] = differences\n",
    "\n",
    "display(difference_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## regular counts\n",
    "\n",
    "threshold_counts_all_simulations = {year: {threshold: [] for threshold in thresholds} for year in pred_years.astype(int).ravel()}\n",
    "\n",
    "# Iterate over each simulation\n",
    "for sim in range(len(COMPUTE_SAMPLE_DATA)):\n",
    "    for year, samples in COMPUTE_SAMPLE_DATA[sim].items():\n",
    "        if year in pred_years:\n",
    "            for threshold in thresholds:\n",
    "                count = sum(x >= 10**threshold for x in samples['samples'])\n",
    "                threshold_counts_all_simulations[year][threshold].append(count)\n",
    "\n",
    "# Calculate counts for each percentile in CI_percentiles\n",
    "threshold_counts_summary = {year: [] for year in pred_years.astype(int).ravel()}\n",
    "for year in pred_years.astype(int).ravel():\n",
    "    for threshold in thresholds:\n",
    "        counts = threshold_counts_all_simulations[year][threshold]\n",
    "        percentile_counts = [np.percentile(counts, p) for p in CI_percentiles]\n",
    "        threshold_counts_summary[year].append(f\"{percentile_counts[1]:.0f} ({percentile_counts[0]:.0f}-{percentile_counts[2]:.0f})\")\n",
    "\n",
    "# Create DataFrames for each percentile\n",
    "percentile_dfs = {}\n",
    "for percentile in CI_percentiles:\n",
    "    percentile_dfs[percentile] = pd.DataFrame(\n",
    "        {year: [int(round(np.percentile(threshold_counts_all_simulations[year][threshold], percentile))) \n",
    "                for threshold in thresholds] \n",
    "         for year in pred_years.astype(int).ravel()},\n",
    "        index=[f'>1e{t}' for t in thresholds]\n",
    "    )\n",
    "\n",
    "# Make cumulative across years\n",
    "percentile_dfs_cumulative = {\n",
    "    percentile: df.cumsum(axis=1) \n",
    "    for percentile, df in percentile_dfs.items()\n",
    "}\n",
    "\n",
    "# Combine into a single DataFrame\n",
    "df_combined_cumulative = pd.DataFrame()\n",
    "for year in percentile_dfs_cumulative[50].columns:\n",
    "    for idx in percentile_dfs_cumulative[50].index:\n",
    "        values = [str(percentile_dfs_cumulative[p].loc[idx, year]) for p in CI_percentiles]\n",
    "        df_combined_cumulative.loc[idx, year] = \", \".join(values)\n",
    "display(df_combined_cumulative)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frontier-connected threshold counts for samples\n",
    "\n",
    "\n",
    "\n",
    "# Generate period data for years 2024-2029 (2029 not inclusive)\n",
    "period_data = pd.date_range(start='2024-01-01', end='2029-01-01', freq=period_freq).strftime('%Y-%m-%d %H:%M:%S').tolist()\n",
    "\n",
    "frontier_counts_all_simulations = {year: {width: [] for width in threshold_widths} for year in pred_years}\n",
    "\n",
    "for sim in range(len(COMPUTE_SAMPLE_DATA)):\n",
    "    for year in pred_years:\n",
    "        year_data = COMPUTE_SAMPLE_DATA[sim][year]\n",
    "        year_data['period'] = round_dates(pd.to_datetime(year_data['date']), period_freq)\n",
    "        year_data['log_compute'] = np.log10(year_data['samples'])\n",
    "        \n",
    "        for width in threshold_widths:\n",
    "            width_year_counts = 0\n",
    "            for period in sorted(year_data['period'].unique()):\n",
    "                largest_model = max(np.concatenate([np.array(data['samples'])[np.array(data['date']) < period] for data in COMPUTE_SAMPLE_DATA[sim].values()])) #get largest model until this period\n",
    "                period_sample_data = np.array(year_data['samples'])[year_data['period'] == period] #get models released in this period\n",
    "                within_threshold_condition = (np.log10(largest_model) - np.log10(period_sample_data) <= width) & (np.log10(largest_model) - np.log10(period_sample_data) > 0) #0 condition makes sure we don't catch models larger than frontier\n",
    "                above_frontier_condition  = period_sample_data > largest_model\n",
    "                count = within_threshold_condition.sum() + above_frontier_condition.sum() #how many models released this period within thresholds of largest model seen so far.\n",
    "                width_year_counts += count\n",
    "            frontier_counts_all_simulations[year][width].append(width_year_counts)\n",
    "\n",
    "\n",
    "\n",
    "# Create DataFrames for each percentile\n",
    "frontier_percentile_dfs = {}\n",
    "for percentile in CI_percentiles:\n",
    "    frontier_percentile_dfs[percentile] = pd.DataFrame(\n",
    "        {year: [int(round(np.percentile(frontier_counts_all_simulations[year][width], percentile)))\n",
    "                for width in threshold_widths]\n",
    "         for year in pred_years},\n",
    "        index=[f'Within {width} OOM' for width in threshold_widths]\n",
    "    )\n",
    "\n",
    "# Combine into a single DataFrame\n",
    "df_frontier_combined = pd.DataFrame()\n",
    "for year in frontier_percentile_dfs[50].columns:\n",
    "    for idx in frontier_percentile_dfs[50].index:\n",
    "        values = [str(frontier_percentile_dfs[p].loc[idx, year]) for p in CI_percentiles]\n",
    "        df_frontier_combined.loc[idx, year] = \", \".join(values)\n",
    "display(df_frontier_combined)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sci_comp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
