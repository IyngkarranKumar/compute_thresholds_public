{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import scipy.optimize as optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy example for exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLL_from_data(lambda_,data):\n",
    "    log_pdf = np.log(lambda_) - lambda_*data\n",
    "    log_likelihood = np.sum(log_pdf)\n",
    "    return -log_likelihood\n",
    "\n",
    "\n",
    "def NLL_from_pdf(pdf):\n",
    "    log_pdf = np.log(pdf)\n",
    "    log_likelihood = np.sum(log_pdf)\n",
    "    return -log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "lambda_ = 3.0\n",
    "size=100\n",
    "data = stats.expon.rvs(scale=1/lambda_,size=size) #draw 'size' datapoints from expon dist with given parameter\n",
    "pdf = stats.expon.pdf(data,scale=1/lambda_) #calculate probs of the datapoints\n",
    "\n",
    "print(NLL_from_data(lambda_=lambda_,data=data),NLL_from_pdf(pdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#data gives the arguments to be fixed\n",
    "#minimise call expects that the first argument is one to be optimised!\n",
    "p0=[1.0]\n",
    "bounds = [(1e-6,None)]\n",
    "options = {'maxiter':1000}\n",
    "est_1 = (optimize.minimize(NLL_from_data,x0=p0,args=(data,),method='L-BFGS-B',bounds=bounds,options=options)).x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truncated exponential fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#taken from 'normed fit data' in other file\n",
    "DATA = [np.array([8.94813851e-01, 1.05365097e-01, 0, 0,\n",
    "        0, 0]),\n",
    " np.array([7.14377891e-01, 2.14385034e-01, 7.15299320e-02, 0,\n",
    "        0, 0]),\n",
    " np.array([6.55267360e-01, 2.06996136e-01, 1.38031332e-01, 0,\n",
    "        0, 0])]\n",
    "\n",
    "years = ['23-24', '24-25', '25-26', '26-27', '27-28', '28-29']\n",
    "mapped_years = np.arange(1,len(years)+1) #this x range is quite arbitrary\n",
    "assert len(years)==len(mapped_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discret_exp_dist(lambda_,start=0,end=1,bin_width=0.1):\n",
    "    n_bins = int(((end-start)/bin_width)) #number of values in pmf\n",
    "    res=n_bins*100 #100 pdf values for each bin\n",
    "    dx = (end-start)/res\n",
    "    data = np.linspace(start,end,res)\n",
    "    pdf = stats.expon.pdf(data,scale=1/lambda_)\n",
    "    pmf = np.zeros(n_bins)\n",
    "\n",
    "    for i in range(n_bins):\n",
    "        stt_idx = int((i*res)/n_bins)\n",
    "        end_idx = int((((i+1)/n_bins)*res))\n",
    "        prob_mass = np.sum(pdf[stt_idx:end_idx]*dx) #integrate\n",
    "        pmf[i]=prob_mass\n",
    "\n",
    "    return pmf\n",
    "\n",
    "\n",
    "def truncated_exp_dist_pdf(lambda_,t,start=0,stop=1,size=100):\n",
    "    '''\n",
    "    Generate a truncated exponential distribution (continous)\n",
    "    '''\n",
    "    data = np.linspace(start=start,stop=stop,num=size)\n",
    "    threshold_idx = int((t/(stop-start))*size)\n",
    "    data_t = data[:threshold_idx]\n",
    "\n",
    "    expon_pdf_t = stats.expon.pdf(x=data_t,scale=1/lambda_) #pdf from start -> threshold\n",
    "    norm_factor = stats.expon.cdf(t,scale=1/lambda_) - stats.expon.cdf(start,scale=1/lambda_)\n",
    "    truncated_pdf = expon_pdf_t/norm_factor\n",
    "    \n",
    "    rem_pdf = np.zeros(len(data)-len(data_t))\n",
    "\n",
    "    full_pdf = np.concatenate([truncated_pdf,rem_pdf])\n",
    "\n",
    "    return data,full_pdf\n",
    "\n",
    "def truncated_exp_dist_pmf(pdf,data,t,bin_width=0.1):\n",
    "\n",
    "    first_zero_idx = np.where(pdf==0)[0][0]\n",
    "    start,stop=data[0],data[-1]\n",
    "\n",
    "    #ensure that bins do not straddle non-zero part of pmf and zero part\n",
    "    div = (t-start)/bin_width\n",
    "    assert div%1==0 \n",
    "\n",
    "    bin_lbs = np.arange(start,stop,bin_width)\n",
    "    bin_ubs = bin_lbs+bin_width\n",
    "    bin_mps = (bin_lbs+bin_ubs)/2\n",
    "\n",
    "    n_bins = int((stop-start)/bin_width)\n",
    "    res = len(pdf) #number of pdf values\n",
    "    dx = (stop-start)/res\n",
    "    pmf = np.zeros(n_bins)\n",
    "\n",
    "    for i in range(n_bins):\n",
    "        stt_idx = int((i*res)/n_bins)\n",
    "        end_idx = int((((i+1)/n_bins)*res))\n",
    "        prob_mass = np.sum(pdf[stt_idx:end_idx]*dx)\n",
    "        pmf[i]=prob_mass\n",
    "    \n",
    "    return bin_mps,pmf\n",
    "\n",
    "def truncated_exp_dist_pmf_2(pdf,data,t,bin_centers,bin_width):\n",
    "    bin_lbs = bin_centers-(bin_width/2)\n",
    "    bin_ubs = bin_centers+(bin_width/2)\n",
    "\n",
    "    dx=np.round(np.mean(np.diff(data)),np.log10(len(data)));print(dx)\n",
    "\n",
    "\n",
    "    pmf = np.zeros(len(bin_centers))\n",
    "\n",
    "\n",
    "\n",
    "start=0\n",
    "stop=1\n",
    "lambda_=1.0\n",
    "t=0.5\n",
    "bin_width=0.1\n",
    "bin_centers = np.linspace(0.1,1.1,len(years)) #mapped years\n",
    "\n",
    "data,pdf = truncated_exp_dist_pdf(lambda_=lambda_,t=t,start=start,stop=stop)\n",
    "bin_mps,pmf = truncated_exp_dist_pmf(pdf,data,t,bin_width=bin_width)\n",
    "\n",
    "#plot\n",
    "plt.bar(bin_mps,pmf,width=bin_width,edgecolor='black')\n",
    "plt.xticks(bin_mps)\n",
    "plt.xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bin_width=0.2\n",
    "bin_centers = np.linspace(0.1,1.1,len(years)) #mapped years\n",
    "bin_lbs = bin_centers-(bin_width/2)\n",
    "bin_ubs = bin_centers+(bin_width/2)\n",
    "bin_bounds = np.array(list(zip(bin_lbs,bin_ubs)))\n",
    "\n",
    "true_pmf = DATA[2]\n",
    "threshold_bin = bin_centers[(np.where(true_pmf==0)[0][0])]\n",
    "threshold = threshold_bin-(bin_width/2) #states where pdf should go to 0\n",
    "\n",
    "\n",
    "start=0\n",
    "stop=2\n",
    "lambda_=4.5\n",
    "t=threshold\n",
    "size=1000\n",
    "data,pdf = truncated_exp_dist_pdf(lambda_=lambda_,t=t,start=start,stop=stop,size=size)\n",
    "dx=np.round(np.mean(np.diff(data)),int(np.log10(len(data)))) #assuming data is of for 10^n\n",
    "\n",
    "assert(np.round(sum(pdf*dx),1)==1) #check that prob mass sums to 1\n",
    "\n",
    "\n",
    "pred_pmf = np.zeros(len(bin_centers))\n",
    "\n",
    "for idx,bin_bound in enumerate(bin_bounds):\n",
    "    lb,ub=bin_bound\n",
    "    idx_a=np.argmin(np.abs(data-lb))\n",
    "    idx_b=np.argmin(np.abs(data-ub)); print(idx_a,idx_b)\n",
    "    sliced_pdf = pdf[idx_a:idx_b]\n",
    "    prob_mass = np.sum(pdf[idx_a:idx_b]*dx)\n",
    "    pred_pmf[idx]=prob_mass\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "ax.bar(bin_centers,true_pmf,width=bin_width,edgecolor='black',label='true pmf',alpha=0.6)\n",
    "ax.bar(bin_centers,pred_pmf,width=bin_width,edgecolor='black',label='pred pmf',alpha=0.6)\n",
    "ax.set_xticks(bin_centers)\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "start=0.1 #start at 0.1 just to see pmf on a bar chart easier\n",
    "stop=1.1\n",
    "mapped_years = np.linspace(start,stop,len(years))\n",
    "\n",
    "def MSE_fit(lambda_,t,probs):\n",
    "    '''\n",
    "    We pass (t,probs) and search over lambda_\n",
    "    '''\n",
    "\n",
    "def NLL(lambda_,t,data):\n",
    "    '''\n",
    "    We are passing (t,data) and need to search over lambda\n",
    "    '''\n",
    "    return None\n",
    "\n",
    "def compute_predicted_pmf(lambda_,t):\n",
    "    predicted_pdf = truncated_exp_dist_pdf(lambda_=lambda_,\n",
    "                                t=t,start=0,stop=2,size=1000) #generate truncated pdf\n",
    "    \n",
    "    predicted_pmf = None\n",
    "\n",
    "def MSE_loss(true_pmf):\n",
    "    predicted_pmf = None\n",
    "    return np.mean((predicted_pmf-true_pmf)**2)\n",
    "    \n",
    "#for 2022 data\n",
    "true_pmf = DATA[0]\n",
    "year_threshold_idx = np.where(true_pmf==0)[0][0]\n",
    "year_t=years[year_threshold_idx]\n",
    "mapped_year_t = mapped_years[year_threshold_idx]\n",
    "\n",
    "\n",
    "initial_params = [1.0]\n",
    "result = minimize()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
