{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def half_year_bin(date):\n",
    "    #CHATGPT generated\n",
    "\n",
    "    if date.month <= 6:\n",
    "        return f'{date.year}-H1'\n",
    "    else: \n",
    "        return f'{date.year}-H2'\n",
    "\n",
    "def year_bin(date):\n",
    "    return date.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '/Users/iyngkarrankumar/Documents/Misc/Tracking models/data/all_systems.csv'\n",
    "DATA = pd.read_csv(csv_path)\n",
    "start_year = 2017\n",
    "DATA['Publication date'] = pd.to_datetime(DATA['Publication date'])\n",
    "DATA = DATA[DATA['Publication date'] > f'{start_year}-01-01'] #data filtering\n",
    "\n",
    "bin_type = 'year'\n",
    "if bin_type=='year':\n",
    "    DATA['Publication bin'] = DATA['Publication date'].apply(year_bin)\n",
    "elif bin_type=='half year':\n",
    "    DATA['Publication bin'] = DATA['Publication date'].apply(half_year_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_DATA = DATA.dropna(subset=['Training compute (FLOP)'])\n",
    "compute_DATA['log10 Training compute'] = np.log10(compute_DATA['Training compute (FLOP)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FLOP breakdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Takeaway from the Bin_fractions dataframe below: The frontier bin and the following bin (top four OOMs) carry all of the aggregate compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#booleans\n",
    "REMOVE_2024 = False\n",
    "DOUBLE_2024 = True #just assume second half of 2024 is a copy of the first half of 2024\n",
    "\n",
    "years = sorted(list(DATA['Publication bin'].unique()))\n",
    "\n",
    "if REMOVE_2024:\n",
    "    years.pop()\n",
    "\n",
    "min_FLOP = 15\n",
    "max_FLOP = 26\n",
    "FLOP_step = 2 \n",
    "FLOP_bin_low = np.arange(min_FLOP,max_FLOP,FLOP_step)\n",
    "FLOP_bin_high = FLOP_bin_low + 2\n",
    "FLOP_bins = list(zip(FLOP_bin_low,FLOP_bin_high))\n",
    "\n",
    "#initialising data structs\n",
    "AGGREGATE_FLOP = []\n",
    "BIN_fractions = pd.DataFrame(columns=[str(f_bin) for f_bin in FLOP_bins])\n",
    "\n",
    "\n",
    "for year in years:\n",
    "    year_filtered_df = compute_DATA[compute_DATA['Publication bin']==year]\n",
    "\n",
    "    total_executed_FLOP = year_filtered_df['Training compute (FLOP)'].sum()\n",
    "    total_executed_log_FLOP = np.log10(total_executed_FLOP)\n",
    "\n",
    "    YEAR_AGGREGATE_FLOP = []\n",
    "    for idx,FLOP_bin in enumerate(FLOP_bins):\n",
    "\n",
    "        FLOP_filtering_condition = (year_filtered_df['log10 Training compute'] > FLOP_bin[0]) & (year_filtered_df['log10 Training compute'] < FLOP_bin[-1])\n",
    "        FLOP_filtered_df = year_filtered_df[FLOP_filtering_condition]\n",
    "\n",
    "        year_bin_aggregate_FLOP = (FLOP_filtered_df['Training compute (FLOP)']).sum() #total FLOP of all training runs in year Y and bin B\n",
    "        YEAR_AGGREGATE_FLOP.append(year_bin_aggregate_FLOP)\n",
    "\n",
    "        if year==2024 and DOUBLE_2024: #double all entries for 2024\n",
    "            YEAR_AGGREGATE_FLOP = [2*elem for elem in YEAR_AGGREGATE_FLOP]\n",
    "\n",
    "\n",
    "    year_aggregate_FLOP = sum(YEAR_AGGREGATE_FLOP) #total FLOP of all runs in year Y\n",
    "\n",
    "\n",
    "    BIN_fractions.loc[year] = np.round((YEAR_AGGREGATE_FLOP/year_aggregate_FLOP)*100,2)\n",
    "    AGGREGATE_FLOP.append(year_aggregate_FLOP)\n",
    "\n",
    "log10_AGGREGATE_FLOP = np.log10(AGGREGATE_FLOP)\n",
    "\n",
    "plt.plot(years,log10_AGGREGATE_FLOP)\n",
    "plt.ylabel('Aggregate training FLOP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extrapolating\n",
    "end_year = 2028\n",
    "\n",
    "if REMOVE_2024:\n",
    "    future_years = np.arange(2024,end_year+1,1)\n",
    "else:\n",
    "    future_years = np.arange(2025,end_year+1,1)\n",
    "    \n",
    "\n",
    "assert len(log10_AGGREGATE_FLOP)==len(years)\n",
    "\n",
    "#prep data\n",
    "years_arr = np.array(years).reshape(-1,1)\n",
    "future_years_arr = future_years.reshape(-1,1)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(years_arr,log10_AGGREGATE_FLOP)\n",
    "aggregate_FLOP_predictions = model.predict(future_years_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "\n",
    "ax.scatter(years,log10_AGGREGATE_FLOP,label='Observed')\n",
    "ax.scatter(future_years,aggregate_FLOP_predictions,label='Predictions')\n",
    "ax.set_ylabel('Aggregate training FLOP ($10^X$)')\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
