{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import scipy.optimize as optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in and process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/save_file.xlsx')\n",
    "print(df['compute'].isna().sum())\n",
    "df.replace('',np.nan,inplace=True)\n",
    "print(df['compute'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Add columns and sort out 'poss 1e23/1e25'\n",
    "\n",
    "# Reset the ones we've set\n",
    "df.loc[~df[\"compute\"].isna(), \"poss1e23\"] = np.nan\n",
    "df.loc[~df[\"compute\"].isna(), \"poss1e25\"] = np.nan\n",
    "\n",
    "# Set some temporary placeholder values\n",
    "# TODO: revisit\n",
    "# df.loc[(df[\"poss1e25\"] == \"checked\"), \"compute\"] = 1.01e25  # placeholder\n",
    "# df.loc[((df[\"poss1e23\"] == \"checked\") & (df[\"poss1e25\"] != \"checked\")), \"compute\"] = 1.01e23  # placeholder\n",
    "\n",
    "# We want to handle these leading models manually via the above compute estimates.\n",
    "assert df[(df[\"poss1e25\"] == \"checked\") & (df[\"compute\"].isna())].size == 0\n",
    "\n",
    "# We sample 1e23-1e25 models with unknown compute from the existing empirical distribution.\n",
    "# TODO: revisit\n",
    "poss1e23 = ((df[\"poss1e23\"] == \"checked\") & (df[\"poss1e25\"] != \"checked\"))\n",
    "df.loc[poss1e23, \"compute\"] = df[(df[\"compute\"] >= 1e23) & (df[\"compute\"] < 1e25)][\"compute\"].sample(poss1e23.sum(), random_state=0).values\n",
    "\n",
    "\n",
    "\n",
    "##\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "df['compute'] = pd.to_numeric(df['compute'],errors='coerce')\n",
    "df[\"log_compute\"] = np.log10(df[\"compute\"])\n",
    "\n",
    "df[\"date_float\"] = df[\"date\"].dt.year + df[\"date\"].dt.month/12\n",
    "\n",
    "df = df.sort_values(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## exp counts fit\n",
    "\n",
    "from scipy.stats import t\n",
    "\n",
    "def exp_pred_counts(years,year_counts,future_years,alpha=0.10):\n",
    "    mapped_years = np.arange(0,len(year_counts)).astype('float')\n",
    "\n",
    "    def exp_fit(x,a,b):\n",
    "        return a*np.exp(b*x)\n",
    "    \n",
    "    popt,pcov = optimize.curve_fit(exp_fit,mapped_years.astype(float),year_counts.values.astype(float))\n",
    "    pred_counts = exp_fit(future_years-years[0],*popt).astype(int) \n",
    "\n",
    "    #calculatiing confidence bounds\n",
    "    #assuming log normal uncertainty, 90% CI\n",
    "    pred_counts_fit = exp_fit(mapped_years,*popt)\n",
    "    log_pred_counts_fit = np.log(pred_counts_fit)\n",
    "    log_obs_counts = np.log(year_counts.values.astype(float))\n",
    "    residuals = log_pred_counts_fit - log_obs_counts #we're calculating residuals of log counts \n",
    "    SEP = np.sqrt(np.sum(residuals**2)/(len(year_counts-2)))\n",
    "\n",
    "\n",
    "    alpha = alpha #90% conf interval\n",
    "    dof = len(year_counts) - 2 #apparenlty for linear function the dof is n-2\n",
    "    crit_t_value = stats.t.ppf(1-alpha/2,dof)\n",
    "    pred_delta = crit_t_value*SEP \n",
    "\n",
    "    years_all = np.concatenate([years,future_years])\n",
    "    preds_all = np.concatenate([pred_counts_fit,pred_counts])\n",
    "    log_pred_UB = np.log(preds_all)+pred_delta\n",
    "    log_pred_LB = np.log(preds_all)-pred_delta\n",
    "    pred_counts_UB = np.exp(log_pred_UB)\n",
    "    pred_counts_LB = np.exp(log_pred_LB)\n",
    "\n",
    "    return years_all,preds_all,pred_counts_UB,pred_counts_LB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exponential counts fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2017-01-01'\n",
    "print(len(df))\n",
    "df_date_filtered = df[df['date']>start_date]\n",
    "print(len(df_date_filtered))\n",
    "\n",
    "REMOVE_2024=True\n",
    "\n",
    "df_date_filtered['year'] = df_date_filtered['date'].dt.year\n",
    "year_counts = df_date_filtered['year'].value_counts().sort_index()\n",
    "future_years = np.arange(2024,2029)\n",
    "\n",
    "if REMOVE_2024: year_counts = year_counts.loc[2017:2023]\n",
    "\n",
    "years = year_counts.index.to_numpy(dtype=float)\n",
    "mapped_years = np.arange(0,len(year_counts)).astype('float')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_fit(x,a,b):\n",
    "    return a*np.exp(b*x)\n",
    "\n",
    "from scipy import optimize\n",
    "\n",
    "\n",
    "popt,pcov = optimize.curve_fit(exp_fit,mapped_years.astype(float),year_counts.values.astype(float))\n",
    "pred_counts = exp_fit(future_years-years[0],*popt).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.plot(years,year_counts,label='obs',color='red')\n",
    "ax.plot(future_years,pred_counts,label='pred',color='tab:blue')\n",
    "\n",
    "ax.grid(True,alpha=0.6)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_counts_fit = exp_fit(mapped_years,*popt)\n",
    "\n",
    "log_pred_counts_fit = np.log(pred_counts_fit)\n",
    "log_obs_counts = np.log(year_counts.values.astype(float))\n",
    "residuals = log_pred_counts_fit - log_obs_counts #we're calculating residuals of log counts\n",
    "SEP = np.sqrt(np.sum(residuals**2)/(len(year_counts-2)))\n",
    "\n",
    "\n",
    "alpha = 0.10 #90% conf interval\n",
    "dof = len(year_counts) - 2 #apparenlty for linear function the dof is n-2\n",
    "from scipy.stats import t\n",
    "crit_t_value = stats.t.ppf(1-alpha/2,dof)\n",
    "pred_delta = crit_t_value*SEP \n",
    "\n",
    "\n",
    "years_all = np.concatenate([years,future_years])\n",
    "preds_all = np.concatenate([pred_counts_fit,pred_counts])\n",
    "log_pred_UB = np.log(preds_all)+pred_delta\n",
    "log_pred_LB = np.log(preds_all)-pred_delta\n",
    "pred_UB = np.exp(log_pred_UB)\n",
    "pred_LB = np.exp(log_pred_LB)\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(10,6))\n",
    "ax.plot(years_all,preds_all,label='pred',color='tab:blue')\n",
    "ax.plot(years,year_counts.values,label='obs',color='tab:red')\n",
    "ax.fill_between(years_all,pred_LB,pred_UB,color='gray',alpha=0.2,label='90% CI')\n",
    "ax.set_title('Predicted model counts with 90% CI')\n",
    "\n",
    "ax.set_xticks(years_all)\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "def exp_pred_counts(years,year_counts,future_years):\n",
    "    mapped_years = np.arange(0,len(year_counts)).astype('float')\n",
    "\n",
    "    def exp_fit(x,a,b):\n",
    "        return a*np.exp(b*x)\n",
    "    \n",
    "    popt,pcov = optimize.curve_fit(exp_fit,mapped_years.astype(float),year_counts.values.astype(float))\n",
    "    pred_counts = exp_fit(future_years-years[0],*popt).astype(int) \n",
    "\n",
    "    #calculatiing confidence bounds\n",
    "    #assuming log normal uncertainty, 90% CI\n",
    "    pred_counts_fit = exp_fit(mapped_years,*popt)\n",
    "    log_pred_counts_fit = np.log(pred_counts_fit)\n",
    "    log_obs_counts = np.log(year_counts.values.astype(float))\n",
    "    residuals = log_pred_counts_fit - log_obs_counts #we're calculating residuals of log counts \n",
    "    SEP = np.sqrt(np.sum(residuals**2)/(len(year_counts-2)))\n",
    "\n",
    "\n",
    "    alpha = 0.10 #90% conf interval\n",
    "    dof = len(year_counts) - 2 #apparenlty for linear function the dof is n-2\n",
    "    crit_t_value = stats.t.ppf(1-alpha/2,dof)\n",
    "    pred_delta = crit_t_value*SEP \n",
    "\n",
    "    years_all = np.concatenate([years,future_years])\n",
    "    preds_all = np.concatenate([pred_counts_fit,pred_counts])\n",
    "    log_pred_UB = np.log(preds_all)+pred_delta\n",
    "    log_pred_LB = np.log(preds_all)-pred_delta\n",
    "    pred_counts_UB = np.exp(log_pred_UB)\n",
    "    pred_counts_LB = np.exp(log_pred_LB)\n",
    "\n",
    "    return years_all,preds_all,pred_counts_UB,pred_counts_LB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting KDEs and counting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy.stats import gaussian_kde,norm,linregress\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fit = None #var place holder\n",
    "mu_0 = None\n",
    "def trunc_norm_NLL(sigma): #NLL assuming we're sampling from  truncated normal \n",
    "    ll = norm.logpdf(data_fit.to_numpy(),mu_0,sigma) - np.log(1-norm.cdf(data_fit.to_numpy().min(),mu_0,sigma))\n",
    "    return -np.sum(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## scatter\n",
    "REMOVE_2024=True\n",
    "\n",
    "start_date = '2017-01-01'\n",
    "end_date = '2024-01-01'\n",
    "\n",
    "if REMOVE_2024:\n",
    "    df_date_filtered = df[(df['date']>start_date) & (df['date']<end_date)]\n",
    "else: \n",
    "    df_date_filtered = df[df['date']>start_date]\n",
    "\n",
    "df_date_filtered['year'] = df_date_filtered['date'].dt.year\n",
    "df_date_filtered = df_date_filtered[~df_date_filtered['log_compute'].isna()] #remove Nan compute rows\n",
    "\n",
    "#lin regress for means\n",
    "grouped_df_mean = df_date_filtered.groupby(['year'])['log_compute'].mean().reset_index()\n",
    "\n",
    "X = grouped_df_mean['year'].values\n",
    "y = grouped_df_mean['log_compute'].values\n",
    "\n",
    "mean_log_compute_model = LinearRegression()\n",
    "mean_log_compute_model.fit(X.reshape(-1,1),y)\n",
    "\n",
    "\n",
    "\n",
    "#plot\n",
    "fig_S,ax_S=plt.subplots()\n",
    "#sns.regplot(data=df_date_filtered,x='date_float',y='log_compute',color='tab:blue')\n",
    "sns.stripplot(x='year',y='log_compute',data=df_date_filtered,jitter=True,ax=ax_S)\n",
    "sns.regplot(x=pd.Categorical(df_date_filtered['year']).codes,y='log_compute',data=df_date_filtered,scatter=False,ax=ax_S)\n",
    "ymin,ymax = ax_S.get_yticks().min(),ax_S.get_yticks().max()\n",
    "ax_S.set_yticks(np.arange(ymin,ymax,1))\n",
    "#ax_S.axhline(y=23.7)\n",
    "\n",
    "#2024 regression line at ~23.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2017-01-01'\n",
    "print(len(df))\n",
    "df_date_filtered = df[df['date']>start_date]\n",
    "print(len(df_date_filtered))\n",
    "df_date_filtered['year'] = df_date_filtered['date'].dt.year\n",
    "\n",
    "PLOT=True\n",
    "FIT_2024_RT = True\n",
    "mean_2024 = mean_log_compute_model.predict(np.array(2024).reshape(-1,1))[0]\n",
    "\n",
    "\n",
    "start_year=2017\n",
    "end_year = 2024 \n",
    "\n",
    "years = np.arange(start_year,end_year+1)\n",
    "log_compute_min = 10\n",
    "log_compute_max = 28\n",
    "x = np.linspace(log_compute_min,log_compute_max,1000)\n",
    "\n",
    "\n",
    "nrows = 4\n",
    "ncols = 2\n",
    "fig,axs = plt.subplots(nrows=nrows,ncols=ncols,figsize=(8,10))\n",
    "axs_ravel = np.ravel(axs)\n",
    "MEAN,VAR= [],[]\n",
    "\n",
    "\n",
    "\n",
    "for idx,year in enumerate(years):\n",
    "    try:ax=axs_ravel[idx]\n",
    "    except: pass\n",
    "\n",
    "\n",
    "    year_filtered_df = df_date_filtered[df_date_filtered['year']==year]\n",
    "    nan_frac =(year_filtered_df['log_compute'].isna().sum())/len(year_filtered_df)\n",
    "    year_filtered_df = year_filtered_df[~year_filtered_df['log_compute'].isna()]\n",
    "    log_compute_data = year_filtered_df['log_compute']\n",
    "\n",
    "    if year==2024:\n",
    "        #find sigma from right tail\n",
    "        if FIT_2024_RT:\n",
    "            RT_filtered_data = log_compute_data[log_compute_data>mean_2024]\n",
    "            #print(len(RT_filtered_data)/len(log_compute_data)) #sanity check\n",
    "            init_sigma = np.std(RT_filtered_data)\n",
    "            data_fit = RT_filtered_data\n",
    "            mu_0 = mean_2024\n",
    "            sigma = (minimize(trunc_norm_NLL,[init_sigma])).x\n",
    "\n",
    "            mean,sigma=mu_0,sigma #variable renaming\n",
    "            MEAN.append(mean)\n",
    "            VAR.append(sigma[0]**2)\n",
    "\n",
    "    #find means in standard way\n",
    "    else: \n",
    "        mean,std = np.mean(log_compute_data),np.std(log_compute_data)\n",
    "        MEAN.append(mean); VAR.append(std**2)\n",
    "        kde = gaussian_kde(log_compute_data)\n",
    "        norm_pdf = norm.pdf(x,mean,std)\n",
    "\n",
    "\n",
    "    sns.kdeplot(log_compute_data,fill=True,ax=ax,label='KDE')\n",
    "    ax.plot(x,norm_pdf,label='norm fit')\n",
    "    ax.set_title(f'{year},nan_frac={np.round(nan_frac,1)}')\n",
    "\n",
    "\n",
    "##predicted pdfs\n",
    "CONST_VAR=True\n",
    "tmp_year = 2021\n",
    "\n",
    "if CONST_VAR:\n",
    "    idx_tmp_year = np.where(years==tmp_year)[0][0]\n",
    "    dist_var = np.mean(VAR[idx_tmp_year:])\n",
    "else: \n",
    "    dist_var = None #not yet implemened\n",
    "\n",
    "future_years = np.arange(2024,2028+1)\n",
    "pred_means = mean_log_compute_model.predict(future_years.reshape(-1,1))\n",
    "\n",
    "fig,axs=plt.subplots(nrows=3,ncols=2,figsize=(8,10))\n",
    "axs_ravel = np.ravel(axs)\n",
    "x_ = np.linspace(15,35)\n",
    "\n",
    "for idx,year in enumerate(future_years):\n",
    "    ax=axs_ravel[idx]\n",
    "    norm_pdf = norm.pdf(x_,pred_means[idx],dist_var)\n",
    "    ax.plot(norm_pdf)\n",
    "\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "#if not PLOT: plt.close()\n",
    "\n",
    "##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Full workflow\n",
    "\n",
    "\n",
    "CONST_VAR = True #take variance from year y\n",
    "tmp_year = 2021\n",
    "\n",
    "years = np.arange(2017,2023+1)\n",
    "future_years = np.arange(2024,2028+1)\n",
    "\n",
    "#model number\n",
    "start_date = '2017-01-01'\n",
    "df_date_filtered = df[df['date']>start_date]\n",
    "df_date_filtered['year'] = df_date_filtered['date'].dt.year\n",
    "year_counts = df_date_filtered['year'].value_counts().sort_index()\n",
    "year_counts = year_counts.loc[2017:2023]\n",
    "\n",
    "years_all,pred_counts,pred_counts_UB,pred_counts_LB = exp_pred_counts(years,year_counts,future_years)\n",
    "\n",
    "if CONST_VAR:\n",
    "    idx_tmp_year = np.where(years==tmp_year)[0][0]\n",
    "    dist_var = np.mean(VAR[idx_tmp_year:])\n",
    "else: \n",
    "    dist_var = None #not yet implemened\n",
    "\n",
    "\n",
    "threshold_count = 0\n",
    "threshold = 25\n",
    "x=np.linspace(22,stop=40,num=1000)\n",
    "for idx,year in enumerate(future_years):\n",
    "    fmt_year = np.array(year).reshape(-1,1)\n",
    "    mean,var = mean_log_compute_model.predict(fmt_year),dist_var\n",
    "    threshold_cdf = 1-norm.cdf(threshold,mean,var) #probability of a model being in [threshold, +inf]\n",
    "    n_models_threshold = pred_counts[idx]*threshold_cdf\n",
    "    threshold_count += n_models_threshold\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
