<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url(https://themes.googleusercontent.com/fonts/css?kit=Dq22Kp-Y5EhP9839Op-RwWN5WIfn_5nKk5GvUsHyJO6bbLOLVs1vtt8ixj684v8zVI5S-YaLE4g0uJgXl0JCqwmmnEZTmeutOJXSdu-FdPs);ul.lst-kix_lrglgln45zbb-7{list-style-type:none}ul.lst-kix_lrglgln45zbb-6{list-style-type:none}ol.lst-kix_vj6rxrp3izri-2.start{counter-reset:lst-ctn-kix_vj6rxrp3izri-2 0}ul.lst-kix_lrglgln45zbb-8{list-style-type:none}.lst-kix_vj6rxrp3izri-7>li{counter-increment:lst-ctn-kix_vj6rxrp3izri-7}.lst-kix_vj6rxrp3izri-2>li{counter-increment:lst-ctn-kix_vj6rxrp3izri-2}ul.lst-kix_46k1qzu5stp6-0{list-style-type:none}ol.lst-kix_vj6rxrp3izri-6.start{counter-reset:lst-ctn-kix_vj6rxrp3izri-6 0}ul.lst-kix_rbsqzpr8hbg5-7{list-style-type:none}ul.lst-kix_rbsqzpr8hbg5-8{list-style-type:none}.lst-kix_vj6rxrp3izri-8>li{counter-increment:lst-ctn-kix_vj6rxrp3izri-8}ul.lst-kix_46k1qzu5stp6-7{list-style-type:none}ul.lst-kix_rbsqzpr8hbg5-3{list-style-type:none}ul.lst-kix_46k1qzu5stp6-8{list-style-type:none}ul.lst-kix_rbsqzpr8hbg5-4{list-style-type:none}ul.lst-kix_46k1qzu5stp6-5{list-style-type:none}ul.lst-kix_rbsqzpr8hbg5-5{list-style-type:none}ul.lst-kix_46k1qzu5stp6-6{list-style-type:none}.lst-kix_vj6rxrp3izri-1>li{counter-increment:lst-ctn-kix_vj6rxrp3izri-1}ul.lst-kix_rbsqzpr8hbg5-6{list-style-type:none}ul.lst-kix_46k1qzu5stp6-3{list-style-type:none}ul.lst-kix_46k1qzu5stp6-4{list-style-type:none}.lst-kix_rbsqzpr8hbg5-0>li:before{content:"\0025cf   "}ul.lst-kix_rbsqzpr8hbg5-0{list-style-type:none}ul.lst-kix_46k1qzu5stp6-1{list-style-type:none}ul.lst-kix_rbsqzpr8hbg5-1{list-style-type:none}ul.lst-kix_46k1qzu5stp6-2{list-style-type:none}ul.lst-kix_rbsqzpr8hbg5-2{list-style-type:none}.lst-kix_vj6rxrp3izri-3>li{counter-increment:lst-ctn-kix_vj6rxrp3izri-3}ol.lst-kix_vj6rxrp3izri-1{list-style-type:none}ol.lst-kix_vj6rxrp3izri-0{list-style-type:none}.lst-kix_vj6rxrp3izri-0>li{counter-increment:lst-ctn-kix_vj6rxrp3izri-0}ol.lst-kix_vj6rxrp3izri-8.start{counter-reset:lst-ctn-kix_vj6rxrp3izri-8 0}.lst-kix_lrglgln45zbb-4>li:before{content:"\0025cb   "}ol.lst-kix_vj6rxrp3izri-5.start{counter-reset:lst-ctn-kix_vj6rxrp3izri-5 0}.lst-kix_46k1qzu5stp6-0>li:before{content:"\0025cf   "}.lst-kix_lrglgln45zbb-5>li:before{content:"\0025a0   "}.lst-kix_46k1qzu5stp6-1>li:before{content:"\0025cb   "}.lst-kix_lrglgln45zbb-6>li:before{content:"\0025cf   "}ol.lst-kix_vj6rxrp3izri-5{list-style-type:none}ul.lst-kix_lrglgln45zbb-3{list-style-type:none}.lst-kix_lrglgln45zbb-7>li:before{content:"\0025cb   "}ol.lst-kix_vj6rxrp3izri-4{list-style-type:none}ul.lst-kix_lrglgln45zbb-2{list-style-type:none}ol.lst-kix_vj6rxrp3izri-3{list-style-type:none}ul.lst-kix_lrglgln45zbb-5{list-style-type:none}ol.lst-kix_vj6rxrp3izri-2{list-style-type:none}ul.lst-kix_lrglgln45zbb-4{list-style-type:none}ol.lst-kix_vj6rxrp3izri-8{list-style-type:none}.lst-kix_vj6rxrp3izri-6>li{counter-increment:lst-ctn-kix_vj6rxrp3izri-6}ol.lst-kix_vj6rxrp3izri-7{list-style-type:none}ul.lst-kix_lrglgln45zbb-1{list-style-type:none}.lst-kix_lrglgln45zbb-8>li:before{content:"\0025a0   "}ol.lst-kix_vj6rxrp3izri-6{list-style-type:none}ul.lst-kix_lrglgln45zbb-0{list-style-type:none}.lst-kix_46k1qzu5stp6-6>li:before{content:"\0025cf   "}.lst-kix_46k1qzu5stp6-4>li:before{content:"\0025cb   "}.lst-kix_46k1qzu5stp6-8>li:before{content:"\0025a0   "}.lst-kix_46k1qzu5stp6-5>li:before{content:"\0025a0   "}.lst-kix_46k1qzu5stp6-2>li:before{content:"\0025a0   "}ol.lst-kix_vj6rxrp3izri-4.start{counter-reset:lst-ctn-kix_vj6rxrp3izri-4 0}ol.lst-kix_vj6rxrp3izri-7.start{counter-reset:lst-ctn-kix_vj6rxrp3izri-7 0}.lst-kix_46k1qzu5stp6-3>li:before{content:"\0025cf   "}.lst-kix_lrglgln45zbb-3>li:before{content:"\0025cf   "}.lst-kix_vj6rxrp3izri-5>li{counter-increment:lst-ctn-kix_vj6rxrp3izri-5}.lst-kix_vj6rxrp3izri-4>li{counter-increment:lst-ctn-kix_vj6rxrp3izri-4}.lst-kix_lrglgln45zbb-2>li:before{content:"\0025a0   "}.lst-kix_vj6rxrp3izri-0>li:before{content:"" counter(lst-ctn-kix_vj6rxrp3izri-0,decimal) ". "}ol.lst-kix_vj6rxrp3izri-1.start{counter-reset:lst-ctn-kix_vj6rxrp3izri-1 0}.lst-kix_lrglgln45zbb-1>li:before{content:"\0025cb   "}.lst-kix_46k1qzu5stp6-7>li:before{content:"\0025cb   "}.lst-kix_lrglgln45zbb-0>li:before{content:"\0025cf   "}.lst-kix_vj6rxrp3izri-4>li:before{content:"" counter(lst-ctn-kix_vj6rxrp3izri-4,lower-latin) ". "}.lst-kix_rbsqzpr8hbg5-1>li:before{content:"\0025cb   "}.lst-kix_rbsqzpr8hbg5-2>li:before{content:"\0025a0   "}.lst-kix_vj6rxrp3izri-2>li:before{content:"" counter(lst-ctn-kix_vj6rxrp3izri-2,lower-roman) ". "}.lst-kix_vj6rxrp3izri-6>li:before{content:"" counter(lst-ctn-kix_vj6rxrp3izri-6,decimal) ". "}.lst-kix_vj6rxrp3izri-1>li:before{content:"" counter(lst-ctn-kix_vj6rxrp3izri-1,lower-latin) ". "}.lst-kix_vj6rxrp3izri-5>li:before{content:"" counter(lst-ctn-kix_vj6rxrp3izri-5,lower-roman) ". "}.lst-kix_rbsqzpr8hbg5-5>li:before{content:"\0025a0   "}ol.lst-kix_vj6rxrp3izri-3.start{counter-reset:lst-ctn-kix_vj6rxrp3izri-3 0}.lst-kix_rbsqzpr8hbg5-3>li:before{content:"\0025cf   "}.lst-kix_rbsqzpr8hbg5-4>li:before{content:"\0025cb   "}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}.lst-kix_vj6rxrp3izri-3>li:before{content:"" counter(lst-ctn-kix_vj6rxrp3izri-3,decimal) ". "}ol.lst-kix_vj6rxrp3izri-0.start{counter-reset:lst-ctn-kix_vj6rxrp3izri-0 0}.lst-kix_vj6rxrp3izri-8>li:before{content:"" counter(lst-ctn-kix_vj6rxrp3izri-8,lower-roman) ". "}.lst-kix_rbsqzpr8hbg5-6>li:before{content:"\0025cf   "}.lst-kix_rbsqzpr8hbg5-7>li:before{content:"\0025cb   "}.lst-kix_rbsqzpr8hbg5-8>li:before{content:"\0025a0   "}.lst-kix_vj6rxrp3izri-7>li:before{content:"" counter(lst-ctn-kix_vj6rxrp3izri-7,lower-latin) ". "}ol{margin:0;padding:0}table td,table th{padding:0}.c26{border-right-style:solid;padding-top:0pt;border-top-width:0pt;border-right-width:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.2;border-left-width:0pt;border-top-style:solid;margin-right:22.5pt;margin-left:31.5pt;border-left-style:solid;border-bottom-width:0pt;border-bottom-style:solid;orphans:2;widows:2;text-align:center;padding-right:0pt}.c64{border-right-style:solid;padding-top:0pt;border-top-width:0pt;border-right-width:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.0;border-left-width:0pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:0pt;border-bottom-style:solid;orphans:2;widows:2;text-align:justify;padding-right:0pt;height:14pt}.c12{border-right-style:solid;padding-top:0pt;border-top-width:0pt;border-right-width:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.0;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;border-bottom-style:solid;orphans:2;widows:2;text-align:justify;padding-right:0pt;height:14pt}.c37{border-right-style:solid;padding-top:0pt;border-top-width:0pt;border-right-width:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.0;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;border-bottom-style:solid;orphans:2;widows:2;text-align:left;padding-right:0pt}.c80{border-right-style:solid;padding-top:0pt;border-top-width:0pt;border-right-width:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.0;border-left-width:0pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:0pt;border-bottom-style:solid;orphans:2;widows:2;text-align:justify;padding-right:0pt}.c8{border-right-style:solid;padding-top:0pt;border-top-width:0pt;border-right-width:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.0;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;border-bottom-style:solid;orphans:2;widows:2;text-align:center;padding-right:0pt}.c49{border-right-style:solid;padding-top:0pt;border-top-width:0pt;border-right-width:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.2;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;border-bottom-style:solid;orphans:2;widows:2;text-align:center;padding-right:0pt}.c63{border-right-style:solid;padding-top:6pt;border-top-width:6pt;border-bottom-color:#fff2cc;border-right-width:6pt;padding-left:6pt;border-left-color:#fff2cc;padding-bottom:6pt;line-height:1.0;border-right-color:#fff2cc;border-left-width:6pt;border-top-style:solid;background-color:#fff2cc;border-left-style:solid;border-bottom-width:6pt;border-top-color:#fff2cc;border-bottom-style:solid;orphans:2;widows:2;text-align:justify;padding-right:6pt}.c18{border-right-style:solid;padding-top:0pt;border-top-width:0pt;border-right-width:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.2;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;border-bottom-style:solid;orphans:2;widows:2;text-align:justify;padding-right:0pt}.c6{border-right-style:solid;padding-top:0pt;border-top-width:0pt;border-right-width:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.2;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;border-bottom-style:solid;orphans:2;widows:2;text-align:left;padding-right:0pt}.c3{border-right-style:solid;padding-top:0pt;border-top-width:0pt;border-right-width:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.2;border-left-width:0pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:0pt;border-bottom-style:solid;orphans:2;widows:2;text-align:center;padding-right:0pt}.c28{border-right-style:solid;padding-top:0pt;border-top-width:0pt;border-right-width:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.2;border-left-width:0pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:0pt;border-bottom-style:solid;orphans:2;widows:2;text-align:justify;padding-right:0pt}.c39{border-right-style:solid;padding-top:0pt;border-top-width:0pt;border-right-width:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.0;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;border-bottom-style:solid;orphans:2;widows:2;text-align:justify;padding-right:0pt}.c35{border-right-style:solid;padding-top:0pt;border-top-width:0pt;border-right-width:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.0;border-left-width:0pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:0pt;border-bottom-style:solid;orphans:2;widows:2;text-align:center;padding-right:0pt}.c66{border-right-style:solid;padding-top:0pt;border-top-width:0pt;border-right-width:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.0;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;border-bottom-style:solid;text-align:left;padding-right:0pt}.c131{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1.5pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;background-color:#fff2cc;border-left-style:solid;border-bottom-width:1pt;width:112.5pt;border-top-color:#000000;border-bottom-style:solid}.c122{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;background-color:#fff2cc;border-left-style:solid;border-bottom-width:1pt;width:112.5pt;border-top-color:#000000;border-bottom-style:solid}.c136{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;background-color:#fff2cc;border-left-style:solid;border-bottom-width:1.5pt;width:112.5pt;border-top-color:#000000;border-bottom-style:solid}.c118{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;width:48.8pt;border-top-color:#000000;border-bottom-style:solid}.c129{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1.5pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:58.5pt;border-top-color:#000000;border-bottom-style:solid}.c10{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;width:78pt;border-top-color:#000000;border-bottom-style:solid}.c11{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;width:92.2pt;border-top-color:#000000;border-bottom-style:solid}.c47{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1.5pt;width:78pt;border-top-color:#000000;border-bottom-style:solid}.c91{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;width:57.8pt;border-top-color:#000000;border-bottom-style:solid}.c99{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1.5pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:87.8pt;border-top-color:#000000;border-bottom-style:solid}.c46{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;width:78pt;border-top-color:#000000;border-bottom-style:solid}.c121{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:78pt;border-top-color:#000000;border-bottom-style:solid}.c50{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1.5pt;width:78pt;border-top-color:#000000;border-bottom-style:solid}.c149{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1.5pt;width:86.2pt;border-top-color:#000000;border-bottom-style:solid}.c125{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;width:94.5pt;border-top-color:#000000;border-bottom-style:solid}.c141{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1.5pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:48.8pt;border-top-color:#000000;border-bottom-style:solid}.c36{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;width:105.8pt;border-top-color:#000000;border-bottom-style:solid}.c25{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;width:105.8pt;border-top-color:#000000;border-bottom-style:solid}.c114{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;width:88.5pt;border-top-color:#000000;border-bottom-style:solid}.c140{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1.5pt;width:86.2pt;border-top-color:#000000;border-bottom-style:solid}.c94{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1.5pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:57.8pt;border-top-color:#000000;border-bottom-style:solid}.c20{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;width:90pt;border-top-color:#000000;border-bottom-style:solid}.c77{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;width:58.5pt;border-top-color:#000000;border-bottom-style:solid}.c130{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:95.2pt;border-top-color:#000000;border-bottom-style:solid}.c150{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1.5pt;width:95.2pt;border-top-color:#000000;border-bottom-style:solid}.c1{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:78pt;border-top-color:#000000;border-bottom-style:solid}.c9{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:86.2pt;border-top-color:#000000;border-bottom-style:solid}.c48{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;width:92.2pt;border-top-color:#000000;border-bottom-style:solid}.c4{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;width:57.8pt;border-top-color:#000000;border-bottom-style:solid}.c89{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1.5pt;width:81.8pt;border-top-color:#000000;border-bottom-style:solid}.c29{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1.5pt;width:93.6pt;border-top-color:#000000;border-bottom-style:solid}.c52{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1.5pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:93.6pt;border-top-color:#000000;border-bottom-style:solid}.c93{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;width:90pt;border-top-color:#000000;border-bottom-style:solid}.c103{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1.5pt;width:94.5pt;border-top-color:#000000;border-bottom-style:solid}.c17{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;width:94.5pt;border-top-color:#000000;border-bottom-style:solid}.c113{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;width:88.5pt;border-top-color:#000000;border-bottom-style:solid}.c107{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1.5pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:105.8pt;border-top-color:#000000;border-bottom-style:solid}.c67{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1.5pt;width:58.5pt;border-top-color:#000000;border-bottom-style:solid}.c116{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1.5pt;width:81.8pt;border-top-color:#000000;border-bottom-style:solid}.c95{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1.5pt;width:88.5pt;border-top-color:#000000;border-bottom-style:solid}.c126{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1.5pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:94.5pt;border-top-color:#000000;border-bottom-style:solid}.c45{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1.5pt;width:90pt;border-top-color:#000000;border-bottom-style:solid}.c124{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1.5pt;width:87.8pt;border-top-color:#000000;border-bottom-style:solid}.c44{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;width:93.6pt;border-top-color:#000000;border-bottom-style:solid}.c78{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1.5pt;width:95.2pt;border-top-color:#000000;border-bottom-style:solid}.c109{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1.5pt;width:105.8pt;border-top-color:#000000;border-bottom-style:solid}.c71{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;width:93.6pt;border-top-color:#000000;border-bottom-style:solid}.c92{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1.5pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:90pt;border-top-color:#000000;border-bottom-style:solid}.c127{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1.5pt;width:92.2pt;border-top-color:#000000;border-bottom-style:solid}.c143{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1.5pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:78pt;border-top-color:#000000;border-bottom-style:solid}.c144{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1.5pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:86.2pt;border-top-color:#000000;border-bottom-style:solid}.c96{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1.5pt;width:57.8pt;border-top-color:#000000;border-bottom-style:solid}.c138{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1.5pt;width:87.8pt;border-top-color:#000000;border-bottom-style:solid}.c69{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:93.6pt;border-top-color:#000000;border-bottom-style:solid}.c102{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1.5pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:88.5pt;border-top-color:#000000;border-bottom-style:solid}.c134{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1.5pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:92.2pt;border-top-color:#000000;border-bottom-style:solid}.c43{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1.5pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:78pt;border-top-color:#000000;border-bottom-style:solid}.c61{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;width:48.8pt;border-top-color:#000000;border-bottom-style:solid}.c148{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1.5pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:95.2pt;border-top-color:#000000;border-bottom-style:solid}.c100{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:87.8pt;border-top-color:#000000;border-bottom-style:solid}.c27{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;width:58.5pt;border-top-color:#000000;border-bottom-style:solid}.c88{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:81.8pt;border-top-color:#000000;border-bottom-style:solid}.c111{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1.5pt;width:48.8pt;border-top-color:#000000;border-bottom-style:solid}.c87{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1.5pt;width:541.5pt;border-top-color:#000000;border-bottom-style:solid}.c146{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1.5pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:81.8pt;border-top-color:#000000;border-bottom-style:solid}.c33{-webkit-text-decoration-skip:none;color:#1155cc;font-weight:400;text-decoration:underline;text-decoration-skip-ink:none;font-size:10pt;font-family:"Lora"}.c7{color:#353744;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:10.5pt;font-family:"Inter";font-style:normal}.c0{color:#353744;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10.5pt;font-family:"Inter";font-style:normal}.c13{color:#000000;font-weight:300;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Inter";font-style:normal}.c2{vertical-align:super;font-size:10pt;font-family:"Lora";color:#000000;font-weight:400}.c40{color:#353744;text-decoration:none;vertical-align:super;font-size:10.5pt;font-style:normal}.c55{color:#1155cc;font-weight:300;font-size:9pt;font-family:"Inter"}.c90{margin-left:-12pt;border-spacing:0;border-collapse:collapse;margin-right:auto}.c119{margin-left:-10.5pt;border-spacing:0;border-collapse:collapse;margin-right:auto}.c23{color:#000000;font-weight:500;font-size:10pt;font-family:"Inter"}.c112{margin-left:-29.6pt;border-spacing:0;border-collapse:collapse;margin-right:auto}.c5{font-size:10pt;font-family:"Lora";color:#000000;font-weight:400}.c60{border-spacing:0;border-collapse:collapse;margin-right:auto}.c151{margin-left:-16.5pt;border-spacing:0;border-collapse:collapse;margin-right:auto}.c120{margin-left:auto;border-spacing:0;border-collapse:collapse;margin-right:auto}.c21{color:#000000;font-weight:400;font-size:10pt;font-family:"Inter"}.c56{font-size:11pt;font-family:"Inter";font-weight:400}.c65{font-weight:500;font-size:11pt;font-family:"Inter"}.c117{font-size:9pt;font-family:"Lora";font-weight:400}.c51{text-decoration:none;vertical-align:baseline;font-style:italic}.c14{text-decoration:none;vertical-align:baseline;font-style:normal}.c59{font-size:9pt;font-family:"Inter";font-weight:400}.c108{font-weight:800;font-size:44pt;font-family:"Inter"}.c58{color:#353744;font-weight:400;font-family:"Arial"}.c16{font-size:10pt;font-weight:300;font-family:"Inter"}.c38{-webkit-text-decoration-skip:none;text-decoration:underline;text-decoration-skip-ink:none}.c123{font-size:19pt;font-family:"Inter";font-weight:300}.c128{color:#666666;font-weight:400;font-family:"Lora"}.c106{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c79{font-size:9pt;font-family:"Inter";font-weight:300}.c57{font-size:15pt;font-family:"Inter";font-weight:300}.c74{font-weight:700;font-family:"Arial"}.c24{color:inherit;text-decoration:inherit}.c105{padding:0;margin:0}.c83{width:33%;height:1px}.c85{font-family:"Lora";font-weight:700}.c32{font-weight:700;font-family:"Inter"}.c110{font-weight:500;font-family:"Inter"}.c137{font-weight:400;font-family:"Trebuchet MS"}.c98{background-color:#ffffff;color:#222222}.c53{vertical-align:super}.c76{height:13pt}.c54{height:11.2pt}.c132{height:18pt}.c133{color:#666666}.c135{font-size:30pt}.c145{height:14pt}.c15{height:0pt}.c72{font-size:10pt}.c101{font-weight:700}.c147{height:41.7pt}.c104{vertical-align:baseline}.c68{text-decoration:none}.c70{font-size:10.5pt}.c41{font-size:16pt}.c62{margin-right:22.5pt}.c84{height:25.4pt}.c81{vertical-align:sub}.c30{margin-left:36pt}.c115{font-size:28pt}.c22{page-break-after:avoid}.c86{font-size:11pt}.c31{color:#000000}.c34{font-size:13pt}.c73{font-style:italic}.c142{background-color:#ffffff}.c42{font-style:normal}.c139{color:#353744}.c82{height:20.9pt}.c19{height:10.5pt}.c75{margin-left:31.5pt}.c97{height:11pt}.title{padding-top:16pt;color:#353744;font-size:36pt;padding-bottom:0pt;font-family:"Arial";line-height:1.0;orphans:2;widows:2;text-align:justify}.subtitle{padding-top:0pt;color:#666666;font-size:13pt;padding-bottom:0pt;font-family:"Arial";line-height:1.0;orphans:2;widows:2;text-align:justify}li{color:#353744;font-size:10.5pt;font-family:"Arial"}p{margin:0;color:#353744;font-size:10.5pt;font-family:"Arial"}h1{padding-top:24pt;color:#353744;font-weight:700;font-size:18pt;padding-bottom:0pt;font-family:"Arial";line-height:1.0;orphans:2;widows:2;text-align:justify}h2{padding-top:16pt;color:#000000;font-weight:700;font-size:14pt;padding-bottom:0pt;font-family:"Arial";line-height:1.0;orphans:2;widows:2;text-align:justify}h3{padding-top:1.2pt;color:#353744;font-size:13pt;padding-bottom:0pt;font-family:"Arial";line-height:1.0;orphans:2;widows:2;text-align:justify}h4{padding-top:8pt;-webkit-text-decoration-skip:none;color:#666666;text-decoration:underline;font-size:11pt;padding-bottom:0pt;line-height:1.2;page-break-after:avoid;text-decoration-skip-ink:none;font-family:"Trebuchet MS";orphans:2;widows:2;text-align:justify}h5{padding-top:8pt;color:#666666;font-size:11pt;padding-bottom:0pt;font-family:"Trebuchet MS";line-height:1.2;page-break-after:avoid;orphans:2;widows:2;text-align:justify}h6{padding-top:8pt;color:#666666;font-size:11pt;padding-bottom:0pt;font-family:"Trebuchet MS";line-height:1.2;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:justify}</style></head><body class="c106 doc-content"><p class="c37 c19 title" id="h.umhg9dlpui5w"><span class="c14 c32 c115 c31"></span></p><p class="c37 title" id="h.69303wvhnlin"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(3.14rad) translateZ(0px); -webkit-transform: rotate(3.14rad) translateZ(0px); width: 821.00px; height: 1059.00px;"><img alt="" src="images/image5.png" style="width: 821.00px; height: 1089.00px; margin-left: 0.00px; margin-top: -30.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c14 c31 c108">Trends in Frontier AI Model Count</span></p><p class="c37 title" id="h.ypcm8npji0qm"><span class="c14 c32 c31 c135">A Forecast to 2028</span></p><p class="c37 title" id="h.ag19dd1hahcx"><span class="c31 c123">Iyngkarran Kumar, Sam Manning</span><hr style="page-break-before:always;display:none;"></p><p class="c39 title" id="h.yvexgvxsu4yy"><span class="c14 c32 c31 c115">Trends in Frontier AI Model Count: A Forecast to 2028</span></p><p class="c39 subtitle" id="h.mis9yonjw5mm"><span class="c31 c57">Iyngkarran Kumar, Sam Manning</span></p><h1 class="c63" id="h.k78q7paz6dkj"><span class="c14 c32 c41 c31">Abstract</span></h1><p class="c63 subtitle" id="h.pfmbcjaj7r4d"><span class="c56 c31">Governments are starting to impose requirements on AI models based on how much compute was used to train them. For example, the EU AI Act imposes requirements on providers of general-purpose AI with systemic risk, which includes systems trained using greater than 10</span><span class="c56 c53 c31">25</span><span class="c56 c31">&nbsp;floating point operations. In the United States&rsquo; AI Diffusion Framework, a training compute threshold of 10</span><span class="c56 c53 c31">26</span><span class="c56 c31">&nbsp;is used to identify &ldquo;controlled models&rdquo; which face a number of requirements. We explore how many models such training compute thresholds will capture over time. We estimate that by the end of 2028, there will be between 810-28790 foundation models exceeding the 10</span><span class="c56 c53 c31">25</span><span class="c31 c56">&nbsp;FLOP threshold put forward in the EU AI Act (90% CI), and 3740-1340 models exceeding the 10</span><span class="c56 c53 c31">26</span><span class="c56 c31">&nbsp;FLOP threshold that defines controlled models in the AI Diffusion Framework (90% CI). We also find that the number of models exceeding these absolute compute thresholds each year will increase superlinearly &ndash; that is, each successive year will see more new models captured within the threshold than the year before. Thresholds that are defined with respect to the largest training run to date (for example, such that all models within one order of magnitude of the largest training run to date are captured by the threshold) see a more stable trend, with 5-350 (90% CI) being captured by this definition each year.</span></p><h1 class="c39" id="h.dcb5bn2ynnne"><span class="c14 c32 c41 c31">1 Introduction</span></h1><p class="c18"><span class="c5">Recent years in machine learning have seen the rise of foundation models &ndash; AI systems that exhibit powerful and general-purpose capabilities. Governments across the world have started to impose requirements on the development and deployment of the most capable such systems, such as the GPT o-series</span><sup class="c5"><a href="#ftnt1" id="ftnt_ref1">[1]</a></sup><span class="c5">. In December 2023 the European Union adopted the EU AI Act, the world&rsquo;s first comprehensive legislation designed to govern the development and use of AI systems. Among other things, the Act imposes requirements on providers of general-purpose AI with systemic risk (</span><span class="c5">GPAISR</span><span class="c5">), as of August 2025, which includes systems trained using greater than 10</span><span class="c2">25</span><span class="c5">&nbsp;floating point operations (FLOP)</span><sup class="c5"><a href="#ftnt2" id="ftnt_ref2">[2]</a></sup><span class="c5">. The European Union is not the only jurisdiction to impose requirements based on </span><span class="c5"><a class="c24" href="https://www.google.com/url?q=https://arxiv.org/abs/2405.10799&amp;sa=D&amp;source=editors&amp;ust=1744328243503053&amp;usg=AOvVaw0SC4Wc1duxzuz0keaQGiIb">training compute thresholds</a></span><span class="c5">; in one of its final acts the Biden administration issued the Artificial Intelligence Diffusion Framework</span><sup class="c5"><a href="#ftnt3" id="ftnt_ref3">[3]</a></sup><span class="c5">, which as one of its key directives introduced a host of requirements on models above 10</span><span class="c2">26</span><span class="c5 c14">&nbsp;FLOP (named &ldquo;controlled models&rdquo; in the framework) with the aim of maintaining leadership in AI technology amongst the US and its allies.</span></p><p class="c18"><span class="c5">However, it is well established that the training </span><span class="c5">compute</span><span class="c5">&nbsp;used for frontier models has been growing extraordinarily quickly,</span><sup class="c5"><a href="#ftnt4" id="ftnt_ref4">[4]</a></sup><span class="c5">&nbsp;with mean model size growing by about 4-5x per year over the past decade. This has important implications for compute-based regulations such as those included in the EU AI Act and the Diffusion Framework. In April 2025, </span><span class="c33"><a class="c24" href="https://www.google.com/url?q=https://epochai.org/data/notable-ai-models&amp;sa=D&amp;source=editors&amp;ust=1744328243503940&amp;usg=AOvVaw1aLcuDkZiEf3STaovSQgPA">estimates suggest</a></span><span class="c5">&nbsp;that there are 2 publicly available models trained using more than 10</span><span class="c2">26</span><span class="c5">&nbsp;FLOP and over 20 publicly available models trained using more than 10</span><span class="c2">25</span><span class="c5 c14">&nbsp;FLOP. However, if current trends continue, these numbers may quickly grow. Governments need to take into account this growth in their AI governance efforts. By underestimating the number of models covered by their thresholds, they may fail to build sufficient regulatory capacity to implement their regulations or may impose regulatory burdens on an excessive number of actors. </span></p><p class="c18"><span class="c5">With this in mind, in the following paper we estimate the number of released models that will exceed various compute thresholds over the coming years. Extrapolating from current trends we conclude that by the end of 2028 there could be between 81-287</span><span class="c5"><a class="c24" href="#h.4ccs6ds00euy">&nbsp;models exceeding the </a></span><span class="c5">10</span><span class="c2">25</span><span class="c5"><a class="c24" href="#h.4ccs6ds00euy">&nbsp;FLOP threshold &nbsp;(90% confidence interval), and 37-134 models exceeding the </a></span><span class="c5">10</span><span class="c2">26</span><span class="c5"><a class="c24" href="#h.4ccs6ds00euy">&nbsp;FLOP threshold (90% confidence interval)</a></span><span class="c5">. We also study &ldquo;frontier-connected thresholds&rdquo; &ndash; thresholds that are defined relative to the largest training run at any one point in time rather than based on the absolute amount of training compute used &ndash; and find that in the coming years there will be between 5-30 models within 1 OOM of the largest training run that has taken place (90% CI). However our analysis has limitations resulting from </span><span class="c5"><a class="c24" href="#h.p60h7aa85z0k">selection effects in the database that we extrapolate trends from</a></span><span class="c5">, as well as uncertainty in key parameters that have </span><span class="c5">influence</span><span class="c5 c14">&nbsp;the projections. </span></p><p class="c18"><span class="c5">Importantly, our estimates do not straightforwardly translate into the number of models in scope of the EU AI Act or AI Diffusion Framework. Our numbers may provide an </span><span class="c5">overestimate</span><span class="c5">&nbsp;in that neither the EU nor the US would apply to models trained and only made available in other jurisdictions (e.g., China). Additionally, the AI Act only applies to general purpose AI - it is unclear whether image and video generation models (such as OpenAI&rsquo;s SORA or Google DeepMind&rsquo;s Imagen</span><sup class="c5"><a href="#ftnt5" id="ftnt_ref5">[5]</a></sup><span class="c5">) would count as GPAI. &nbsp;The Act may also not apply to models that were placed on the market before the relevant obligations come into force in August 2025. Further, both rules could affect the market for AI development, making it less attractive for companies to release in-scope models. If these effects occur, our analysis may end up over counting the models captured by these thresholds. At the same time, our estimates may underestimate the number of models subject to the compute-based threshold requirements. This is because the regulation could apply not only to original </span><span class="c5">GPAISR</span><span class="c5">&nbsp;developers but also to companies that modify the models</span><sup class="c5"><a href="#ftnt6" id="ftnt_ref6">[6]</a></sup><span class="c5">, for example by adding software infrastructure around the model to make an AI agent</span><sup class="c5"><a href="#ftnt7" id="ftnt_ref7">[7]</a></sup><span class="c5 c14">. Since our analysis does not account for such adaptations, the actual number of affected models could be higher than our estimates suggest. Finally it should be noted that the EU AI Office has the ability to update the threshold in both directions - as does the US Bureau of Industry and Security in the U.S. as it relates to the AI Diffusion Framework - which would have to be taken into consideration when interpreting the predictions in future years. </span></p><h1 class="c39" id="h.qiwh5xegzm2u"><span class="c14 c32 c41 c31">2 Methodology</span></h1><p class="c18"><span class="c5">Our aim is to forecast the number of models that will be released above different training compute thresholds over the next four years. To do this, we model scenarios for how the distribution of model size over training </span><span class="c5">compute</span><span class="c5 c14">&nbsp;evolves. Once these distributions are established, we can simply count the models that exceed each specific compute threshold.</span></p><h2 class="c39" id="h.jeu33gxwc6qb"><span class="c14 c32 c31 c34">2.1 Data</span></h2><p class="c18"><span class="c5">We use Epoch AI&rsquo;s </span><span class="c33"><a class="c24" href="https://www.google.com/url?q=https://epoch.ai/data/notable-ai-models-documentation%23:~:text%3DChangelog%2520Downloads%2520Acknowledgements-,Overview,and%2520future%2520of%2520artificial%2520intelligence.&amp;sa=D&amp;source=editors&amp;ust=1744328243508246&amp;usg=AOvVaw3XvApkh4E2QsMwruv2VHLB">Notable Models dataset</a></span><span class="c5">&nbsp;as the main dataset for our analysis. To our knowledge, this is the most comprehensive publicly available dataset of machine learning models available with over 450 entries of models and their estimated training compute. However, it is important to note that ML models must satisfy one of the following four criteria (the </span><span class="c5 c73">notability criteria</span><sup class="c5 c73"><a href="#ftnt8" id="ftnt_ref8">[8]</a></sup><span class="c5 c73">)</span><span class="c5 c14">&nbsp;to be included in the database:</span></p><ul class="c105 lst-kix_lrglgln45zbb-0 start"><li class="c39 c30 li-bullet-0"><span class="c5 c14">highly cited (over 1000 citations);</span></li><li class="c39 c30 li-bullet-0"><span class="c5 c14">large training cost (over $1,000,000, measured in 2023 USD);</span></li><li class="c39 c30 li-bullet-0"><span class="c5 c14">significant use (over one million monthly active users);</span></li><li class="c39 c30 li-bullet-0"><span class="c5 c14">state of the art performance (typically on a recognised ML benchmark);</span></li><li class="c39 c30 li-bullet-0"><span class="c5 c14">indisputable historical significance.</span></li></ul><p class="c18"><span class="c5">This makes the notable models dataset a strict subset of all</span><span class="c5 c73">&nbsp;machine learning models, </span><span class="c5">and the selection effect applied by the notability criteria should be accounted for when interpreting the results in this paper. In short, this selection effect biases our median estimates towards being a lower bound estimate, especially for models that are multiple orders of magnitude of training </span><span class="c5">compute</span><span class="c5">&nbsp;below frontier models</span><sup class="c5"><a href="#ftnt9" id="ftnt_ref9">[9]</a></sup><span class="c5">. For these models that are significantly smaller than the frontier models, it is also difficult to quantitatively estimate the extent to which the estimates derived from the notable models database will be lower than the actual value. However, anchoring on the full 90% prediction intervals presented in the </span><span class="c33"><a class="c24" href="#h.4ccs6ds00euy">Results</a></span><span class="c5">&nbsp;section provides </span><span class="c5 c73">some</span><span class="c5">&nbsp;insurance against the effects of this selection effect (i.e: in some cases the 95th percentile projection is likely to be closer to the actual number of models exceeding the compute threshold). The effects of the Notable Model database selection effects, and how this can be accounted for within our model are discussed in further detail in the </span><span class="c33"><a class="c24" href="#h.p60h7aa85z0k">limitations</a></span><span class="c5 c14">&nbsp;section.</span></p><p class="c18"><span class="c5">Whilst the Notable Models database contains ~450 entries with associated training compute values from 2010-2024, we fit our model based on the data from 2017-2023 (with 296 </span><span class="c5">datapoints</span><span class="c5">) to capture recent trends in the field. We do not use 2024 data to fit the model as the data is more likely to be incomplete - this is because the models tracked in the database lag behind models released by a handful of months. Visualisations of the model distribution in the dataset provide evidence in support of this, and are shown in </span><span class="c33"><a class="c24" href="#h.kzodekz7i8dh">Appendix A</a></span><span class="c5 c14">. &nbsp;</span></p><h2 class="c39" id="h.70oh9e3oara0"><span class="c14 c32 c31 c34">2.2 Allocating total compute spending across different model scales</span></h2><p class="c18"><span class="c5">We forecast the distribution of models over training </span><span class="c5">compute</span><span class="c5">&nbsp;by projecting the total amount of compute that will be spent training AI models in the coming years, and then modelling how this compute stock is distributed over models of different </span><span class="c5">size</span><span class="c5">. We choose this approach as we expect the </span><span class="c5 c73">total</span><span class="c5">&nbsp;training compute spending to be a strong and relatively simple-to-forecast constraint on model distributions (over training compute). The allocation of </span><span class="c5">compute</span><span class="c5 c14">&nbsp;to models of different sizes also exhibits a linear trend that is simple to extrapolate (discussed below). </span></p><p class="c18"><span class="c5">Note that there are alternate ways to estimate the future distribution of models over training compute; for example, one could fit a parametric distribution (e.g: a normal distribution) to historical data, extrapolate this into future years and then sample from this distribution. However we do not use this method for the following reasons: Firstly, it is unclear which parametric distributions, if any, are a good </span><span class="c33"><a class="c24" href="#h.kzodekz7i8dh">fit to historical distributions</a></span><span class="c5 c14">&nbsp;of training compute. Secondly, our approach has a more explicit focus on determining model distributions from total training compute spending - which, as mentioned above, we expect to be a strong and simple-to-forecast constraint over the next few years. </span></p><p class="c18"><span class="c5 c14">Using our approach, we project future model distributions over training compute by: </span></p><ol class="c105 lst-kix_vj6rxrp3izri-0 start" start="1"><li class="c18 c30 li-bullet-0"><span class="c5">Exponentially projecting the total </span><span class="c5">compute</span><span class="c5 c14">&nbsp;that will be used for AI workloads (both training and inference) with a median annual growth rate of roughly 4.1x. </span></li><li class="c18 c30 li-bullet-0"><span class="c5">Allocating this </span><span class="c5">compute</span><span class="c5 c14">&nbsp;with a split of 40% of compute towards model training and 60% of compute towards other uses (inference and research experiments) in 2025 and 2026, and a 30-70 allocation in 2027 and 2028. </span></li><li class="c18 c30 li-bullet-0"><span class="c5 c14">Allocating the training compute across models of different scales - i.e: models within 1 OOM of the frontier model, models within 1 and 2 OOMs of the frontier model, models within 2 and 3 OOMs of the frontier etc. - by fitting to data from 2017-2023 and assuming these allocation trends hold over the coming years. </span></li></ol><p class="c18"><span class="c5 c14">We will now discuss each of these in turn in greater detail.</span></p><p class="c18"><span class="c5 c14">We first begin by projecting the total amount of compute that will be used for AI workloads (training and inference) in the coming years. We use two sources for this. </span></p><p class="c18"><span class="c5">Firstly, we can look at historical growth rates of training </span><span class="c5">compute</span><span class="c5">&nbsp;from the Notable Models database. Doing so for the years that we fit the model (2017-2023), we find a rapid growth rate of 6.3x annually for the total training </span><span class="c5">compute</span><span class="c5">&nbsp;used to train AI models. </span><span class="c5 c73">Assuming that the historical allocation between model training and inference has stayed roughly constant (at </span><span class="c33 c73"><a class="c24" href="#h.w37fa0y8qvzs">40-60</a></span><span class="c5 c73">),</span><span class="c5 c14">&nbsp;we can generalise this to a 6.3x growth in compute used for AI workloads. </span></p><p class="c18"><span class="c5">On the other hand, Dean et al.</span><sup class="c5"><a href="#ftnt10" id="ftnt_ref10">[10]</a></sup><span class="c5">&nbsp;model the growth in compute for AI workloads as increasing at a rate of 3.4x per year. This is the compound growth rate resulting from a 2.25x increase per year of the compute stock that </span><span class="c5 c73">can</span><span class="c5">&nbsp;be used for AI workloads, and a 1.5x increase per year of the </span><span class="c5 c73">share</span><span class="c5">&nbsp;of this stock that actually is allocated to AI training and inference</span><sup class="c5"><a href="#ftnt11" id="ftnt_ref11">[11]</a></sup><span class="c5">. The 2.25x growth rate in global AI-relevant </span><span class="c5">compute</span><span class="c5">&nbsp;stocks results from a 1.35x growth rate in the physical stock of AI chips and 1.65x in chip efficiency</span><sup class="c5"><a href="#ftnt12" id="ftnt_ref12">[12]</a></sup><span class="c5 c14">. The 1.5x growth in share results from aggressive build outs of data centres by leading AI developers, financed by revenues on the order of tens of billions of dollars resulting from highly performant AI models and agents. </span></p><p class="c18"><span class="c5">Given the discrepancy between these two estimates we integrate both into our median growth rate forecast. We put more weight on the 3.4x per year increase in compute for AI workloads given the detailed analysis that leads to this figure, however we do not fully discount the rapid growth rate that has been historically observed. Specifically we give the 3.4x figure three times as much weight as the historically observed figure, but this weighting is subjective and predictions for alternative growth rates are shown in </span><span class="c33"><a class="c24" href="#h.kc72pam40q20">Appendix G</a></span><span class="c5">. Applying this weighting between the two growth rates leads to a median growth rate of the AI workload stock (i.e: the stock of </span><span class="c5">compute</span><span class="c5 c14">&nbsp;used for AI training and inference) of 4.1x per year. To account for uncertainty in the actual annual growth rate of compute for AI workloads, we add noise to the median growth rate, drawn from a normal distribution with mean of 0 and standard deviation of 0.5. </span></p><p class="c18"><span class="c5">Next, we model (a) how the AI compute stock is allocated between training and inference and (b) how the total training compute is allocated across models of different sizes. In this analysis we project two scenarios for part (a) &ndash; one in which the allocation remains the same as previous years, and another in which we see an increasing fraction of compute allocated to model inference; this is discussed in further detail </span><span class="c33"><a class="c24" href="#h.w37fa0y8qvzs">here</a></span><span class="c5">. To answer (b), we look at how training </span><span class="c5">compute</span><span class="c5">&nbsp;</span><span class="c5">has</span><span class="c5">&nbsp;been allocated to models of different sizes in recent years, and assume that these allocation trends hold in the coming years.</span><span class="c85 c72 c31">&nbsp;</span><span class="c5 c14">This approach means that we do not have to explicitly commit to fixed parametric distributions. </span></p><p class="c18"><span class="c33"><a class="c24" href="#h.kv9ocx80dib5">Figure 2A</a></span><span class="c5">&nbsp;below shows how training compute spending in the years 2020-2023 has been allocated to models of different sizes (data for 2017-2019 are shown in </span><span class="c33"><a class="c24" href="#h.68seg8jevz5n">Appendix B</a></span><span class="c5">). The x-axis represents the size of individual models. The y-axis shows the fraction of training </span><span class="c5">compute</span><span class="c5 c14">&nbsp;spent training models of size m or less. &nbsp;Differences in model sizes and their compute share can span orders of magnitude so both axes are log-scaled.</span></p><p class="c49"><span style="overflow: hidden; display: inline-block; margin: 0.00px -0.00px; border: 1.33px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 513.42px; height: 366.07px;"><img alt="" src="images/image11.png" style="width: 513.42px; height: 366.07px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h6 class="c26 c22" id="h.kv9ocx80dib5"><span class="c32 c72 c31 c42">Figure 2A</span><span class="c21 c14">: Compute allocation across model sizes for years 2020-2023, x-axis unnormalised. </span></h6><p class="c18"><span class="c5 c14">To get a concrete sense of what the plot shows, here are some conclusions that can be made by reading off the graph:</span></p><ul class="c105 lst-kix_rbsqzpr8hbg5-0 start"><li class="c18 c30 li-bullet-0"><span class="c5">In 2021, models of size 10</span><span class="c2">22</span><span class="c5">&nbsp;FLOP or less contributed to approximately 1% of total </span><span class="c5">compute</span><span class="c5 c14">&nbsp;spending.</span></li><li class="c18 c30 li-bullet-0"><span class="c5">In 2021, models of size 10</span><span class="c2">21 </span><span class="c5 c14">FLOP or less contributed approximately 0.1% of total compute spending</span></li><li class="c18 c30 li-bullet-0"><span class="c5">In 2022, models of size 10</span><span class="c2">21</span><span class="c5 c14">&nbsp;FLOP or less contributed approximately 0.01% of total compute spending</span></li><li class="c18 c30 li-bullet-0"><span class="c5">In 2023, models of size 10</span><span class="c2">23</span><span class="c5">&nbsp;FLOP or less contributed just less than 10% total training </span><span class="c5">compute</span><span class="c5 c14">&nbsp;spending.</span></li></ul><p class="c18"><span class="c33"><a class="c24" href="#h.kv9ocx80dib5">Figure 2A</a></span><span class="c5">&nbsp;also marks the largest model trained each year with the red vertical line. By definition, the largest model and all those smaller than it account for 100% of compute spending in a given year; this is shown in </span><span class="c33"><a class="c24" href="#h.kv9ocx80dib5">Figure 2A</a></span><span class="c5 c14">&nbsp;by the fact that this line intersects with the line representing total compute spending. </span></p><p class="c18"><span class="c5">The relationship between model size m and total compute spent training models of size m or less is consistently linear</span><span class="c5 c73">&nbsp;</span><span class="c5">across 2020-2023 (and </span><span class="c33"><a class="c24" href="#h.68seg8jevz5n">2017-2019</a></span><span class="c5">), suggesting a stable trend that we can extrapolate. The size of individual models grows each year, so to extrapolate this trend we normalise the x-axis by the largest model trained in each year (shown in </span><span class="c33"><a class="c24" href="#h.6nitnzyx8dyh">Figure 2B</a></span><span class="c5 c14">). Table 1 shows the compute allocations for different model sizes for 2023 that are derived from these plots. </span></p><p class="c49"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 1.33px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 498.50px; height: 354.79px;"><img alt="" src="images/image13.png" style="width: 498.50px; height: 354.79px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h6 class="c26 c22" id="h.6nitnzyx8dyh"><span class="c32 c72 c31 c42">Figure 2B</span><span class="c21 c14">: Compute allocation amongst model sizes for years 2020-2023, x-axis normalised by largest model trained that year. Linear fit shown.</span></h6><p class="c18 c19"><span class="c5 c14"></span></p><table class="c112"><tr class="c82"><td class="c87" colspan="6" rowspan="1"><p class="c39"><span class="c14 c32 c31 c86">Compute allocation in 2023</span></p></td></tr><tr class="c82"><td class="c131" colspan="1" rowspan="1"><p class="c8"><span class="c23">Model size relative to Gemini Ultra (5x10</span><span class="c23 c53">25</span><span class="c23 c14">&nbsp;FLOP)</span></p></td><td class="c99" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">All models within 5 OOM - 4 OOM</span></p></td><td class="c144" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">All models within 4 OOM - 3 OOM</span></p></td><td class="c146" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">All models within 3 OOM - 2 OOM</span></p></td><td class="c143" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">All models within 2 OOM - 1 OOM</span></p></td><td class="c148" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">All models within 1 OOM</span></p></td></tr><tr class="c82"><td class="c122" colspan="1" rowspan="1"><p class="c8"><span class="c23 c14">Model size (absolute)</span></p></td><td class="c100" colspan="1" rowspan="1"><p class="c28"><span class="c16">5</span><img src="images/image1.png"><span class="c16">10</span><span class="c16 c53">20</span><span class="c16">&nbsp;- 5</span><img src="images/image1.png"><span class="c16">10</span><span class="c16 c53">21</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c28"><span class="c16">5</span><img src="images/image1.png"><span class="c16">10</span><span class="c16 c53">21</span><span class="c16">&nbsp;- 5</span><img src="images/image1.png"><span class="c16">10</span><span class="c16 c53">22</span></p></td><td class="c88" colspan="1" rowspan="1"><p class="c28"><span class="c16">5</span><img src="images/image1.png"><span class="c16">10</span><span class="c16 c53">22</span><span class="c16">&nbsp;- 5</span><img src="images/image1.png"><span class="c16">10</span><span class="c16 c53">23</span></p></td><td class="c121" colspan="1" rowspan="1"><p class="c28"><span class="c16">5</span><img src="images/image1.png"><span class="c16">10</span><span class="c16 c53">23</span><span class="c16">-5</span><img src="images/image1.png"><span class="c16">10</span><span class="c16 c53">24</span></p></td><td class="c130" colspan="1" rowspan="1"><p class="c28"><span class="c16">5</span><img src="images/image1.png"><span class="c16">10</span><span class="c16 c53">24</span><span class="c16">&nbsp;- 5</span><img src="images/image1.png"><span class="c16">10</span><span class="c16 c53">25</span></p></td></tr><tr class="c54"><td class="c122" colspan="1" rowspan="1"><p class="c8"><span class="c23 c14">Fractional allocation of total compute (2 s.f.)</span></p></td><td class="c100" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">0.00011%</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">0.0010%</span></p></td><td class="c88" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">0.010%</span></p></td><td class="c121" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">8.6%</span></p></td><td class="c130" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">90%</span></p></td></tr><tr class="c15"><td class="c136" colspan="1" rowspan="1"><p class="c8"><span class="c23 c14">Compute allocation (FLOP)</span></p></td><td class="c124" colspan="1" rowspan="1"><p class="c8"><span class="c16 c31">1.51</span><img src="images/image1.png"><span class="c16">10</span><span class="c16 c53">22</span></p></td><td class="c149" colspan="1" rowspan="1"><p class="c8"><span class="c16 c31">1.43</span><img src="images/image1.png"><span class="c16">10</span><span class="c16 c53 c68 c31 c42">23</span></p></td><td class="c89" colspan="1" rowspan="1"><p class="c8"><span class="c16 c31">1.36</span><img src="images/image1.png"><span class="c16">10</span><span class="c16 c53 c68 c31 c42">24</span></p></td><td class="c47" colspan="1" rowspan="1"><p class="c8"><span class="c16 c31">1.16</span><img src="images/image1.png"><span class="c16">10</span><span class="c16 c53 c68 c31 c42">25</span></p></td><td class="c150" colspan="1" rowspan="1"><p class="c8"><span class="c16 c31">1.22</span><img src="images/image1.png"><span class="c16">10</span><span class="c16 c53 c68 c31 c42">26</span></p></td></tr></table><h6 class="c26 c22" id="h.z87cw66c9p4f"><span class="c32 c72 c31 c42">Table 1</span><span class="c21 c42">: 2023 allocations &ndash; Largest model: Gemini Ultra @ 5x10</span><span class="c21 c53 c42">25</span><span class="c21 c42">&nbsp;FLOP, total compute = 1.35x10</span><span class="c21 c53 c42">26</span><span class="c21 c14">&nbsp;FLOP. We use OOM to refer to an order of magnitude of training compute. Allocations may not sum exactly to 1 due to rounding errors.</span></h6><p class="c6"><span class="c5 c14">Before moving on, It is worth briefly considering the constraints and physical interpretations of the parameters of the linear fits - namely, the gradient (k) and the intercept (b). </span></p><p class="c6"><span class="c5">First, note that the linear fits must pass through (1,1) on the normalised plots (Figure 2B) - this is because, by definition, the largest model and all models smaller than it (i.e: all models released in a given year) account for 100% of </span><span class="c5">compute</span><span class="c5">&nbsp;used. This means that the intercept of the linear fits - b - must be 0 (see </span><span class="c33"><a class="c24" href="#h.wxd47v1bse8f">Appendix C</a></span><span class="c5">&nbsp;for details). Regarding k, </span><span class="c33"><a class="c24" href="#h.wxd47v1bse8f">Appendix C</a></span><span class="c5">&nbsp;shows that models that are 10x the size of a smaller counterpart are allocated roughly 10</span><span class="c2">k</span><span class="c5">&nbsp;times as much compute. Historical values for k are seemingly equally distributed across the range [0.9, 1.1] (</span><span class="c33"><a class="c24" href="#h.io0s51ptaeqw">Appendix D</a></span><span class="c5">), therefore our model samples k uniformly from the range [0.9,1.1]. The edge case of k=0.9 corresponds to models that are 10x as large as a counterpart being allocated 10</span><span class="c2">0.9 </span><span class="c5">= ~8.0</span><span class="c2">&nbsp;</span><span class="c5">times as much compute, whereas the factor for the k=1 case is 10</span><span class="c2">1.1</span><span class="c2 c73">&nbsp;</span><span class="c5 c14">= 12.6 times as much compute. </span></p><p class="c18"><span class="c5">Finally, observing </span><span class="c33"><a class="c24" href="#h.z87cw66c9p4f">Table 1</a></span><span class="c5">&nbsp;closely shows that our model requires an assumption to be made about the size of the largest model released in a given year in relation to the total training </span><span class="c5">compute</span><span class="c5">&nbsp;spending that year. This parameter is referred to as the largest model share (or LMS parameter) in the rest of this analysis. Observing this parameter from the years we fit the model to (</span><span class="c33"><a class="c24" href="#h.k3leb43q2dhl">Appendix F.1</a></span><span class="c5">) leads us to sampling the LMS uniformly from the range [0.05, 0.5] except for the year 2024 where we set the largest model to the size of GPT-4o (3.8x10</span><span class="c2">25</span><span class="c5">&nbsp;FLOP, released May 2024) following the data in the Notable models database. Concretely, this means that in the years 2025-2028 we assume that the largest training run uses at most 50% of the training </span><span class="c5">compute</span><span class="c5">&nbsp;stock that year, and at least 5%. A 50% share of the total training compute used may initially appear large, but similar scenarios are not historically unprecedented, with the Notable Models database documenting that GPT-3 175B davinci (3.14</span><img src="images/image1.png"><span class="c5">10</span><span class="c2">23</span><span class="c5">&nbsp;FLOP) accounted for ~46% of the 6.75</span><img src="images/image1.png"><span class="c5">10</span><span class="c2">23</span><span class="c5 c14">&nbsp;FLOP of training compute that year.</span></p><p class="c6"><span class="c5">Our modelling choices for &nbsp;the LMS parameter for 2024 are discussed further in </span><span class="c33"><a class="c24" href="#h.c8bml13pwy2u">Appendix E</a></span><span class="c5">. The LMS parameter is an important input to our model and its influence on the model&rsquo;s predictions are discussed further in </span><span class="c33"><a class="c24" href="#h.hpl38q1ioep3">Appendix F.2</a></span><span class="c5 c14">. </span></p><p class="c6"><span class="c5 c14">Finally, to generate model distributions to extend the historical data we randomly sample models from each bin until the total training compute allocated to that bin is met or exceeded. </span></p><h2 class="c39" id="h.w37fa0y8qvzs"><span class="c14 c32 c31 c34">2.3 Allocating compute between training, inference, and other workloads </span></h2><p class="c18"><span class="c5">Given estimates of the total compute stock, the next key stage involves allocating this stock between training, inference and other workloads. First a note on the different usages for </span><span class="c5">compute</span><span class="c5">. AI developers can use compute for model training (both pre- and post-training), as well as serving models to customers (&lsquo;external&rsquo; deployment/inference), using models in-house for research automation and monitoring (&lsquo;internal&rsquo; deployment/inference), compute for research experiments, generating synthetic data, and more. For this analysis, it is sufficient to categorise compute usage into &lsquo;training&rsquo; and &lsquo;inference&rsquo; following existing analyses</span><sup class="c5"><a href="#ftnt13" id="ftnt_ref13">[13]</a></sup><span class="c5 c14">, though it&rsquo;s important to note that &lsquo;inference&rsquo; here encompasses model inference and other related uses (such as synthetic data generation). &nbsp;</span></p><p class="c18"><span class="c5">Dean et al.&rsquo;s compute forecast</span><sup class="c5"><a href="#ftnt14" id="ftnt_ref14">[14]</a></sup><span class="c5">&nbsp;estimates that in 2024 approximately 40% of compute was used for training (including both pre- and post-training), with the remaining share going to model inference and other uses. This is used as the starting point for the model. Dean et al. then estimate the share of compute allocated to training in the following years, estimating that in 2025 and 2026 40% of compute will be used for model training, 30% at the start of 2027 and 20% by the end of 2027. These allocations are mapped to the predictions years for this forecast (2025-2028) in the first column of </span><span class="c33"><a class="c24" href="#h.u2xvqea6rw2r">Table 2</a></span><sup class="c5"><a href="#ftnt15" id="ftnt_ref15">[15]</a></sup><span class="c5">. The 20-80 allocation of compute between training and other uses at the end of 2027 represents an aggressive </span><span class="c5">scenario</span><span class="c5 c14">&nbsp;with respect to AI automation, and is therefore adjusted to a slightly more balanced 30-70 split for the baseline forecast in this paper, as can be observed in the second column of table 2. </span></p><p class="c18"><span class="c5">It is also worth noting that there appears to be large uncertainty in the compute allocations between training, inference and other workloads, with estimates varying largely between publicly available information</span><sup class="c5"><a href="#ftnt16" id="ftnt_ref16">[16]</a></sup><span class="c5">. In </span><span class="c33"><a class="c24" href="#h.uoquc4qd38jc">Appendix H</a></span><span class="c5 c14">&nbsp;we present results for alternate allocation scenarios. </span></p><p class="c18 c19"><span class="c5 c14"></span></p><p class="c18 c19"><span class="c5 c14"></span></p><table class="c120"><tr class="c82"><td class="c141" colspan="1" rowspan="1"><p class="c8"><span class="c23 c14">Year</span></p></td><td class="c107" colspan="1" rowspan="1"><p class="c8"><span class="c23">Approximate training </span><span class="c23">compute</span><span class="c23 c14">&nbsp;allocations (Dean et al.) </span></p></td><td class="c107" colspan="1" rowspan="1"><p class="c8"><span class="c23 c14">Training compute allocation (ours) </span></p></td></tr><tr class="c82"><td class="c118" colspan="1" rowspan="1"><p class="c8"><span class="c21 c14">2025</span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">40%</span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">40%</span></p></td></tr><tr class="c54"><td class="c61" colspan="1" rowspan="1"><p class="c8"><span class="c21 c14">2026</span></p></td><td class="c36" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">40%</span></p></td><td class="c36" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">40%</span></p></td></tr><tr class="c54"><td class="c61" colspan="1" rowspan="1"><p class="c8"><span class="c21 c14">2027</span></p></td><td class="c36" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">30%</span></p></td><td class="c36" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">30%</span></p></td></tr><tr class="c15"><td class="c111" colspan="1" rowspan="1"><p class="c8"><span class="c21 c14">2028</span></p></td><td class="c109" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">20%</span></p></td><td class="c109" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">30%</span></p></td></tr></table><h6 class="c26 c22" id="h.u2xvqea6rw2r"><span class="c32 c72 c31 c42">Table 2</span><span class="c21 c14">&nbsp;- Compute allocations for training models for 2025-2028. </span></h6><h2 class="c12" id="h.c8pwiup75zhc"><span class="c14 c32 c31 c34"></span></h2><h2 class="c39" id="h.8inev3nflxt0"><span class="c14 c32 c31 c34">2.4 Frontier-connected thresholds</span></h2><p class="c18"><span class="c5">An alternative to setting training compute thresholds based on absolute compute limits would (e.g: 10</span><span class="c2">25</span><span class="c5">&nbsp;FLOP, 10</span><span class="c2">26</span><span class="c5">&nbsp;FLOP) is to set thresholds based upon a model&rsquo;s proximity to the largest model trained to date</span><sup class="c5"><a href="#ftnt17" id="ftnt_ref17">[17]</a></sup><span class="c5 c14">. To get a sense for how such a threshold would operate, at a given point in time a model regulator could require that any model trained over the next 3 months that is either (a) within 1 OOM of the largest model that existed at the start of this period or (b) exceeding the size of this largest model is subjected to additional reporting or transparency requirements. We project trends for these &lsquo;frontier-connected&rsquo; thresholds for models that are within 0.5, 1 and 1.5 orders of magnitude of the largest model to date. </span></p><h1 class="c39" id="h.4ccs6ds00euy"><span class="c14 c32 c41 c31">3 Results </span></h1><p class="c18"><span class="c5">In this section we present the results of our model for both absolute compute thresholds (e.g: 10</span><span class="c2">25</span><span class="c5 c14">&nbsp;FLOP, etc.) and for frontier-connected thresholds that incorporate models within 0.5, 1.0 and 1.5 orders of magnitude from the largest model released. We present the results of our model in the format (5, 50, 95), where 5, 50, 95 refer to the 5th, 50th and 95th percentile projections of the model when running it 1000 times. The 90% confidence prediction intervals are presented to convey uncertainty about parameters of the model, such as the largest model share (LMS), compute growth rates and allocation gradient. Interpretations of these results should anchor on the full prediction interval, rather than a single point estimate (e.g: the median projection). </span></p><p class="c49"><span style="overflow: hidden; display: inline-block; margin: 0.00px -0.00px; border: 1.33px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 547.50px; height: 291.55px;"><img alt="" src="images/image8.png" style="width: 547.50px; height: 291.55px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h6 class="c26 c22" id="h.26105212vtl1"><span class="c32 c72 c31 c42">Figure 4</span><span class="c21 c14">: Scatter plot of the model&rsquo;s projected samples when all parameters are set to their median values (LMS=27.05, allocation gradient=1.0, growth rate =4.1x). </span></h6><p class="c18"><span class="c5">The Verification section aims to validate the model projections by </span><span class="c5">retrodicting</span><span class="c5 c14">&nbsp;our model and comparing the results to the historically observed data. Here we find that the 90% prediction intervals capture all historically observed data points. Taken together, this provides considerable evidence that the 90% prediction intervals presented below are likely to capture the number of models released in the coming years &nbsp;above each respective threshold.</span></p><h2 class="c39" id="h.n2qcn584d2hr"><span class="c14 c32 c31 c34">3.1 Absolute compute thresholds</span></h2><p class="c18"><span class="c5">First, we can compare our </span><span class="c5">model&rsquo;s</span><span class="c5">&nbsp;</span><span class="c5">projections</span><span class="c5">&nbsp;to what we know about the number of AI models exceeding 10</span><span class="c2">25</span><span class="c5">&nbsp;FLOP</span><sup class="c5"><a href="#ftnt18" id="ftnt_ref18">[18]</a></sup><span class="c5">. Recall that we set the largest model share parameter for 2024 to 0.1 to enforce the condition that the largest model released that year was the size of GPT-4o at 3.8x10</span><span class="c2">25</span><span class="c5">&nbsp;FLOP. &nbsp;We show a results table </span><span class="c5 c73">without this constraint</span><span class="c5">&nbsp;in </span><span class="c33"><a class="c24" href="#h.c8bml13pwy2u">Appendix E</a></span><span class="c5">. &nbsp;With this constraint, our model predicts a median of 16 10</span><span class="c2">25</span><span class="c5">&nbsp;FLOP models in 2024, which falls in the centre of the 12 counted in the latest version of the Notable Models database and the 20 estimated in </span><span class="c33"><a class="c24" href="https://www.google.com/url?q=https://epoch.ai/data-insights/models-over-1e25-flop&amp;sa=D&amp;source=editors&amp;ust=1744328243554922&amp;usg=AOvVaw08noD4T-MXK9M5Wy4FUZRN">this</a></span><span class="c5 c14">&nbsp;article. </span></p><p class="c18"><span class="c5">Assuming these prediction intervals will hold over the coming years, what are the implications for training compute thresholds? By the end of 2028 (EOY 2028) our median and 95th percentile projections for the number of models exceeding the 10</span><span class="c2">25</span><span class="c5">&nbsp;FLOP threshold in the EU AI Act are 127 and 287 respectively. Our median and 95th percentile projection for the number of models exceeding the 10</span><span class="c2">26</span><span class="c5">&nbsp;threshold in the Diffusion Framework are 63 and 134. </span></p><table class="c60"><thead><tr class="c15"><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">Threshold (FLOP)</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2024</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2025</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2026</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2027</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2028</span></p></td><tbody></tbody></tr><tr class="c15"><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c32">&gt; 10</span><span class="c40 c32">25</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[13, 16, 19]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[24, 33, 57]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[39, 58, 117]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[60, 88, 192]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[81, 127, 287]</span></p></td></tr><tr class="c15"><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c32">&gt; 10</span><span class="c40 c32">26</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[2, 6, 10]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[10, 19, 36]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[22, 37, 74]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[37, 63, 134]</span></p></td></tr><tr class="c15"><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c32">&gt; 10</span><span class="c40 c32">27</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 1]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 2, 5]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[1, 9, 17]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[8, 22, 47]</span></p></td></tr><tr class="c15"><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c32">&gt; 10</span><span class="c40 c32">28</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 1]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 3, 9]</span></p></td></tr><tr class="c15"><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c32">&gt; 10</span><span class="c40 c32">29</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td></tr></thead></table><h3 class="c80 c76" id="h.tx3of8peszku"><span class="c14 c58 c34"></span></h3><h6 class="c26 c22" id="h.6j319widv6ul"><span class="c32 c72 c31 c42">Table 3</span><span class="c21 c42">: </span><span class="c32 c31 c42 c72">Results for absolute thresholds.</span><span class="c21 c42">&nbsp;Table 3 presents the 90% prediction intervals for the absolute compute thresholds. The results in the table are cumulative, showing the projections for the number of models above threshold X that had been released by the end of a given year, rather than the number of models that were released in that year. For example, our 95th percentile projection for the number of models exceeding 10</span><span class="c21 c53 c42">25</span><span class="c21 c14">&nbsp;FLOP by the end of 2025 is 57, with 19 of these released in 2024. </span></h6><p class="c18"><span class="c5">It is also worth noting the growth rate of the number of models exceeding the AI Act&rsquo;s threshold each year. Considering the 95th percentile projections, we see that from 2024-2025 the number of models captured by the 10</span><span class="c2">25</span><span class="c5">&nbsp;threshold increases by 38, and then 60, 75 and 90 &nbsp;in subsequent years. This highlights a superlinear growth trend; not only does the number of models captured by the Act&rsquo;s compute threshold increase, but it increases at a growing rate. This superlinear growth trend holds across </span><span class="c5 c73">all </span><span class="c5 c14">projections (5th, 50th and 95th percentile forecasts) and across all absolute compute thresholds.</span></p><h2 class="c39" id="h.myo7hmhgq1ij"><span class="c14 c32 c31 c34">3.2 Frontier-connected thresholds</span></h2><p class="c18"><span class="c5">We now consider the results of our projections for the frontier-connected thresholds defined in </span><span class="c33"><a class="c24" href="#h.8inev3nflxt0">Section 2.4</a></span><span class="c5">. These results are shown in </span><span class="c33"><a class="c24" href="#h.1p6kfvxhsfr8">Table 4</a></span><span class="c5">. The key takeaway is that across all projections (5th, 50th and 95th percentile) and all thresholds (within 0.5, 1.0 and 1.5 OOMs of the largest model), the number of models captured by the threshold stays roughly constant</span><span class="c5 c73">&nbsp;each year</span><sup class="c5 c73"><a href="#ftnt19" id="ftnt_ref19">[19]</a></sup><span class="c5 c14">. For example, our median projection for the number of models that are within 1 OOM of the largest model at a given date is stable at 9-11 models across each year from 2025-2028, and the other thresholds of 0.5 OOMs and 1.5 OOMs see a similar trend. This constancy across time in the number of models captured by the threshold may be a desirable property for regulatory bodies responsible for enforcement; however the extent to which the frontier-connected thresholds are preferable over absolute training compute thresholds will also depend on whether the risks posed by a model are due to its absolute size or it&rsquo;s size relative to the frontier. </span></p><table class="c151"><thead><tr class="c15"><td class="c126" colspan="1" rowspan="1"><p class="c8"><span class="c31 c110">Distance from frontier model</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2024</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2025</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2026</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2027</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2028</span></p></td><tbody></tbody></tr><tr class="c15"><td class="c125" colspan="1" rowspan="1"><p class="c3"><span class="c7">Within 0.5 OOM</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[8, 11, 14]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[1, 5, 18]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[2, 5, 17]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[1, 4, 13]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[2, 5, 16]</span></p></td></tr><tr class="c15"><td class="c17" colspan="1" rowspan="1"><p class="c3"><span class="c7">Within 1 OOM</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[19, 22, 25]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[5, 10, 34]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[5, 10, 35]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[5, 9, 28]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[5, 11, 34]</span></p></td></tr><tr class="c15"><td class="c103" colspan="1" rowspan="1"><p class="c3"><span class="c7">Within 1.5 OOM</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[30, 34, 38]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[8, 14, 54]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[8, 17, 52]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[8, 15, 44]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[8, 16, 50]</span></p></td></tr></thead></table><h6 class="c26 c22" id="h.1p6kfvxhsfr8"><span class="c32 c72 c31 c42">Table 4: Frontier-connected thresholds. </span><span class="c21 c14">Results for frontier-connected thresholds (5th, 50th, 95th percentile projections). 2024 predictions differ from 2025-2028 as we fix the largest model in 2024 to the size of GPT-4o. Results are for model release projections within the specified year only.</span></h6><h1 class="c39" id="h.wcl9a3mn9mgv"><span class="c14 c32 c41 c31">4 Verification</span></h1><p class="c18"><span class="c5">In this section we present results obtained by </span><span class="c5">retrodicting</span><span class="c5">&nbsp;our model for absolute compute thresholds 10</span><span class="c2">23</span><span class="c5">, 10</span><span class="c2">24</span><span class="c5">&nbsp;and 10</span><span class="c2">25</span><span class="c5 c14">&nbsp;FLOP, for which there exists data from the years 2020-2023. We also compare our models predictions with the number of AI models satisfying the frontier-connected thresholds. The model&rsquo;s 90% prediction intervals capture all of these historically observed data points, which provides considerable evidence that the predicted intervals will capture the actual number of models exceeding the thresholds. </span></p><h2 class="c39" id="h.oxgwyevqg4hc"><span class="c14 c32 c31 c34">4.1 Absolute compute thresholds</span></h2><p class="c28 c19"><span class="c14 c58 c70"></span></p><table class="c60"><thead><tr class="c147"><td class="c52" colspan="1" rowspan="1"><p class="c3"><span class="c14 c74 c70 c139">Threshold (FLOP)</span></p></td><td class="c52" colspan="1" rowspan="1"><p class="c3"><span class="c7">2020</span></p></td><td class="c52" colspan="1" rowspan="1"><p class="c3"><span class="c7">2021</span></p></td><td class="c52" colspan="1" rowspan="1"><p class="c3"><span class="c7">2022</span></p></td><td class="c52" colspan="1" rowspan="1"><p class="c3"><span class="c7">2023</span></p></td><tbody></tbody></tr><tr class="c15"><td class="c44" colspan="1" rowspan="1"><p class="c3"><span class="c101">&gt; 10</span><span class="c40 c74">23</span></p></td><td class="c44" colspan="1" rowspan="1"><p class="c3"><span class="c0">2 (0,1,4)</span></p></td><td class="c44" colspan="1" rowspan="1"><p class="c3"><span class="c0">9 (8,14,27)</span></p></td><td class="c44" colspan="1" rowspan="1"><p class="c3"><span class="c0">29 (18,30,63)</span></p></td><td class="c44" colspan="1" rowspan="1"><p class="c3"><span class="c0">54 (34,54,126)</span></p></td></tr><tr class="c15"><td class="c71" colspan="1" rowspan="1"><p class="c3"><span class="c101">&gt; 10</span><span class="c40 c74">24</span></p></td><td class="c71" colspan="1" rowspan="1"><p class="c3"><span class="c0">0 (0,0,0)</span></p></td><td class="c71" colspan="1" rowspan="1"><p class="c3"><span class="c0">3 (0,2,3)</span></p></td><td class="c71" colspan="1" rowspan="1"><p class="c3"><span class="c0">8 (2,7,10)</span></p></td><td class="c71" colspan="1" rowspan="1"><p class="c3"><span class="c0">19 (12,21,43)</span></p></td></tr><tr class="c15"><td class="c29" colspan="1" rowspan="1"><p class="c3"><span class="c101">&gt; 10</span><span class="c53 c101">25</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c3"><span class="c0">0 (0,0,0)</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c3"><span class="c0">0 (0,0,0)</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c3"><span class="c0">0 (0,0,0)</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c3"><span class="c0">4 (0,4,5)</span></p></td></tr></thead></table><h4 class="c49 c22" id="h.9ho4e4b8km2d"><span class="c21 c14">Table 5: Absolute compute thresholds retrodiction. Each cell is formatted as O (5, 50, 95) where: O - historically observed data, 5 - 5th percentile projection, 50 - 50th percentile projection, 95 - 95th percentile projection. </span></h4><p class="c18"><span class="c5">For the absolute compute thresholds 10</span><span class="c2">23</span><span class="c5">, 10</span><span class="c2">24</span><span class="c5">&nbsp;and 10</span><span class="c2">25</span><span class="c5 c14">&nbsp;FLOP, our 90% confidence interval captures the historically observed values for the years 2020-2023. Note however, that for a number of cells the historically observed value is closer to the model&rsquo;s 5th or 95th projection than it is to the median projection, highlighting the importance of interpreting the full prediction interval. </span></p><h2 class="c12" id="h.xjx96z79taz4"><span class="c14 c32 c31 c34"></span></h2><h2 class="c39" id="h.res3zj9ti1gz"><span class="c14 c32 c31 c34">4.2 Frontier-connected threshold</span></h2><table class="c60"><thead><tr class="c15"><td class="c52" colspan="1" rowspan="1"><p class="c3"><span class="c7">&nbsp;Distance from frontier model </span></p></td><td class="c52" colspan="1" rowspan="1"><p class="c3"><span class="c7">2020</span></p></td><td class="c52" colspan="1" rowspan="1"><p class="c3"><span class="c7">2021</span></p></td><td class="c52" colspan="1" rowspan="1"><p class="c3"><span class="c7">2022</span></p></td><td class="c52" colspan="1" rowspan="1"><p class="c3"><span class="c7">2023</span></p></td><tbody></tbody></tr><tr class="c15"><td class="c44" colspan="1" rowspan="1"><p class="c35"><span class="c7">Within 0.5 OOM</span></p></td><td class="c44" colspan="1" rowspan="1"><p class="c35"><span class="c0">3 (1,5,13)</span></p></td><td class="c44" colspan="1" rowspan="1"><p class="c35"><span class="c0">4 (1,5,17)</span></p></td><td class="c44" colspan="1" rowspan="1"><p class="c35"><span class="c0">5 (1,4,15)</span></p></td><td class="c44" colspan="1" rowspan="1"><p class="c35"><span class="c0">5 (1,5,17)</span></p></td></tr><tr class="c15"><td class="c71" colspan="1" rowspan="1"><p class="c35"><span class="c7">Within 1.0 OOM</span></p></td><td class="c71" colspan="1" rowspan="1"><p class="c35"><span class="c0">7 (4,10,29)</span></p></td><td class="c71" colspan="1" rowspan="1"><p class="c35"><span class="c0">19 (5,11,33)</span></p></td><td class="c71" colspan="1" rowspan="1"><p class="c35"><span class="c0">16 (4,10,30)</span></p></td><td class="c71" colspan="1" rowspan="1"><p class="c35"><span class="c0">11 (5,9,32)</span></p></td></tr><tr class="c15"><td class="c29" colspan="1" rowspan="1"><p class="c35"><span class="c7">Within 1.5 OOM</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c35"><span class="c0">11 (8,16,47)</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c35"><span class="c0">27 (8,17,49)</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c35"><span class="c0">22 (7,15,46)</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c35"><span class="c0">17 (8,14,47)</span></p></td></tr></thead></table><h6 class="c22 c26" id="h.edsjpnon3kk4"><span class="c32 c72 c31 c42">Table 6</span><span class="c21 c42">: </span><span class="c32 c72 c31 c42">Frontier-connected thresholds retrodiction. </span><span class="c21 c14">Each cell is formatted as O (5, 50, 95) where: O - historically observed data, 5 - 5th percentile projection, 50 - 50th percentile projection, 95 - 95th percentile projection. </span></h6><p class="c18"><span class="c5 c14">For the 0.5, 1.0 and 1.5 OOM frontier-connected thresholds, our 90% confidence interval captures all of the historically &nbsp;observed values. Again, in some cases (e.g: 2021), the observed value is closer to the 5th or 95th percentile projection than it is to the median projection. </span></p><h1 class="c39" id="h.ohts958cil4p"><span class="c14 c32 c41 c31">5 Limitations</span></h1><p class="c18"><span class="c5 c14">In this section the limitations of our analysis are discussed. This includes the selection effect on the machine learning models tracked by the Notable Models database, as well as limitations resulting from uncertainty in key parameters that influence the model&rsquo;s predictions (such as the largest model share parameter) and compute growth rates. &nbsp;</span></p><h2 class="c39" id="h.p60h7aa85z0k"><span class="c14 c32 c31 c34">5.1 Notable models selection effect</span></h2><p class="c18"><span class="c5">The notable models database is a strict subset of all machine learning models. Therefore using this dataset to model future trends will, in general, lead to point estimates of the number of models that exceed the absolute compute thresholds being a lower bound on the true number</span><span class="c5 c73">. </span><span class="c5">However, the nearer a model is to the frontier, the closer this lower bound estimate will be to the actual number of models that exceed the threshold. To illustrate, consider the cases of setting a 10</span><span class="c2">22</span><span class="c5">&nbsp;FLOP compute threshold and 10</span><span class="c2">25</span><span class="c5">&nbsp;FLOP threshold in the year 2023. In 2023, the largest model released was Gemini Ultra at 5x10</span><span class="c2">25</span><span class="c5">&nbsp;FLOP. Most models with training </span><span class="c5">compute</span><span class="c5">&nbsp;on the order of 10</span><span class="c2">25</span><span class="c5">&nbsp;are likely to have satisfied at least one of the notability criteria</span><sup class="c5"><a href="#ftnt20" id="ftnt_ref20">[20]</a></sup><span class="c5">&nbsp;given their proximity to the frontier AI model of the day. However, models of size ~10</span><span class="c2">22</span><span class="c5">&nbsp;FLOP in 2023 are far less likely to have met the notability criteria and thus more likely to be excluded from the dataset, making point estimates of the trends of 10</span><span class="c2">22</span><span class="c5 c14">&nbsp;FLOP models less reliable. </span></p><p class="c18"><span class="c5">One way in which this effect can be accounted for within our model is by setting the allocation gradient (k) to less than one. Qualitatively this means that smaller models get more compute relative to the median scenario in our baseline case (where the median value of k is 1.0). For example, in the case where k = 1.0, models that are within 1 OOM of the largest model trained in a given year are allocated 90% of the </span><span class="c5">compute</span><span class="c5">&nbsp;share, with models within 1 OOM and &nbsp;2 OOM of the largest model getting a factor of 10 less - 9%. On the other hand, when k = 0.5, models within 1 OOM of the frontier get only 68% of compute, and those in the category below it get 10</span><span class="c2">0.5 </span><span class="c5">&nbsp;~ 3.2x less (other allocations are shown in </span><span class="c33"><a class="c24" href="#h.bv43yhbu9378">Table I.1 in Appendix I</a></span><span class="c5">). The results of our baseline model shown in </span><span class="c33"><a class="c24" href="#h.4ccs6ds00euy">Section 3</a></span><span class="c5">&nbsp;</span><span class="c5">choose k</span><span class="c5">&nbsp;based on </span><span class="c33"><a class="c24" href="#h.io0s51ptaeqw">historical values</a></span><span class="c5">&nbsp;found from the Notable Models database as it is unclear how to modify this parameter to account for the notable models selection effect. However in </span><span class="c33"><a class="c24" href="#h.97eqny6utl2u">Appendix I</a></span><span class="c5 c14">, results are presented in which k is sampled uniformly from the range [0.5, 1.0] to illustrate the outcome on compute thresholds when a correction for the notable models selection effect is applied. </span></p><p class="c18"><span class="c5 c14">Even within our baseline predictions (where k is sampled uniformly from [0.9,1.1]), it should be emphasised that our 90% prediction intervals are designed to capture uncertainty in the model parameters (such as largest model share, allocation gradient, and compute stock growth rate), not the uncertainty that arises from the Notable Models selection effect. However anchoring on the full prediction intervals will insure decisions against this selection effect to some extent. In other words, whilst our median projections are biased towards underestimating the actual number of models captured by the compute thresholds, this is less likely to be the case for our 95th percentile projections. </span></p><h2 class="c39" id="h.2e3vlucf1z5x"><span class="c14 c32 c31 c34">5.2 Uncertainty in key model parameters</span></h2><p class="c18"><span class="c5 c14">Key parameters that influence the model&rsquo;s predictions are the largest model share parameter (LMS), the compute stock growth rate, the allocation gradient, and the allocation of the compute stock between training and inference. Our choices for most of these parameters are informed by their historical values, for which we have limited data (2017-2023). This introduces uncertainty into our model, which we account for with 90% confidence intervals. However the limited historical data often only provides six (6) data points to calibrate these intervals with. </span></p><p class="c18"><span class="c5">For example, the LMS in previous years has varied significantly over the range 0.1 (2024) to 0.46 (2020). In making projections for the years 2025-2028 we therefore sample the LMS uniformly from a wider range of [0.05,0.5]. Given that low values of the LMS can lead to substantially different projections to larger values (</span><span class="c33"><a class="c24" href="#h.hpl38q1ioep3">Appendix F.2</a></span><span class="c5">&nbsp;discusses this in further detail), future work could look to further calibrate this parameter as more data becomes available. The case for the compute stock growth rate is similar - the two sources of evidence that are used in this study (historical compute growth rates and Dean et al.&rsquo;s</span><sup class="c5"><a href="#ftnt21" id="ftnt_ref21">[21]</a></sup><span class="c5 c14">&nbsp;forecast of future compute stock growth) show a noticeable discrepancy &nbsp;which we resolve by subjectively weighting the estimated growth rates. Valuable future work could look to conduct further analysis into the growth of compute that is available for AI training and inference. &nbsp;</span></p><h1 class="c39" id="h.ljpb78miup1"><span class="c14 c32 c41 c31">6 Implications for Compute-Threshold-Based Governance Frameworks</span></h1><p class="c18"><span class="c5">Training </span><span class="c5">compute is</span><span class="c5">&nbsp;increasingly being used as a proxy for determining which AI models should be subject to requirements imposed by AI governance frameworks. As Heim and Koessler (2024) argue, compute thresholds serve as an effective initial filter to identify potentially risky general-purpose AI models that warrant regulatory oversight and further scrutiny.</span><sup class="c5"><a href="#ftnt22" id="ftnt_ref22">[22]</a></sup><span class="c5">&nbsp;This approach is valuable because training compute correlates with model capabilities and potential risks while being easily quantifiable compared to other inputs to AI development.</span><sup class="c5"><a href="#ftnt23" id="ftnt_ref23">[23]</a></sup></p><p class="c18"><span class="c5">However, our analysis demonstrates a critical challenge: any static compute threshold will capture an increasing number of models over time. By the end of 2028, our median projections indicate that 127 models will exceed the 10</span><span class="c2">25</span><span class="c5">&nbsp;FLOP threshold established in the EU AI Act, and 63 models will surpass the 10</span><span class="c2">26</span><span class="c5 c14">&nbsp;FLOP threshold set in the US AI Diffusion Framework. Especially relevant is the superlinear growth pattern we observe. Not only does the number of models captured by these thresholds increase yearly, but the rate of increase accelerates..</span></p><p class="c18"><span class="c5 c14">This pace of increase could strain governmental capacity to enforce and monitor requirements while potentially imposing excessive regulatory burdens on a growing number of AI developers. In response, governments have two main options. First, they can make regulatory burdens more proportionate for less risky models while increasing their regulatory capacity to handle the growing number of models in scope. Second, they can reduce the scope of requirements by excluding certain models from the regime. Both the EU AI Office in the EU and the Bureau of Industry and Security in the US have the authority to make such adjustments to the scope of their respective regulatory frameworks.</span></p><h1 class="c39 c132" id="h.j2v69rupsi1x"><span class="c14 c32 c41 c31"></span></h1><h1 class="c39" id="h.z1jv8pmaslk6"><span class="c14 c32 c41 c31">7 Conclusion</span></h1><p class="c18"><span class="c5">In this paper we estimate the number of AI models that will exceed training compute thresholds such as those proposed in the EU AI Act</span><sup class="c5"><a href="#ftnt24" id="ftnt_ref24">[24]</a></sup><span class="c5">&nbsp;and the Artificial Intelligence Diffusion Framework</span><sup class="c5"><a href="#ftnt25" id="ftnt_ref25">[25]</a></sup><span class="c5">. Our method centres around estimating the total stock of compute that will be available for AI workloads (training and inference), and then allocating the training compute stock to models of different size following trends seen from 2017-2023. We find that 80-290 models will exist by the end of 2028 that exceed a 10</span><span class="c2">25</span><span class="c5">&nbsp;FLOP compute threshold with a 90% confidence interval, and 40-130 models will exist above the 10</span><span class="c2">26</span><span class="c5 c14">&nbsp;FLOP threshold. For all compute thresholds defined with respect to an absolute value, the number of models exceeding the threshold increases at an accelerating (superlinear) rate. &nbsp;</span></p><p class="c18"><span class="c5 c14">We also analyse trends for compute thresholds that are connected to the largest frontier model at the time of their release and find for thresholds that capture models within 0.5, 1.0 and 1.5 orders of magnitude of the largest model, the median number of models captured remains roughly stable each year (at 5, 10 and ~15-16 respectively) - however we have wide 90% confidence intervals around these. We validate our predictions by predicting threshold counts for the years 2020-2023, with our 90% confidence intervals capturing all historically observed values. </span></p><p class="c18"><span class="c5 c14">However our analysis is limited by the selection effects applied by the Notable Models database which bias our median projections towards being a lower bound on the actual number of models that will exceed the absolute compute thresholds. Additionally uncertainty around model parameters such as the largest model share (LMS), allocation gradient and compute growth rate mean that the full 90% prediction interval should be accounted for when basing policy decisions on these results. These findings emphasize the need for policymakers and regulatory bodies to consider the rapid growth in frontier AI model counts when designing and implementing compute-based governance frameworks, ensuring they have sufficient capacity to monitor and regulate an expanding number of models while maintaining flexibility to adjust thresholds as the AI landscape evolves.</span></p><hr style="page-break-before:always;display:none;"><h1 class="c39 c132" id="h.s2n92xml1024"><span class="c14 c32 c31 c41"></span></h1><h1 class="c39" id="h.oadl1ds6kzfq"><span class="c14 c32 c41 c31">Appendices</span></h1><h2 class="c39" id="h.kzodekz7i8dh"><span class="c14 c32 c31 c34">Appendix A | Historical distribution of notable models and fit data choice</span></h2><p class="c49"><span style="overflow: hidden; display: inline-block; margin: 0.00px -0.00px; border: 1.33px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 356.00px;"><img alt="" src="images/image7.png" style="width: 624.00px; height: 356.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h6 class="c26 c22" id="h.alafihtui337"><span class="c32 c72 c31 c42">Figure A.1</span><span class="c21 c14">: Historical distribution of models over training compute - scatter.</span></h6><p class="c18"><span class="c5 c14">The dataset we use for this analysis contains records of models and their estimated training compute dating back to the 1950s. We filter out all models that were released before 2017 as this corresponds to the era before the release of the Transformer architecture at the core of most frontier models today. Additionally, we do not use 2024 data to fit our model. Observing the model distribution in the scatter plot above, 2024 data appears incomplete relative to the previous years, especially towards the lower end of the distribution (i.e: there is a notable absence of models on the lower end of compute usage). The deviation of 2024 data from previous years can also be seen in the kernel density estimates below. </span></p><p class="c49"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 1.33px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 401.01px; height: 399.89px;"><img alt="" src="images/image10.png" style="width: 401.01px; height: 399.89px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h6 class="c26 c22" id="h.fxhcxyc26j06"><span class="c32 c72 c31 c42">Figure A.2</span><span class="c21 c14">: Historical distribution of models over training compute - KDEs</span></h6><hr style="page-break-before:always;display:none;"><h2 class="c12" id="h.ftx8xlc83cjd"><span class="c14 c32 c31 c34"></span></h2><h2 class="c39" id="h.68seg8jevz5n"><span class="c14 c32 c31 c34">Appendix B | Compute allocations for 2017-2019</span></h2><p class="c49"><span style="overflow: hidden; display: inline-block; margin: -0.00px -0.00px; border: 1.33px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 205.33px;"><img alt="" src="images/image12.png" style="width: 624.00px; height: 205.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h6 class="c26 c22" id="h.tdoy8qliarnq"><span class="c32 c72 c31 c42">Figure B.1</span><span class="c21 c14">: Allocation plots for the years 2017-2019, x-axis normalised by the largest model trained that year. A similar linear trend to the 2020-2023 data is observed.</span></h6><h3 class="c37 c76" id="h.2uu5wztmp927"><span class="c65 c14 c31"></span></h3><hr style="page-break-before:always;display:none;"><h2 class="c37 c145" id="h.yb2wiho6hwp5"><span class="c14 c32 c31 c34"></span></h2><h2 class="c37" id="h.wxd47v1bse8f"><span class="c14 c32 c31 c34">Appendix C | Constraints and interpretation of the linear fits</span></h2><p class="c18"><span class="c5 c14">This Appendix discusses the constraints on the linear fit to the compute allocation trends, and the interpretation of the allocation gradient parameter. </span></p><p class="c18"><span class="c5 c14">Observing historical data we see that the relationship between normalised model size (normalised by the largest model trained that year) - m&#771; and the fraction of compute spent on models of size m&#771; or less - denoted by A(m&#771;) - is linear in log-space. Mathematically:</span></p><p class="c49"><img src="images/image2.png"><img src="images/image3.png"></p><p class="c18"><span class="c5">Let that largest model trained in a given year be m_max, then m&#771;</span><span class="c5 c81">max</span><span class="c5">&nbsp;= 1. Models of size m</span><span class="c5 c81">max</span><span class="c5">&nbsp;or smaller (i.e: all models) take up all </span><span class="c5">compute</span><span class="c5">&nbsp;spending that year, therefore A(m&#771;</span><span class="c5 c81">max</span><span class="c5">&nbsp;= 1) = 1. Enforcing this constraint on 1 means that b = 0 - and so equation 1 reduces to A(m&#771;) = m</span><span class="c2">k</span><span class="c5 c14">.</span></p><p class="c18"><span class="c5">The parameter k determines </span><span class="c5">how compute</span><span class="c5">&nbsp;is allocated across models of different scales. To see this, let us first denote a(m&#8321;, m&#8322;) as the amount of compute that is allocated to models in the range [m&#8321;, m&#8322;). Consider also three sizes of models - m*, 10m*, and 100m*. The compute allocated to models in the range [m*, 10m*] is a(m*, 10m*) = A(10m*) - A(m*) = (10</span><span class="c2">k</span><span class="c5">&nbsp;- 1)m</span><span class="c2">k</span><span class="c5">&nbsp;using equation 1. The compute allocated to models in the range [10m*, 100m*) is a(10m*, 100m*) = A(100m*) - A(10m*) = 10^k(10</span><span class="c2">k</span><span class="c5">&nbsp;- 1)m</span><span class="c2">k</span><span class="c5 c14">&nbsp;after some simplification. Therefore the relationship between a(m, 10m*) and a(10m*, 100m*) is simply:</span></p><p class="c49"><img src="images/image4.png"><img src="images/image2.png"></p><p class="c18"><span class="c5">In other words, scaling up model size by a factor of 10 leads to a factor of 10</span><span class="c2">k</span><span class="c5 c14">&nbsp;increase in compute allocated to models of this size. k = 1 means that these larger models get 10 times as much compute as their smaller counterparts, k &gt; 1 means that they get a factor greater than 10, and k &lt; 1 leads to a factor less than 10.</span></p><hr style="page-break-before:always;display:none;"><h2 class="c12" id="h.jnxvt2bb4974"><span class="c14 c32 c31 c34"></span></h2><h2 class="c39" id="h.io0s51ptaeqw"><span class="c14 c32 c31 c34">Appendix D | Historical values of allocation gradients</span></h2><p class="c18"><span style="overflow: hidden; display: inline-block; margin: 0.00px -0.00px; border: 1.33px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 372.00px;"><img alt="" src="images/image14.png" style="width: 624.00px; height: 372.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h6 class="c26 c22" id="h.dx4prrvi1ugo"><span class="c32 c72 c31 c42">Figure D.1</span><span class="c21 c14">: Allocation gradient parameter over time. </span></h6><p class="c18"><span class="c5 c14">Historical values of the gradient of the compute allocation fits (k). Informed by this, our model draws k uniformly from the range [0.9,1.1].</span></p><h3 class="c37 c76" id="h.71610a5zs5a7"><span class="c65 c14 c31"></span></h3><hr style="page-break-before:always;display:none;"><h3 class="c37 c76" id="h.vlwes5hxuscs"><span class="c65 c14 c31"></span></h3><h2 class="c37" id="h.c8bml13pwy2u"><span class="c14 c32 c31 c34">Appendix E | 2024 predictions under uniform sampling of LMS </span></h2><p class="c18"><span class="c5">When predicting model counts for the years 2025-2028 we sample the largest model share parameter (LMS) from the range [0.05, 0.5]. However when predicting model counts for the year 2024 we set the LMS to 0.1. This is because we have some data to inform our projections for 2024. It appears that the largest model trained during 2024 was GPT-4o at 3.8x10</span><span class="c2">25</span><span class="c5">&nbsp;FLOP, corresponding to an LMS parameter of roughly 0.1</span><sup class="c5"><a href="#ftnt26" id="ftnt_ref26">[26]</a></sup><span class="c5">. If the LMS parameter is sampled uniformly from [0.05, 0.5] for 2024, we obtain Table E.1 and Table E.2 below, in which the median projection of the number of models above 10</span><span class="c2">25</span><span class="c5">&nbsp;and 10</span><span class="c2">26</span><span class="c5">&nbsp;FLOP is 12 and 1. In other words, our model expects there to have been models exceeding 10</span><span class="c2">26</span><span class="c5">&nbsp;FLOP in 2024, and in predicting </span><span class="c5">this</span><span class="c5">&nbsp;</span><span class="c5">sacrifices compute</span><span class="c5">&nbsp;that instead would have gone to the 10</span><span class="c2">25</span><span class="c5">&nbsp;FLOP category. Observing the historical trend of the largest model and its relation to the total training </span><span class="c5">compute</span><span class="c5 c14">&nbsp;spent that year shows that 2024 deviates from previous years, and thus our model&rsquo;s expectation is warranted. </span></p><p class="c49"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 1.33px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 475.00px; height: 302.35px;"><img alt="" src="images/image9.png" style="width: 475.00px; height: 302.35px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h6 class="c26 c22" id="h.v62qodpqkidi"><span class="c32 c72 c31 c42">Figure E.1</span><span class="c21 c14">: Historical data for largest model and total training compute</span></h6><hr style="page-break-before:always;display:none;"><p class="c49 c19"><span class="c5 c51"></span></p><h3 class="c35 c76" id="h.w8ujry42d6a1"><span class="c14 c58 c34"></span></h3><table class="c119"><thead><tr class="c15"><td class="c102" colspan="1" rowspan="1"><p class="c3"><span class="c7">Threshold (FLOP)</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2024</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2025</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2026</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2027</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2028</span></p></td><tbody></tbody></tr><tr class="c15"><td class="c113" colspan="1" rowspan="1"><p class="c3"><span class="c32">&gt; 10</span><span class="c40 c32">25</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[7, 12, 19]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[18, 29, 53]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[33, 53, 112]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[51, 83, 187]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[74, 121, 283]</span></p></td></tr><tr class="c15"><td class="c114" colspan="1" rowspan="1"><p class="c3"><span class="c32">&gt; 10</span><span class="c40 c32">26</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 1, 2]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[4, 6, 12]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[13, 20, 37]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[23, 38, 79]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[38, 64, 135]</span></p></td></tr><tr class="c15"><td class="c114" colspan="1" rowspan="1"><p class="c3"><span class="c32">&gt; 10</span><span class="c40 c32">27</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 1]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 2, 6]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[3, 9, 20]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[10, 23, 46]</span></p></td></tr><tr class="c15"><td class="c114" colspan="1" rowspan="1"><p class="c3"><span class="c32">&gt; 10</span><span class="c40 c32">28</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 1]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 3, 8]</span></p></td></tr><tr class="c15"><td class="c95" colspan="1" rowspan="1"><p class="c3"><span class="c32">&gt; 10</span><span class="c40 c32">29</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td></tr></thead></table><h6 class="c26 c22" id="h.fgzrud85zggd"><span class="c32 c72 c31 c42">Table E.1</span><span class="c21 c14">: Absolute threshold predictions when 2024 LMS parameter sampled from uniformly from (0.05,0.5)</span></h6><h6 class="c26 c22 c97" id="h.g3ch7296a43t"><span class="c14 c32 c72 c31"></span></h6><p class="c28 c19"><span class="c14 c58 c70"></span></p><table class="c90"><thead><tr class="c15"><td class="c92" colspan="1" rowspan="1"><p class="c3"><span class="c7">Distance from frontier model </span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2024</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2025</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2026</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2027</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2028</span></p></td><tbody></tbody></tr><tr class="c15"><td class="c93" colspan="1" rowspan="1"><p class="c3"><span class="c7">Within 0.5 OOM</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[2, 4, 15]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[2, 4, 14]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[2, 5, 15]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[2, 6, 15]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[2, 5, 16]</span></p></td></tr><tr class="c15"><td class="c20" colspan="1" rowspan="1"><p class="c3"><span class="c7">Within 1 OOM</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[5, 9, 29]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[4, 9, 31]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[5, 10, 29]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[5, 12, 31]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[5, 10, 34]</span></p></td></tr><tr class="c15"><td class="c45" colspan="1" rowspan="1"><p class="c3"><span class="c7">Within 1.5 OOM</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[8, 15, 49]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[7, 14, 48]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[8, 15, 49]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[9, 18, 53]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[8, 16, 53]</span></p></td></tr></thead></table><h6 class="c49 c22 c62" id="h.4ijewpud2ynx"><span class="c32 c72 c31 c42">Table E.2</span><span class="c21 c14">: Frontier-connected threshold predictions when 2024 LMS parameter sampled from Unif(0.05,0.5).</span></h6><h2 class="c12" id="h.fo9l7prhouuh"><span class="c14 c32 c31 c34"></span></h2><h3 class="c37 c76" id="h.t3v688yaxz1h"><span class="c14 c31 c65"></span></h3><hr style="page-break-before:always;display:none;"><h3 class="c37 c76" id="h.w6fugem9jegl"><span class="c65 c14 c31"></span></h3><h2 class="c37" id="h.1b8s4hwsy5m"><span class="c14 c32 c31 c34">Appendix F | LMS parameter and influence of LMS on projections</span></h2><h3 class="c39" id="h.k3leb43q2dhl"><span class="c65 c14 c31">F.1 &nbsp;Historical LMS</span></h3><p class="c49"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 1.33px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 464.50px; height: 302.13px;"><img alt="" src="images/image6.png" style="width: 464.50px; height: 302.13px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h6 class="c26 c22" id="h.4k2xdx8hikaq"><span class="c32 c72 c31 c42">Figure F.1:</span><span class="c21 c14">&nbsp;Historical data for the largest model share parameter</span></h6><p class="c49"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 1.33px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 475.00px; height: 302.35px;"><img alt="" src="images/image9.png" style="width: 475.00px; height: 302.35px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h6 class="c26 c22" id="h.o1gknzc4sjuq"><span class="c32 c72 c31 c42">Figure F.2</span><span class="c21 c14">: Historical data for largest model and total training compute. </span></h6><p class="c18"><span class="c5 c14">Historical values of the LMS parameter and the total compute and largest model each year that the LMS is derived from. AlphaGo, AlphaGo Zero and AlphaGo Master have been removed from the dataset as they represent outliers in model size. We fit the model on data from 2017-2023 and ignore the LMS for 2018 as it appears to be an outlier. </span></p><p class="c18"><span class="c5">Our predictions sample the LMS uniformly from the range [0.05,0.5]. The upper bound is chosen to accommodate GPT-3 davinci accounting for ~46% of training </span><span class="c5">compute</span><span class="c5 c14">&nbsp;in 2021. The lower bound is chosen with the 2022 value of 0.15 in mind, however we incorporate a wide range underneath this value due to the strong influence of low LMS values on the model&rsquo;s predictions (see Appendix F.2 below). </span></p><h3 class="c39" id="h.hpl38q1ioep3"><span class="c65 c14 c31">F.2 &nbsp;Influence of LMS on projections </span></h3><p class="c18"><span class="c5">When experimenting with the model, we find that the </span><span class="c72 c31 c85">number</span><span class="c5 c14">&nbsp;of models that exceed the compute thresholds grows large as the LMS parameter tends to 0. This appendix explores in further detail why this is the case with a toy example. </span></p><p class="c18"><span class="c5">Consider the following setup. We have 10</span><span class="c2">30</span><span class="c5">&nbsp;FLOP of </span><span class="c5">compute</span><span class="c5 c14">&nbsp;allocated to training models in a given year. The assignment of compute amongst model sizes is shown in the table below. (note that we assume that increasing the model size by a factor of 10 grants it 10x as much compute - corresponding to k=1 for the allocation plot gradient). </span></p><table class="c60"><tr class="c15"><td class="c69" colspan="1" rowspan="1"><p class="c8"><span class="c23 c14">Model size (in relation to largest model)</span></p></td><td class="c69" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">Within 3-4 OOM</span></p></td><td class="c69" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">Within 2-3 OOM</span></p></td><td class="c69" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">Within 1-2 OOM</span></p></td><td class="c69" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">Within 1 OOM </span></p></td></tr><tr class="c15"><td class="c69" colspan="1" rowspan="1"><p class="c8"><span class="c23 c14">Fractional allocation</span></p></td><td class="c69" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">0.009%</span></p></td><td class="c69" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">0.9%</span></p></td><td class="c69" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">9%</span></p></td><td class="c69" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">90%</span></p></td></tr><tr class="c15"><td class="c69" colspan="1" rowspan="1"><p class="c8"><span class="c23 c14">Allocation (FLOP)</span></p></td><td class="c69" colspan="1" rowspan="1"><p class="c8"><span>9</span><img src="images/image1.png"><span>10</span><span class="c53">26</span></p></td><td class="c69" colspan="1" rowspan="1"><p class="c8"><span>9</span><img src="images/image1.png"><span>10</span><span class="c53">27</span></p></td><td class="c69" colspan="1" rowspan="1"><p class="c8"><span>9</span><img src="images/image1.png"><span>10</span><span class="c53">28</span></p></td><td class="c69" colspan="1" rowspan="1"><p class="c8"><span>9</span><img src="images/image1.png"><span>10</span><span class="c53">29</span></p></td></tr></table><p class="c18"><span class="c5"><br>Now let us consider two cases: one in which the LMS = 0.05, and another in which the LMS = 0.5. In scenario 1, the largest model trained that year is 0.05</span><img src="images/image1.png"><span class="c5">10</span><span class="c2">30</span><span class="c5">&nbsp;= 5</span><img src="images/image1.png"><span class="c5">10</span><span class="c2">28</span><span class="c5">&nbsp;FLOP, and in scenario two the largest model is 0.5</span><img src="images/image1.png"><span class="c5">10</span><span class="c2">30</span><span class="c5">&nbsp;= </span><span>5</span><img src="images/image1.png"><span>10</span><span class="c53">29</span><span class="c5">&nbsp;FLOP. Now consider the number of models that can be drawn from each category.</span><span class="c85 c72 c31">&nbsp;</span><span class="c5">To approximate this we find the average model size of each category</span><sup class="c5"><a href="#ftnt27" id="ftnt_ref27">[27]</a></sup><span class="c5">&nbsp;- </span><span class="c5">m</span><span class="c5 c81">avg</span><span class="c5">&nbsp;- and find how many times </span><span class="c5">m</span><span class="c5 c81">avg</span><span class="c5">&nbsp;can be sampled from the compute allocations given in row three of the table above. </span><span class="c5 c38">This is </span><span class="c5 c38">show</span><span class="c5 c38">&nbsp;in the tables below</span><span class="c38 c85 c72 c31">.</span><span class="c5 c14">&nbsp;</span></p><p class="c18"><span class="c5">In the case where the LMS=0.05, approximately 56 models of size </span><span class="c5">m</span><span class="c5 c81">avg</span><span class="c5">&nbsp;can be sampled for each category, compared to the 5 sampled from each category for the case of LMS=0.5. More generally, the number of average sized models that can be sampled from each category grows inversely with the </span><span class="c5 c73">size</span><span class="c5">&nbsp;of the average model - and the average sized model of a category grows proportionally with the LMS parameter. </span></p><h4 class="c18 c22" id="h.ddv77e5te7ly"><span class="c21 c14">Scenario 1 - LMS=0.05 </span></h4><table class="c60"><tr class="c15"><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c23 c14">Model size (in relation to largest model)</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">Within 3-4 OOM</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">Within 2-3 OOM</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">Within 1-2 OOM</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">Within 1 OOM </span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8 c19"><span class="c14 c16 c31"></span></p></td></tr><tr class="c15"><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c23 c14">Model size (FLOP)</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c16 c31">5x10</span><span class="c16 c31 c53">24</span><span class="c16 c31">-5x10</span><span class="c16 c53 c31">25</span><span class="c14 c16 c31">&nbsp;</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c16 c31">5x10</span><span class="c16 c53 c31">25</span><span class="c16 c31">-5x10</span><span class="c16 c53 c31">26</span><span class="c14 c16 c31">&nbsp;</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c16 c31">5x10</span><span class="c16 c53 c31">26</span><span class="c16 c31">-5x10</span><span class="c16 c53 c31">27</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c16 c31">5x10</span><span class="c16 c53 c31">27</span><span class="c16 c31">-5x10</span><span class="c16 c53 c31">28</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8 c19"><span class="c14 c16 c31"></span></p></td></tr><tr class="c15"><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c23">Average</span><sup class="c23"><a href="#ftnt28" id="ftnt_ref28">[28]</a></sup><span class="c23 c14">&nbsp;model size (FLOP)</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c16 c31">1.6x10</span><span class="c16 c53 c68 c31 c42">24</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c16 c31">1.6x10</span><span class="c16 c53 c31 c42 c68">25</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c16 c31">1.6x10</span><span class="c16 c53 c68 c31 c42">26</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c16 c31">1.6x10</span><span class="c16 c53 c68 c31 c42">27</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8 c19"><span class="c14 c16 c31"></span></p></td></tr><tr class="c15"><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c23 c14">Allocation </span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c16 c31">9x10</span><span class="c16 c53 c68 c31 c42">26</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c16 c31">9x10</span><span class="c16 c53 c68 c31 c42">27</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c16 c31">9x10</span><span class="c16 c53 c68 c31 c42">28</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c16 c31">9x10</span><span class="c16 c53 c68 c31 c42">29</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8 c19"><span class="c14 c16 c31"></span></p></td></tr><tr class="c15"><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c23 c14">Number of samples drawn</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">56</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">56</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">56</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">56</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">224 (TOTAL)</span></p></td></tr></table><p class="c18 c19"><span class="c5 c14"></span></p><h4 class="c18 c22" id="h.1w3dh0jrk956"><span class="c21 c14">Scenario 2 - LMS=0.5 </span></h4><table class="c60"><tr class="c15"><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c14 c23">Model size (in relation to largest model)</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">Within 3-4 OOM</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">Within 2-3 OOM</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">Within 1-2 OOM</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">Within 1 OOM </span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8 c19"><span class="c14 c16 c31"></span></p></td></tr><tr class="c15"><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c23 c14">Model size (FLOP)</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c16 c31">5x10</span><span class="c16 c53 c31">25</span><span class="c16 c31">-5x10</span><span class="c16 c53 c31">26</span><span class="c14 c16 c31">&nbsp;</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c16 c31">5x10</span><span class="c16 c53 c31">26</span><span class="c16 c31">-5x10</span><span class="c16 c53 c31">27</span><span class="c14 c16 c31">&nbsp;</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c16 c31">5x10</span><span class="c16 c53 c31">27</span><span class="c16 c31">-5x10</span><span class="c16 c53 c31">28</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c16 c31">5x10</span><span class="c16 c53 c31">28</span><span class="c16 c31">-5x10</span><span class="c16 c53 c31">29</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8 c19"><span class="c14 c16 c31"></span></p></td></tr><tr class="c15"><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c23">Average</span><sup class="c23"><a href="#ftnt29" id="ftnt_ref29">[29]</a></sup><span class="c23 c14">&nbsp;model size</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c16 c31">1.6x10</span><span class="c16 c53 c68 c31 c42">25</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c16 c31">1.6x10</span><span class="c16 c53 c68 c31 c42">26</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c16 c31">1.6x10</span><span class="c16 c53 c68 c31 c42">27</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c16 c31">1.6x10</span><span class="c16 c53 c68 c31 c42">28</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8 c19"><span class="c14 c16 c31"></span></p></td></tr><tr class="c15"><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c23 c14">Allocation </span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c16 c31">9x10</span><span class="c16 c53 c68 c31 c42">26</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c16 c31">9x10</span><span class="c16 c53 c68 c31 c42">27</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c16 c31">9x10</span><span class="c16 c53 c68 c31 c42">28</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c16 c31">9x10</span><span class="c16 c53 c68 c31 c42">29</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8 c19"><span class="c14 c16 c31"></span></p></td></tr><tr class="c15"><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c23 c14">Number of samples drawn</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">5</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">5</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">5</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">5</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">20 (TOTAL)</span></p></td></tr></table><h4 class="c18 c22 c97" id="h.wulh3wt3do86"><span class="c21 c14"></span></h4><p class="c28 c19"><span class="c5 c14"></span></p><h6 class="c3 c62 c22 c75" id="h.k98tcxnqe0r8"><span style="overflow: hidden; display: inline-block; margin: 0.00px -0.00px; border: 1.33px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 465.33px;"><img alt="" src="images/image15.png" style="width: 624.00px; height: 465.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c32 c72 c31">Figure F.3</span><span class="c32 c72 c31 c42">&nbsp;</span><span class="c21">Left:</span><span class="c21 c42">&nbsp;The average-sized model for each category of model size for LMS = 0.05, 0.1 and 0.5. &nbsp; </span><span class="c21">Right: The number of average-sized </span><span class="c21">model</span><span class="c21">s that can be drawn from a given compute allocation for LMS = 0.05, 0.1 and 0.5. </span></h6><p class="c28 c19"><span class="c5 c14"></span></p><p class="c28"><span class="c5">The information in the table below is shown graphically above, alongside another configuration where the LMS=0.1. We see that the LMS determines the size of each model category - when the LMS=0.5 the average size of a model in the largest category is 1.6x10</span><span class="c2">29</span><span class="c5">&nbsp;FLOP whereas when the LMS = 0.1 and 0.05, the average size of a model in the largest category is 9.5x10</span><span class="c2">28</span><span class="c5">&nbsp;and 1.6x10</span><span class="c2">28</span><span class="c5 c14">&nbsp;respectively. The number of samples that can be drawn given the compute allocations derived above is shown in the right hand side plot - for each category, roughly 50 samples can be drawn when the LMS=0.05, 30 when the LMS=0.1 and 5 when the LMS = 0.5 (the number of samples drawn from each category is constant across model sizes in the plot above because we choose an allocation gradient of k=1.)</span></p><p class="c28 c19"><span class="c5 c14"></span></p><p class="c28 c19"><span class="c5 c14"></span></p><h2 class="c64" id="h.uwpk8bp45y7h"><span class="c14 c32 c31 c34"></span></h2><h2 class="c64" id="h.fytp98m8pu8l"><span class="c14 c32 c31 c34"></span></h2><h2 class="c80" id="h.kc72pam40q20"><span class="c14 c32 c31 c34">Appendix G | Results for varying growth rate weightings</span></h2><p class="c18 c19"><span class="c5 c14"></span></p><p class="c18"><span class="c5">Two sources of evidence inform the growth rates in the baseline scenario - the historical growth rate of training compute stocks and the compute forecast of Dean et al</span><sup class="c5"><a href="#ftnt30" id="ftnt_ref30">[30]</a></sup><span class="c5 c14">. The baseline scenario gives three times as much weight to the latter (ascribing weights of 0.25 and 0.75 to each respective growth rate), but these are subjective judgements. This Appendix shows predictions for other choices of growth rate weightings - namely weightings of (0.1,0.9), (0.33, 0.66) and (0.5, 0.5).</span></p><table class="c60"><thead><tr class="c15"><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">Threshold (FLOP)</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2024</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2025</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2026</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2027</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2028</span></p></td><tbody></tbody></tr><tr class="c15"><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c32">&gt; 10</span><span class="c40 c32">25</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[12, 15, 18]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[22, 33, 53]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[35, 55, 105]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[51, 81, 175]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[69, 114, 254]</span></p></td></tr><tr class="c15"><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c32">&gt; 10</span><span class="c40 c32">26</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 5, 8]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[6, 16, 26]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[15, 31, 59]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[26, 52, 108]</span></p></td></tr><tr class="c84"><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c32">&gt; 10</span><span class="c40 c32">27</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 1, 3]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 5, 11]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[4, 15, 34]</span></p></td></tr><tr class="c15"><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c32">&gt; 10</span><span class="c40 c32">28</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 4]</span></p></td></tr><tr class="c15"><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c32">&gt; 10</span><span class="c40 c32">29</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td></tr></thead></table><h6 class="c3 c62 c22 c75" id="h.vcnt8jlu4g4m"><span class="c32 c72 c31 c42">Table G.1</span><span class="c14 c21">&nbsp;- Results for growth rate weighting of (0.1,0.9)</span></h6><p class="c28 c19"><span class="c5 c14"></span></p><table class="c60"><thead><tr class="c15"><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">Threshold (FLOP)</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2024</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2025</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2026</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2027</span></p></td><td class="c134" colspan="1" rowspan="1"><p class="c3"><span class="c7">2028</span></p></td><tbody></tbody></tr><tr class="c15"><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c32">&gt; 10</span><span class="c40 c32">25</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[14, 17, 20]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[26, 35, 65]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[41, 61, 135]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[59, 93, 215]</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c3"><span class="c0">[85, 135, 320]</span></p></td></tr><tr class="c15"><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c32">&gt; 10</span><span class="c40 c32">26</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[4, 7, 10]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[12, 21, 41]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[24, 41, 85]</span></p></td><td class="c48" colspan="1" rowspan="1"><p class="c3"><span class="c0">[41, 70, 150]</span></p></td></tr><tr class="c84"><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c32">&gt; 10</span><span class="c40 c32">27</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 1]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 3, 7]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[5, 11, 23]</span></p></td><td class="c48" colspan="1" rowspan="1"><p class="c3"><span class="c0">[14, 27, 55]</span></p></td></tr><tr class="c15"><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c32">&gt; 10</span><span class="c40 c32">28</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 2]</span></p></td><td class="c48" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 5, 12]</span></p></td></tr><tr class="c15"><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c32">&gt; 10</span><span class="c40 c32">29</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c127" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td></tr></thead></table><h6 class="c26 c22" id="h.39zo0433p49l"><span class="c32 c72 c31 c42">Table G.2</span><span class="c21 c14">&nbsp;- Results for growth rate weighting of (0.33,0.66)</span></h6><h3 class="c39 c76" id="h.3bpem1284vh0"><span class="c65 c14 c31"></span></h3><p class="c18 c19"><span class="c5 c14"></span></p><p class="c28 c19"><span class="c5 c14"></span></p><table class="c60"><thead><tr class="c15"><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">Threshold</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2024</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2025</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2026</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2027</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2028</span></p></td><tbody></tbody></tr><tr class="c15"><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c32">&gt; 10</span><span class="c32 c40">25</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[15, 17, 21]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[28, 37, 72]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[45, 63, 139]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[66, 96, 212]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[89, 136, 341]</span></p></td></tr><tr class="c15"><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c32">&gt; 10</span><span class="c40 c32">26</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[5, 8, 13]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[15, 23, 46]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[28, 45, 91]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[45, 72, 174]</span></p></td></tr><tr class="c84"><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c32">&gt; 10</span><span class="c40 c32">27</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 1]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 4, 8]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[6, 14, 26]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[17, 30, 68]</span></p></td></tr><tr class="c15"><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c32">&gt; 10</span><span class="c40 c32">28</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 3]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 6, 14]</span></p></td></tr><tr class="c15"><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c32">&gt; 10</span><span class="c32 c53">29</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 1]</span></p></td></tr></thead></table><h6 class="c3 c62 c22 c75" id="h.7c38rgipdomf"><span class="c32 c72 c31 c42">Table G.3</span><span class="c21 c14">&nbsp;- Results for growth rate weighting of (0.5,0.5)</span></h6><p class="c18 c19"><span class="c5 c14"></span></p><p class="c18 c19"><span class="c5 c14"></span></p><p class="c18 c19"><span class="c5 c14"></span></p><p class="c18 c19"><span class="c5 c14"></span></p><p class="c18 c19"><span class="c5 c14"></span></p><h2 class="c12" id="h.cqt4ueew9iwj"><span class="c14 c32 c31 c34"></span></h2><h2 class="c12" id="h.grwjfrwz6lrv"><span class="c14 c32 c31 c34"></span></h2><h2 class="c12" id="h.he1rk7br6y69"><span class="c14 c32 c31 c34"></span></h2><h2 class="c12" id="h.5dafxc4ntrfa"><span class="c14 c32 c31 c34"></span></h2><h2 class="c12" id="h.lfz16ayy5891"><span class="c14 c32 c31 c34"></span></h2><h2 class="c12" id="h.r2th8tray0ft"><span class="c14 c32 c31 c34"></span></h2><h2 class="c12" id="h.lp7tf86sy2i4"><span class="c14 c32 c31 c34"></span></h2><h2 class="c12" id="h.or1d0w12kcsh"><span class="c14 c32 c31 c34"></span></h2><h2 class="c12" id="h.kvveleapstsw"><span class="c14 c32 c31 c34"></span></h2><h2 class="c39" id="h.uoquc4qd38jc"><span class="c14 c32 c31 c34">Appendix H - Results for alternate training compute allocations</span></h2><p class="c18"><span class="c33"><a class="c24" href="#h.w37fa0y8qvzs">Section 2.3</a></span><span class="c5">&nbsp;highlighted that the publicly available information on the allocation of </span><span class="c5">compute</span><span class="c5">&nbsp;between training, inference and other workloads was conflicting. Our baseline model uses a slightly adjusted version of the allocation in Dean et al</span><sup class="c5"><a href="#ftnt31" id="ftnt_ref31">[31]</a></sup><span class="c5">. However another source for the compute allocations is the Epoch GATE model</span><sup class="c5"><a href="#ftnt32" id="ftnt_ref32">[32]</a></sup><span class="c5 c14">; the allocations for this model are shown below. &nbsp;</span></p><table class="c120"><tr class="c82"><td class="c141" colspan="1" rowspan="1"><p class="c8"><span class="c23 c14">Year</span></p></td><td class="c107" colspan="1" rowspan="1"><p class="c8"><span class="c23">Approximate training </span><span class="c23">compute</span><span class="c23 c14">&nbsp;allocations (GATE)</span></p></td></tr><tr class="c82"><td class="c118" colspan="1" rowspan="1"><p class="c8"><span class="c21 c14">2025</span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">90%</span></p></td></tr><tr class="c54"><td class="c61" colspan="1" rowspan="1"><p class="c8"><span class="c21 c14">2026</span></p></td><td class="c36" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">70%</span></p></td></tr><tr class="c54"><td class="c61" colspan="1" rowspan="1"><p class="c8"><span class="c21 c14">2027</span></p></td><td class="c36" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">70%</span></p></td></tr><tr class="c15"><td class="c111" colspan="1" rowspan="1"><p class="c8"><span class="c21 c14">2028</span></p></td><td class="c109" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">70%</span></p></td></tr></table><h6 class="c26 c22" id="h.pd4j5m303l20"><span class="c21 c14">Table H.1 - GATE model compute allocations for training, 2025-2028</span></h6><p class="c18"><span class="c5">It&rsquo;s clear that these forecasts differ substantially to those in AI 2027, however it is out of scope for this article to explore why. This Appendix shows the predictions of the model for the absolute compute thresholds </span><span class="c5">when</span><span class="c5">&nbsp;</span><span class="c5">training compute</span><span class="c5 c14">&nbsp;allocations are set as above. </span></p><table class="c60"><thead><tr class="c15"><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">Threshold (FLOP)</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2024</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2025</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2026</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2027</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2028</span></p></td><tbody></tbody></tr><tr class="c15"><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c7">&gt;1e25</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[21, 24, 28]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[35, 45, 75]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[50, 69, 137]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[69, 98, 217]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[94, 140, 331]</span></p></td></tr><tr class="c15"><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c7">&gt;1e26</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 2, 5]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[6, 12, 23]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[15, 26, 52]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[28, 45, 102]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[45, 74, 178]</span></p></td></tr><tr class="c15"><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c7">&gt;1e27</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 2]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 4, 10]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[6, 14, 31]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[16, 32, 70]</span></p></td></tr><tr class="c15"><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c7">&gt;1e28</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 1, 4]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 7, 20]</span></p></td></tr><tr class="c15"><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c7">&gt;1e29</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 1]</span></p></td></tr></thead></table><h6 class="c49 c62 c22" id="h.qydyez29q8at"><span class="c32 c72 c31 c42">Table H.2</span><span class="c21 c14">&nbsp;- Predictions under GATE model allocations</span></h6><h2 class="c12" id="h.8va5cihspgs"><span class="c14 c32 c31 c34"></span></h2><h2 class="c39" id="h.97eqny6utl2u"><span class="c14 c32 c31 c34">Appendix I | Results for varying allocation gradients</span></h2><p class="c18 c19"><span class="c5 c14"></span></p><p class="c28 c19"><span class="c5 c14"></span></p><table class="c60"><thead><tr class="c15"><td class="c94" colspan="1" rowspan="1"><p class="c8 c19"><span class="c23 c14"></span></p></td><td class="c94" colspan="1" rowspan="1"><p class="c8"><span class="c23">10</span><span class="c23 c53">-7</span><span class="c23">-10</span><span class="c23 c53">-6</span></p></td><td class="c94" colspan="1" rowspan="1"><p class="c8"><span class="c23">10</span><span class="c23 c53">-7</span><span class="c23">-10</span><span class="c23 c53">-</span></p></td><td class="c94" colspan="1" rowspan="1"><p class="c8"><span class="c23">10</span><span class="c23 c53">-5</span><span class="c23">-10</span><span class="c23 c53">-4</span></p></td><td class="c94" colspan="1" rowspan="1"><p class="c8"><span class="c23">10</span><span class="c23 c53">-4</span><span class="c23">-10</span><span class="c23 c53">-3</span></p></td><td class="c94" colspan="1" rowspan="1"><p class="c8"><span class="c23">10</span><span class="c23 c53">-3</span><span class="c23">-10</span><span class="c23 c53">-2</span></p></td><td class="c94" colspan="1" rowspan="1"><p class="c8"><span class="c23">10</span><span class="c23 c53">-2</span><span class="c23">-10</span><span class="c23 c53">-1</span></p></td><td class="c129" colspan="1" rowspan="1"><p class="c8"><span class="c23">10</span><span class="c23 c53">-1</span><span class="c23">-10</span><span class="c23 c53">0</span></p></td><tbody></tbody></tr><tr class="c15"><td class="c91" colspan="1" rowspan="1"><p class="c8"><span class="c21 c14">k=0.5</span></p></td><td class="c91" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">0.068</span></p></td><td class="c91" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">0.22</span></p></td><td class="c91" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">0.68</span></p></td><td class="c91" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">2.2</span></p></td><td class="c91" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">6.8</span></p></td><td class="c91" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">22</span></p></td><td class="c77" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">68</span></p></td></tr><tr class="c15"><td class="c4" colspan="1" rowspan="1"><p class="c8"><span class="c21 c14">k=0.6</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">0.019</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">0.075 </span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">0.3</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">1.2</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">4.7</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">19</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">75</span></p></td></tr><tr class="c84"><td class="c4" colspan="1" rowspan="1"><p class="c8"><span class="c21 c14">k=0.7</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">0.0051</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">0.0025</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">0.13</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">0.64</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">3.2</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">16</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">80</span></p></td></tr><tr class="c15"><td class="c4" colspan="1" rowspan="1"><p class="c8"><span class="c21 c14">k=0.8</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">0.0013</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">0.0084</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">0.53</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">0.34</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">2.1</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">13</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">84</span></p></td></tr><tr class="c15"><td class="c4" colspan="1" rowspan="1"><p class="c8"><span class="c21 c14">k=0.9</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">0.00035</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">0.0028</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">0.022</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">0.17</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">1.4</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">11</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">87</span></p></td></tr><tr class="c15"><td class="c96" colspan="1" rowspan="1"><p class="c8"><span class="c21 c14">k=1.0</span></p></td><td class="c96" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">0.00009</span></p></td><td class="c96" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">0.0009</span></p></td><td class="c96" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">0.009</span></p></td><td class="c96" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">0.09</span></p></td><td class="c96" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">0.9</span></p></td><td class="c96" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">9</span></p></td><td class="c67" colspan="1" rowspan="1"><p class="c8"><span class="c14 c16 c31">90</span></p></td></tr></thead></table><h6 class="c26 c22" id="h.bv43yhbu9378"><span class="c32 c72 c31 c42">Table I.1</span><span class="c21 c42">&nbsp;- Compute allocations for various k &lt; 1. Each column gives the allocation for a particular model size, relative to the largest model trained in a given year.</span><span class="c21">&nbsp;</span><span class="c21 c14">E.g: The rightmost column shows compute allocations for models within 1 OOM of the largest model size.</span></h6><p class="c18"><span class="c5">Our baseline scenario samples the allocation gradient uniformly from the range [0.9, 1.1]. The median prediction in this scenario will therefore follow a compute allocation across model sizes as shown in the k=1 scenario in the table above. This modelling choice is made from observations of the allocation plots for the Notable models released in the </span><span class="c33"><a class="c24" href="#h.io0s51ptaeqw">years 2017-2023</a></span><span class="c5 c14">. &nbsp;</span></p><p class="c18"><span class="c5">However section 5.2 discusses the limitations of the Notable Models database upon which these trends are based. One way to account for the Notable Models selection effect is to allocate more compute to smaller models relative to their larger counterparts. This can be seen in the table above where the k=0.5 case allocates ~68% of compute that year to the largest model category, whereas the k=1.0 case allocates 90% of compute. More generally, increasing model size by 10x leads to a 10</span><span class="c2">k</span><span class="c5">&nbsp;times increase in compute allocated, as shown in </span><span class="c33"><a class="c24" href="#h.wxd47v1bse8f">Appendix C</a></span><span class="c5 c14">. </span></p><p class="c18"><span class="c5 c14">This Appendix presents model predictions for allocation gradients that allocate relatively more compute to smaller model sizes. Specifically, the table below presents the results of our model if the allocation gradient is sampled uniformly from the range [0.5, 0.1]. Noticeably more aggressive median predictions and wider confidence intervals can be observed.</span></p><p class="c28 c19"><span class="c14 c58 c34"></span></p><p class="c28 c19"><span class="c14 c58 c34"></span></p><p class="c28 c19"><span class="c14 c58 c34"></span></p><p class="c28 c19"><span class="c14 c58 c34"></span></p><table class="c60"><thead><tr class="c15"><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">Threshold</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2024</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2025</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2026</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2027</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c3"><span class="c7">2028</span></p></td><tbody></tbody></tr><tr class="c15"><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c32">&gt; 10</span><span class="c40 c32">25</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[11, 15, 18]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[24, 37, 55]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[41, 73, 145]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[61, 113, 265]</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3"><span class="c0">[87, 187, 510]</span></p></td></tr><tr class="c15"><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c32">&gt; 10</span><span class="c40 c32">26</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[3, 5, 8]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[11, 18, 33]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[23, 38, 76]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[39, 73, 172]</span></p></td></tr><tr class="c15"><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c32">&gt; 10</span><span class="c40 c32">27</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 2, 4]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[2, 8, 15]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[10, 22, 47]</span></p></td></tr><tr class="c15"><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c32">&gt; 10</span><span class="c40 c32">28</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 1]</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 2, 7]</span></p></td></tr><tr class="c15"><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c32">&gt; 10</span><span class="c32 c53">29</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3"><span class="c0">[0, 0, 0]</span></p></td></tr></thead></table><h6 class="c3 c62 c22 c75" id="h.prpov72fvtkr"><span class="c21 c14">Table I.2: Predictions when allocation gradient (k) sampled uniform from range [0.5, 1.0], as an approximate correction mechanism to notable models selection effect. </span></h6><p class="c28 c19"><span class="c14 c58 c70"></span></p><p class="c28 c19"><span class="c14 c58 c70"></span></p><p class="c28 c19"><span class="c14 c58 c70"></span></p><h4 class="c49 c22 c97" id="h.boan3vvfi2ee"><span class="c38 c133 c104 c86 c42 c137"></span></h4><h3 class="c76 c80" id="h.o41838gko7el"><span class="c14 c58 c34"></span></h3><h3 class="c80 c76" id="h.ljnz3id5y4fr"><span class="c14 c58 c34"></span></h3><p class="c19 c28"><span class="c5 c14"></span></p><p class="c18 c19"><span class="c5 c14"></span></p><p class="c18 c19"><span class="c5 c14"></span></p><p class="c28 c19"><span class="c5 c14"></span></p><p class="c28 c19"><span class="c5 c14"></span></p><h2 class="c64" id="h.vd8wa2fgiyhv"><span class="c14 c32 c31 c34"></span></h2><p class="c28 c19"><span class="c14 c58 c70"></span></p><p class="c28 c19"><span class="c14 c58 c70"></span></p><hr class="c83"><div><h5 class="c39 c22" id="h.e1huadk7u6i6"><a href="#ftnt_ref1" id="ftnt1">[1]</a><span class="c79 c31">&nbsp;</span><span class="c55 c38"><a class="c24" href="https://www.google.com/url?q=https://openai.com/o1/&amp;sa=D&amp;source=editors&amp;ust=1744328243740589&amp;usg=AOvVaw2Y1UYG2ivyOReCmEQ584HC">Introducing OpenAI o1</a></span><span class="c13">&nbsp;</span></h5></div><div><h5 class="c39 c22" id="h.tqjnynm8it3i"><a href="#ftnt_ref2" id="ftnt2">[2]</a><span class="c79 c31">&nbsp;In this paper we often use the notation 10</span><span class="c79 c53 c31">X </span><span class="c79 c31">to refer to absolute compute thresholds. However the notation 1eX also appears at times which is interchangeable with the first notation. For 1e24 FLOP = 10</span><span class="c79 c53 c31">24 </span><span class="c79 c31">FLOP, 5.3e25 FLOP = 5.3 x 10</span><span class="c79 c53 c31">25</span><span class="c13">&nbsp;FLOP, etc.</span></h5></div><div><h5 class="c39 c22" id="h.1t0rfnyivt9r"><a href="#ftnt_ref3" id="ftnt3">[3]</a><span class="c79 c31">&nbsp;</span><span class="c55 c38"><a class="c24" href="https://www.google.com/url?q=https://www.federalregister.gov/documents/2025/01/15/2025-00636/framework-for-artificial-intelligence-diffusion&amp;sa=D&amp;source=editors&amp;ust=1744328243741792&amp;usg=AOvVaw2gMIia8cw7PWEKQINypRrR">Federal Register :: Framework for Artificial Intelligence Diffusion</a></span><span class="c13">&nbsp;</span></h5></div><div><h5 class="c37 c22" id="h.74mc5xncuqqd"><a href="#ftnt_ref4" id="ftnt4">[4]</a><span class="c79 c31">&nbsp;</span><span class="c55 c38"><a class="c24" href="https://www.google.com/url?q=https://epochai.org/blog/training-compute-of-frontier-ai-models-grows-by-4-5x-per-year&amp;sa=D&amp;source=editors&amp;ust=1744328243742271&amp;usg=AOvVaw1JhdQT8IFSg1F2WFGKayrX">Training Compute of Frontier AI Models Grows by 4-5x per Year</a></span><span class="c13">&nbsp;</span></h5></div><div><h5 class="c39 c22" id="h.70d0dll74nmt"><a href="#ftnt_ref5" id="ftnt5">[5]</a><span class="c79 c31">&nbsp;</span><span class="c38 c55"><a class="c24" href="https://www.google.com/url?q=https://openai.com/sora/&amp;sa=D&amp;source=editors&amp;ust=1744328243742562&amp;usg=AOvVaw1vsKAaGtTN6yRP7KARNyQ-">https://openai.com/sora</a></span><span class="c79 c31">&nbsp; </span><span class="c55 c38"><a class="c24" href="https://www.google.com/url?q=https://deepmind.google/technologies/imagen-3/&amp;sa=D&amp;source=editors&amp;ust=1744328243742733&amp;usg=AOvVaw1SYD-V-7uj6NZPsB7OIB1A">Imagen - Google DeepMind</a></span><span class="c13">&nbsp;</span></h5></div><div><p class="c39"><a href="#ftnt_ref6" id="ftnt6">[6]</a><span class="c79 c31">&nbsp;</span><span class="c55 c38"><a class="c24" href="https://www.google.com/url?q=https://arxiv.org/abs/2503.11922&amp;sa=D&amp;source=editors&amp;ust=1744328243743065&amp;usg=AOvVaw3GQjHVvtipT58UVAFYl65g">[2503.11922] On Regulating Downstream AI Developers</a></span><span class="c13">&nbsp;</span></p></div><div><h5 class="c39 c22" id="h.42a264ucil6h"><a href="#ftnt_ref7" id="ftnt7">[7]</a><span class="c79 c31">&nbsp;</span><span class="c79 c98">Chan, Alan, et al. &quot;Infrastructure for AI Agents.&quot;</span><span class="c55 c142"><a class="c24" href="https://www.google.com/url?q=https://arxiv.org/abs/2501.10114&amp;sa=D&amp;source=editors&amp;ust=1744328243743428&amp;usg=AOvVaw2vtNJek4_M9lt80dgdTG4K">&nbsp;arXiv preprint arXiv:2501.10114 (2025).</a></span></h5></div><div><h5 class="c39 c22" id="h.a2nzsoct3ri6"><a href="#ftnt_ref8" id="ftnt8">[8]</a><span class="c31 c79">&nbsp;</span><span class="c55 c38"><a class="c24" href="https://www.google.com/url?q=https://epoch.ai/data/notable-ai-models-documentation%23inclusion&amp;sa=D&amp;source=editors&amp;ust=1744328243743736&amp;usg=AOvVaw12jgeOEYa-Lxt-N1SEI9BH">Notable AI Models Documentation | Epoch AI</a></span></h5></div><div><h5 class="c39 c22" id="h.bubi4w92ya5p"><a href="#ftnt_ref9" id="ftnt9">[9]</a><span class="c13">&nbsp;This is because models multiple orders of magnitude away from the frontier are less likely to be captured by the notable model criteria relative to models close to the frontier. </span></h5></div><div><h5 class="c39 c22" id="h.a6skg0bzw96g"><a href="#ftnt_ref10" id="ftnt10">[10]</a><span class="c79 c31">&nbsp;</span><span class="c55 c38"><a class="c24" href="https://www.google.com/url?q=https://ai-2027.com/research/compute-forecast&amp;sa=D&amp;source=editors&amp;ust=1744328243744425&amp;usg=AOvVaw1f3DQtZRixpQNlt5tzMZvr">Compute Forecast &mdash; AI 2027</a></span><span class="c13">&nbsp;</span></h5></div><div><h5 class="c39 c22" id="h.3tivt6qvnetq"><a href="#ftnt_ref11" id="ftnt11">[11]</a><span class="c79 c31">&nbsp;One can think of these two quantities as AI compute </span><span class="c79 c31 c73">capacity</span><span class="c79 c31">&nbsp;and AI compute </span><span class="c51 c79 c31">usage. </span></h5></div><div><h5 class="c39 c22" id="h.uoku3aninxio"><a href="#ftnt_ref12" id="ftnt12">[12]</a><span class="c79 c31">&nbsp;</span><span class="c55 c38"><a class="c24" href="https://www.google.com/url?q=https://ai-2027.com/research/compute-forecast&amp;sa=D&amp;source=editors&amp;ust=1744328243745037&amp;usg=AOvVaw0DWTOwr_lPwgx9LvayHxi7">Compute Forecast &mdash; AI 2027</a></span><span class="c13">&nbsp;</span></h5></div><div><p class="c39"><a href="#ftnt_ref13" id="ftnt13">[13]</a><span class="c31 c117">&nbsp;</span><span class="c55 c38"><a class="c24" href="https://www.google.com/url?q=https://epoch.ai/gate&amp;sa=D&amp;source=editors&amp;ust=1744328243745328&amp;usg=AOvVaw2dioScValycUOssuAcspVv">GATE Model Playground | Epoch AI</a></span><span class="c13">&nbsp;</span></p></div><div><p class="c39"><a href="#ftnt_ref14" id="ftnt14">[14]</a><span class="c31 c59">&nbsp;</span><span class="c55 c38"><a class="c24" href="https://www.google.com/url?q=https://ai-2027.com/research/compute-forecast&amp;sa=D&amp;source=editors&amp;ust=1744328243745592&amp;usg=AOvVaw0EYB-kjCOxwEiT94J4CIWH">Compute Forecast &mdash; AI 2027</a></span><span class="c13">&nbsp;</span></p></div><div><p class="c39"><a href="#ftnt_ref15" id="ftnt15">[15]</a><span class="c79 c31">&nbsp;Concretely, we take the start of 2027 allocation (30%) as the allocation for all of 2027, and the end of 2027 allocation (20%) as the 2028 allocation.</span><span class="c5 c14">&nbsp;</span></p></div><div><p class="c39"><a href="#ftnt_ref16" id="ftnt16">[16]</a><span class="c16 c31">&nbsp;</span><span class="c79 c31">For example, the </span><span class="c55 c38"><a class="c24" href="https://www.google.com/url?q=https://epoch.ai/gate&amp;sa=D&amp;source=editors&amp;ust=1744328243746221&amp;usg=AOvVaw2-EKkd6BDYSPCDq8SgdpQj">Epoch GATE model</a></span><span class="c13">&nbsp;estimates an allocation of 90% of compute to model training in 2024, moving to 70% in 2028.</span></p></div><div><h5 class="c39 c22" id="h.1bjfgvesrnq"><a href="#ftnt_ref17" id="ftnt17">[17]</a><span class="c79 c31">&nbsp;See Appendix A of </span><span class="c55 c38"><a class="c24" href="https://www.google.com/url?q=https://arxiv.org/pdf/2307.03718&amp;sa=D&amp;source=editors&amp;ust=1744328243746682&amp;usg=AOvVaw3BtTLZJdscdZdECHkpjgwa">Frontier AI Regulation: Managing Emerging Risks to Public Safety</a></span><span class="c13">&nbsp;for discussion. &nbsp;</span></h5></div><div><h5 class="c39 c22" id="h.f01y4m8p8car"><a href="#ftnt_ref18" id="ftnt18">[18]</a><span class="c79 c31">&nbsp;Although we didn&rsquo;t use 2024 data to fit the model because it appears </span><span class="c55 c38">incomplete</span><span class="c79 c31">, we include this comparison as it seems that the 2024 data is incomplete towards the </span><span class="c79 c31 c73">left tail</span><span class="c79 c31">&nbsp;of the distribution. 10</span><span class="c79 c53 c31">25</span><span class="c13">&nbsp;FLOP models in 2024 are firmly on the right tail of the model distribution, making them more likely to be accounted for in the database. </span></h5></div><div><h5 class="c39 c22" id="h.i8knhzm9xupx"><a href="#ftnt_ref19" id="ftnt19">[19]</a><span class="c79 c31">&nbsp;The exception in the table above is for 2024 where we set the largest model produced to be the size of GPT-4o. For the predictions </span><span class="c59 c38 c31">without</span><span class="c79 c31">&nbsp;this constraint, see </span><span class="c55 c38">Appendix D</span><span class="c13">; in this case, the 2024 frontier-connected counts follow a similar trend to 2025-2028. </span></h5></div><div><h5 class="c39 c22" id="h.e3s5ikjpv0xq"><a href="#ftnt_ref20" id="ftnt20">[20]</a><span class="c13">&nbsp;As a reminder, the notability criteria are:</span></h5><ul class="c105 lst-kix_46k1qzu5stp6-0 start"><li class="c39 c30 c22 li-bullet-0"><h5 id="h.i8gls7r44t7u" style="display:inline"><span class="c13">highly cited (over 1000 citations);</span></h5></li><li class="c39 c30 c22 li-bullet-0"><h5 id="h.qfitcre0qi8a" style="display:inline"><span class="c13">large training cost (over $1,000,000, measured in 2023 USD);</span></h5></li><li class="c39 c30 c22 li-bullet-0"><h5 id="h.v6ebrok2udrl" style="display:inline"><span class="c13">significant use (over one million monthly active users);</span></h5></li><li class="c39 c30 c22 li-bullet-0"><h5 id="h.qjos0w52h25r" style="display:inline"><span class="c13">state of the art performance (typically on a recognised ML benchmark);</span></h5></li><li class="c39 c30 c22 li-bullet-0"><h5 id="h.6u67idannzp9" style="display:inline"><span class="c13">indisputable historical significance.</span></h5></li></ul></div><div><p class="c39"><a href="#ftnt_ref21" id="ftnt21">[21]</a><span class="c5">&nbsp;</span><span class="c33"><a class="c24" href="https://www.google.com/url?q=https://ai-2027.com/supplements/compute-forecast&amp;sa=D&amp;source=editors&amp;ust=1744328243749865&amp;usg=AOvVaw3uKVZyOHoTDk3tTm8aFzVL">https://ai-2027.com/supplements/compute-forecast</a></span><span class="c5 c14">&nbsp;</span></p></div><div><h5 class="c39 c22" id="h.wfa3a0tvsyh8"><a href="#ftnt_ref22" id="ftnt22">[22]</a><span class="c79 c31">&nbsp;</span><span class="c55 c38"><a class="c24" href="https://www.google.com/url?q=https://arxiv.org/abs/2405.10799&amp;sa=D&amp;source=editors&amp;ust=1744328243750169&amp;usg=AOvVaw3-QRBoww3sLljx0SZZ7Sip">Heim and Koessler, 2024</a></span></h5></div><div><h5 class="c39 c22" id="h.ihugngt2infl"><a href="#ftnt_ref23" id="ftnt23">[23]</a><span class="c79 c31">&nbsp;</span><span class="c55 c38"><a class="c24" href="https://www.google.com/url?q=https://arxiv.org/abs/2402.08797&amp;sa=D&amp;source=editors&amp;ust=1744328243750428&amp;usg=AOvVaw1nQ3YdBHzJDdkKyekDUyew">Sastry, et al. 2024</a></span></h5></div><div><h5 class="c39 c22" id="h.eaj2caprg6cw"><a href="#ftnt_ref24" id="ftnt24">[24]</a><span class="c79 c31">&nbsp; </span><span class="c55 c38"><a class="c24" href="https://www.google.com/url?q=https://artificialintelligenceact.eu/&amp;sa=D&amp;source=editors&amp;ust=1744328243750671&amp;usg=AOvVaw2iWTgaA9J3ymUQ0aIvmFQC">EU AI Act</a></span><span class="c13">&nbsp;</span></h5></div><div><h5 class="c39 c22" id="h.rvno71t82817"><a href="#ftnt_ref25" id="ftnt25">[25]</a><span class="c79 c31">&nbsp; </span><span class="c55 c38"><a class="c24" href="https://www.google.com/url?q=https://www.federalregister.gov/documents/2025/01/15/2025-00636/framework-for-artificial-intelligence-diffusion&amp;sa=D&amp;source=editors&amp;ust=1744328243751072&amp;usg=AOvVaw39JSne25_vTrj1nQWiAWOe">Federal Register :: Framework for Artificial Intelligence Diffusion</a></span><span class="c13">&nbsp;</span></h5></div><div><h5 class="c39 c22" id="h.vxdxur2dudqg"><a href="#ftnt_ref26" id="ftnt26">[26]</a><span class="c79 c31">How reliable is this figure given that 2024 data is incomplete? Our assumption here is that 2024 data is incomplete towards the left tail of the model distribution, but is more reliable towards the right tail of the model distribution. Given that the largest model </span><span class="c59 c31">and</span><span class="c13">&nbsp;the total compute in a given year are dependent on models on the right tail of the model distribution, we take them to be sufficiently reliable to use in our projections. </span></h5><p class="c39 c19"><span class="c5 c14"></span></p></div><div><p class="c39"><a href="#ftnt_ref27" id="ftnt27">[27]</a><span class="c5 c14">&nbsp;By taking the geometric mean of the model category bounds. We take the geometric mean instead of the arithmetic mean as the bounds are given in logspace. </span></p></div><div><h5 class="c39 c22" id="h.r9yg6b97pbf6"><a href="#ftnt_ref28" id="ftnt28">[28]</a><span class="c13">&nbsp;Geometric mean</span></h5></div><div><h5 class="c39 c22" id="h.5aup8fra5sn0"><a href="#ftnt_ref29" id="ftnt29">[29]</a><span class="c13">&nbsp;Geometric mean</span></h5></div><div><p class="c39"><a href="#ftnt_ref30" id="ftnt30">[30]</a><span class="c5">&nbsp;</span><span class="c33"><a class="c24" href="https://www.google.com/url?q=https://ai-2027.com/research/compute-forecast&amp;sa=D&amp;source=editors&amp;ust=1744328243752799&amp;usg=AOvVaw1ZnMR1UFWrqdMwr6B7v-hX">Compute Forecast &mdash; AI 2027</a></span><span class="c5 c14">&nbsp;</span></p></div><div><p class="c39"><a href="#ftnt_ref31" id="ftnt31">[31]</a><span class="c5">&nbsp;</span><span class="c33"><a class="c24" href="https://www.google.com/url?q=https://ai-2027.com/supplements/compute-forecast&amp;sa=D&amp;source=editors&amp;ust=1744328243753084&amp;usg=AOvVaw0JtJujGFKysKs2S6pcNHl3">https://ai-2027.com/supplements/compute-forecast</a></span><span class="c5 c14">&nbsp;</span></p></div><div><p class="c39"><a href="#ftnt_ref32" id="ftnt32">[32]</a><span class="c5">&nbsp;</span><span class="c33"><a class="c24" href="https://www.google.com/url?q=https://epoch.ai/gate&amp;sa=D&amp;source=editors&amp;ust=1744328243753297&amp;usg=AOvVaw24hfFcK9rQw_mjJd42da0o">https://epoch.ai/gate</a></span><span class="c5 c14">&nbsp;- See inference-training split graph. Note that the GATE model forecasts the allocation of effective compute - which is the physical compute stock multiplied by algorithmic progress. However in the near future (e.g: 2025-2028), these two quantities do not substantially differ. </span></p></div></body></html>